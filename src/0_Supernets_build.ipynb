{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f2a6167-590b-4075-a79b-bc9c87c21fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "import copy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d44daf17-a904-432d-9a14-c31e4ee01fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rep_model_convert(model:torch.nn.Module, save_path=None, do_copy=True):\n",
    "    if do_copy:\n",
    "        model = copy.deepcopy(model)\n",
    "    for module in model.modules():\n",
    "        if hasattr(module, 'switch_to_deploy'):\n",
    "            module.switch_to_deploy()\n",
    "    if save_path is not None:\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc16632e-5d34-416b-b805-250e92a80c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302ae760-f36c-44a4-8f65-bfd05beffb37",
   "metadata": {},
   "source": [
    "# NAS_REP_ConvBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f5ff14f-7205-4ce4-9f12-03cca3be5b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a helper function to create a convolutional layer followed by batch normalization\n",
    "def conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups=1):\n",
    "    # Use nn.Sequential to combine multiple layers into a single module\n",
    "    result = nn.Sequential()\n",
    "    # Add a convolutional layer\n",
    "    result.add_module('conv', nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                                  kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=False))\n",
    "    # Add a batch normalization layer\n",
    "    result.add_module('bn', nn.BatchNorm2d(num_features=out_channels))\n",
    "    return result\n",
    "\n",
    "\n",
    "class NAS_REP_ConvBNBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_channels, \n",
    "        out_channels, \n",
    "        max_kernel_size,\n",
    "        stride, \n",
    "        deploy = False,\n",
    "        verbose = False,\n",
    "        scaling_factor = 0.5,\n",
    "        run_time_depth_index = 0):\n",
    "        \"\"\"\n",
    "        Initialize the block with given parameters.\n",
    "        in_channels               : number of input channels\n",
    "        out_channels              : number of output channels\n",
    "        max_kernel_size           : maximum kernel size\n",
    "        stride                    : stride for the convolution\n",
    "        deploy                    : if True, deploy the model for inference\n",
    "        verbose                   : if True, print log messages\n",
    "        scaling_factor            : scaling factor for combining the outputs\n",
    "        run_time_depth_index      : 这是标记这个conv属于progressive中的哪个stage，如果， 默认都是零\n",
    "        \"\"\"\n",
    "\n",
    "        super(NAS_REP_ConvBNBlock, self).__init__()\n",
    "        self.in_channels      =  in_channels\n",
    "        self.out_channels     =  out_channels\n",
    "        self.max_kernel_size  =  max_kernel_size\n",
    "        self.stride           =  stride\n",
    "        self.verbose          =  verbose\n",
    "        self.deploy           =  deploy\n",
    "        self.scaling_factor   =  scaling_factor # 因为是所有的输出就要相加，所以当kernel过大的时候，可能需要一个scaling\n",
    "        self.run_time_depth_index   = run_time_depth_index\n",
    "        self.current_run_time_depth = None\n",
    "        assert max_kernel_size>=1\n",
    "        assert max_kernel_size%2==1\n",
    "        self.out_channels   =  out_channels\n",
    "        self.in_channels    =  in_channels\n",
    "        self.kernel_list = [0] + list(range(1,max_kernel_size+1,2))\n",
    "\n",
    "        self.active_kernel_index = len(self.kernel_list)-1 \n",
    "\n",
    "        if self.stride == 2 or out_channels != in_channels:\n",
    "            self.kernel_index_range = list(range(1,self.active_kernel_index+1))\n",
    "        else:\n",
    "            self.kernel_index_range = list(range(0,self.active_kernel_index+1))\n",
    "\n",
    "        self.nonlinearity = nn.ReLU()\n",
    "        \n",
    "\n",
    "        # -------------------- Identity -Skip Connection------------------------------\n",
    "\n",
    "        # =============== TODO Identidy ======================================\n",
    "        if out_channels == in_channels and stride == 1:\n",
    "            setattr(self, f\"branch_kernel_0\", nn.BatchNorm2d(num_features=in_channels))\n",
    "        else:\n",
    "            setattr(self, f\"branch_kernel_0\", None)\n",
    "\n",
    "\n",
    "        # -------------------- convolutional with Batchnormalizition with kernel >= 1------------------------\n",
    "        for k in self.kernel_list[1:]:\n",
    "            setattr(self, f\"branch_kernel_{k}\", conv_bn(in_channels, out_channels, k, stride, k//2))\n",
    "\n",
    "    def log(self, message):\n",
    "        if self.verbose:\n",
    "            print(message)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        if self.active_kernel_index in self.kernel_index_range:\n",
    "            if self.current_run_time_depth is None or self.current_run_time_depth>=self.run_time_depth_index:\n",
    "                if hasattr(self, 'conv_reparam'):\n",
    "                    return self.nonlinearity(self.conv_reparam(inputs))\n",
    "                \n",
    "                else:\n",
    "                    if getattr(self, f\"branch_kernel_0\") is not None:\n",
    "                        self.log(\"using branch_kernel_0\")\n",
    "                        output = self.scaling_factor * getattr(self, f\"branch_kernel_0\")(inputs)\n",
    "        \n",
    "                        index = 1\n",
    "                    else:\n",
    "                        self.log(\"using branch_kernel_1\")\n",
    "                        output = self.scaling_factor * getattr(self, f\"branch_kernel_1\")(inputs)\n",
    "                        index = 2  \n",
    "                    \n",
    "                    for k in self.kernel_list[index:self.active_kernel_index+1]:\n",
    "                        self.log(f\"using branch_kernel_{k}\")\n",
    "                        output += self.scaling_factor * getattr(self, f\"branch_kernel_{k}\")(inputs)\n",
    "        \n",
    "        \n",
    "                    return self.nonlinearity(output)\n",
    "            else:\n",
    "                return inputs\n",
    "            \n",
    "        else:\n",
    "            return inputs\n",
    "\n",
    "\n",
    "    def _fuse_bn_tensor(self, branch):\n",
    "\n",
    "        if branch is None:\n",
    "            return 0, 0\n",
    "        if isinstance(branch, nn.Sequential):\n",
    "            kernel = branch.conv.weight\n",
    "            running_mean = branch.bn.running_mean\n",
    "            running_var = branch.bn.running_var\n",
    "            gamma = branch.bn.weight\n",
    "            beta = branch.bn.bias\n",
    "            eps = branch.bn.eps\n",
    "        else:\n",
    "            assert isinstance(branch, nn.BatchNorm2d)\n",
    "            if not hasattr(self, 'id_tensor'):\n",
    "                input_dim = self.in_channels // 1\n",
    "                if self.active_kernel_index>0:\n",
    "                    kernel_value = np.zeros((self.in_channels, input_dim, self.kernel_list[self.active_kernel_index], self.kernel_list[self.active_kernel_index]), dtype=np.float32)\n",
    "                else:\n",
    "                    kernel_value = np.zeros((self.in_channels, input_dim, 1, 1), dtype=np.float32)\n",
    "                for i in range(self.in_channels):\n",
    "                    kernel_value[i, i % input_dim, self.kernel_list[self.active_kernel_index]//2, self.kernel_list[self.active_kernel_index]//2] = 1\n",
    "                self.id_tensor = torch.from_numpy(kernel_value).to(branch.weight.device)\n",
    "            kernel = self.id_tensor\n",
    "            running_mean = branch.running_mean\n",
    "            running_var = branch.running_var\n",
    "            gamma = branch.weight\n",
    "            beta = branch.bias\n",
    "            eps = branch.eps\n",
    "        std = (running_var + eps).sqrt()\n",
    "        t = (gamma / std).reshape(-1, 1, 1, 1)\n",
    "        return kernel * t, beta - running_mean * gamma / std\n",
    "\n",
    "\n",
    "    def get_equivalent_kernel_bias(self):\n",
    " \n",
    "        kernel, bias = self._fuse_bn_tensor(getattr(self, f\"branch_kernel_0\"))\n",
    "    \n",
    "        if kernel is not None:\n",
    "            kernel = kernel * self.scaling_factor\n",
    "            bias   = bias   * self.scaling_factor\n",
    "\n",
    "        \n",
    "        for k in self.kernel_list[1:self.active_kernel_index+1]:\n",
    "            temp_kernel, temp_bias = self._fuse_bn_tensor(getattr(self, f\"branch_kernel_{k}\"))\n",
    "            pld = int((self.kernel_list[self.active_kernel_index]-k)/2)\n",
    "            if pld > 0 :\n",
    "                temp_kernel = torch.nn.functional.pad(temp_kernel, [pld, pld, pld, pld])\n",
    "\n",
    "            kernel = temp_kernel  * self.scaling_factor + kernel\n",
    "            bias   = temp_bias    * self.scaling_factor + bias\n",
    "        \n",
    "\n",
    "        return kernel, bias\n",
    "\n",
    "\n",
    "    def set_active_sample_net_param(self):\n",
    "\n",
    "        for kernel in self.kernel_list:\n",
    "            if getattr(self, f\"branch_kernel_{kernel}\") is not None:\n",
    "                for param in getattr(self, f\"branch_kernel_{kernel}\").parameters():\n",
    "                    param.requires_grad = False\n",
    "        \n",
    "\n",
    "        kernel = self.kernel_list[self.active_kernel_index]\n",
    "        for param in getattr(self, f\"branch_kernel_{kernel}\").parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "    def set_active_sample_all_net_param(self):\n",
    "        # start_index = 0\n",
    "        # if self.stride == 2 or self.out_channels != self.in_channels:\n",
    "        #     start_index = 1\n",
    "        for kernel in self.kernel_list:\n",
    "            if getattr(self, f\"branch_kernel_{kernel}\") is not None:\n",
    "                for param in getattr(self, f\"branch_kernel_{kernel}\").parameters():\n",
    "                    param.requires_grad = False\n",
    "        \n",
    "        for kernel in self.kernel_list[:self.active_kernel_index+1]:\n",
    "            if getattr(self, f\"branch_kernel_{kernel}\") is not None:\n",
    "                for param in getattr(self, f\"branch_kernel_{kernel}\").parameters():\n",
    "                        param.requires_grad = True\n",
    "\n",
    "    def reset_active_net_param(self):\n",
    "\n",
    "        for kernel in self.kernel_list:\n",
    "            if getattr(self, f\"branch_kernel_{kernel}\") is not None:\n",
    "                for param in getattr(self, f\"branch_kernel_{kernel}\").parameters():\n",
    "                    param.requires_grad = True\n",
    "        self.active_kernel_index = len(self.kernel_list)-1 \n",
    "        self.current_run_time_depth = None\n",
    "        \n",
    "\n",
    "    def generate_active_convs(self):\n",
    "        self.active_kernel_index = random.choice(self.kernel_index_range)\n",
    "\n",
    "    def set_active_convs(self, conv_index):\n",
    "        #assert conv_index in self.kernel_index_range\n",
    "        self.active_kernel_index = conv_index\n",
    "        \n",
    "    def set_current_run_time_depth(self, current_run_time_depth):\n",
    "        self.current_run_time_depth = current_run_time_depth\n",
    "\n",
    "    def set_current_runtime_depth_and_kernel(self, \n",
    "                                             current_run_time_depth  = None, \n",
    "                                             kernel_index            = None, \n",
    "                                             \n",
    "                                             random                  = False, \n",
    "                                             all_layers              = False,\n",
    "                                             \n",
    "                                             active_net              = False, \n",
    "                                             active_all_sub_net      = False,\n",
    "                                             \n",
    "                                            ):\n",
    "\n",
    "\n",
    "        for kernel in self.kernel_list:\n",
    "            if getattr(self, f\"branch_kernel_{kernel}\") is not None:\n",
    "                for param in getattr(self, f\"branch_kernel_{kernel}\").parameters():\n",
    "                    param.requires_grad = False\n",
    "\n",
    "        \n",
    "        if kernel_index is None:\n",
    "            assert random == True\n",
    "        else:\n",
    "            assert random == False\n",
    "\n",
    "        if random:\n",
    "            assert kernel_index is None\n",
    "        else:\n",
    "            assert kernel_index is not None\n",
    "            \n",
    "        self.current_run_time_depth = current_run_time_depth\n",
    "\n",
    "        if current_run_time_depth<self.run_time_depth_index:\n",
    "            kernel_index = 0\n",
    "        elif current_run_time_depth == self.run_time_depth_index:\n",
    "            active_net = True\n",
    "        else:\n",
    "            if not all_layers and not random:\n",
    "                kernel_index = len(self.kernel_list)-1 \n",
    "\n",
    "            # --------?----------\n",
    "            if random or all_layers:\n",
    "                if not active_all_sub_net:\n",
    "                    active_net = True\n",
    "\n",
    "\n",
    "        if kernel_index is not None:\n",
    "            if kernel_index == 0:\n",
    "                if self.stride == 2 or self.out_channels != self.in_channels:\n",
    "                    kernel_index = 1\n",
    "                \n",
    "            self.active_kernel_index = kernel_index\n",
    "        else:\n",
    "            self.generate_active_convs()\n",
    "\n",
    "\n",
    "        if current_run_time_depth == self.run_time_depth_index:\n",
    "            if active_net:\n",
    "                self.set_active_sample_net_param()\n",
    "\n",
    "            if active_all_sub_net:\n",
    "                self.set_active_sample_all_net_param()\n",
    "        elif current_run_time_depth>self.run_time_depth_index:\n",
    "            if all_layers or random:\n",
    "                if active_net:\n",
    "                    self.set_active_sample_net_param()\n",
    "    \n",
    "                if active_all_sub_net:\n",
    "                    self.set_active_sample_all_net_param() \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    def switch_to_deploy(self, only_for_weight=False):\n",
    "        \n",
    "\n",
    "            \n",
    "        if hasattr(self, 'conv_reparam'):\n",
    "            return\n",
    "\n",
    "        kernel, bias = self.get_equivalent_kernel_bias()\n",
    "            \n",
    "        if only_for_weight:\n",
    "            return kernel, bias\n",
    "        if self.active_kernel_index>0:\n",
    "            self.conv_reparam = nn.Conv2d(in_channels=self.in_channels, out_channels=self.out_channels,\n",
    "                                         kernel_size=self.kernel_list[self.active_kernel_index], stride=self.stride,\n",
    "                                         padding=self.kernel_list[self.active_kernel_index]//2, dilation=1, groups=1, bias=True)\n",
    "        else:\n",
    "            \n",
    "            self.conv_reparam = nn.Conv2d(in_channels=self.in_channels, out_channels=self.out_channels,\n",
    "                                         kernel_size=1, stride=self.stride,\n",
    "                                         padding=1//2, dilation=1, groups=1, bias=True)\n",
    "        \n",
    "\n",
    "        self.conv_reparam.weight.data = kernel\n",
    "        self.conv_reparam.bias.data = bias\n",
    "        \n",
    "        for para in self.parameters():\n",
    "            para.detach_()\n",
    "            \n",
    "        if hasattr(self, 'id_tensor'):\n",
    "            self.__delattr__('id_tensor')\n",
    "\n",
    "        for k in self.kernel_list:\n",
    "            if hasattr(self, f'branch_kernel_{k}'):\n",
    "                self.__delattr__(f'branch_kernel_{k}')\n",
    "        self.deploy = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609a38c2-2388-4f0a-b212-349739d28e33",
   "metadata": {},
   "source": [
    "### check the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f10875a4-e78f-4ffa-be52-678425435675",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------op.active_kernel_index: 4\n",
      "Parameter name: branch_kernel_1.conv.weight, Shape: torch.Size([256, 256, 1, 1])\n",
      "Parameter name: branch_kernel_1.bn.weight, Shape: torch.Size([256])\n",
      "Parameter name: branch_kernel_1.bn.bias, Shape: torch.Size([256])\n",
      "Parameter name: branch_kernel_3.conv.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Parameter name: branch_kernel_3.bn.weight, Shape: torch.Size([256])\n",
      "Parameter name: branch_kernel_3.bn.bias, Shape: torch.Size([256])\n",
      "Parameter name: branch_kernel_5.conv.weight, Shape: torch.Size([256, 256, 5, 5])\n",
      "Parameter name: branch_kernel_5.bn.weight, Shape: torch.Size([256])\n",
      "Parameter name: branch_kernel_5.bn.bias, Shape: torch.Size([256])\n",
      "Parameter name: branch_kernel_7.conv.weight, Shape: torch.Size([256, 256, 7, 7])\n",
      "Parameter name: branch_kernel_7.bn.weight, Shape: torch.Size([256])\n",
      "Parameter name: branch_kernel_7.bn.bias, Shape: torch.Size([256])\n",
      "-----------------------------SPLIT-------------------------------------\n",
      "---------op.active_kernel_index: 3\n",
      "Parameter name: branch_kernel_5.conv.weight, Shape: torch.Size([256, 256, 5, 5])\n",
      "Parameter name: branch_kernel_5.bn.weight, Shape: torch.Size([256])\n",
      "Parameter name: branch_kernel_5.bn.bias, Shape: torch.Size([256])\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "tensor(3.7795, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# check the nas_rep_block\n",
    "in_channels     = 32\n",
    "out_channels    = 32  #  change here\n",
    "img_size        = 128\n",
    "max_kernel_size = 7\n",
    "stride          = 2   #  change here\n",
    "verbose         = True\n",
    "scaling_factor  = 0.5\n",
    "run_time_depth_index = 1\n",
    "\n",
    "\n",
    "op = NAS_REP_ConvBNBlock(\n",
    "\n",
    "    in_channels          = in_channels,\n",
    "    out_channels         = out_channels,\n",
    "    max_kernel_size      = max_kernel_size,\n",
    "    stride               = stride,\n",
    "    deploy               = False,\n",
    "    verbose              = verbose,\n",
    "    scaling_factor       = scaling_factor,\n",
    "    run_time_depth_index = run_time_depth_index,\n",
    "\n",
    ").to(device)\n",
    "\n",
    "\n",
    "print(\"---------op.active_kernel_index:\",op.active_kernel_index)\n",
    "for name, param in op.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Parameter name: {name}, Shape: {param.shape}\")\n",
    "\n",
    "print(\"-----------------------------SPLIT-------------------------------------\")\n",
    "\n",
    "op.set_current_runtime_depth_and_kernel(\n",
    "\n",
    "    current_run_time_depth=1,          #  change here\n",
    "    kernel_index=3,                    #  change here\n",
    "\n",
    "    random=False,                      #  change here\n",
    "    all_layers=False,                  #  change here\n",
    "    \n",
    "    active_net=False,                  #  change here\n",
    "    active_all_sub_net=False,          #  change here\n",
    ")\n",
    "\n",
    "\n",
    "print(\"---------op.active_kernel_index:\",op.active_kernel_index)\n",
    "for name, param in op.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Parameter name: {name}, Shape: {param.shape}\")\n",
    "        \n",
    "\n",
    "for _ in range(10):\n",
    "    x = torch.randn([1, in_channels, img_size, img_size]).to(device)\n",
    "    y = op(x)\n",
    "\n",
    "op.eval()\n",
    "# check the inference with a random input\n",
    "x = torch.randn([1, in_channels, img_size, img_size]).to(device)\n",
    "\n",
    "\n",
    "y1 = op(x)\n",
    "\n",
    "\n",
    "op.switch_to_deploy()\n",
    "op.to(device)\n",
    "op.eval()\n",
    "\n",
    "\n",
    "y2 = op(x)\n",
    "\n",
    "\n",
    "\n",
    "print(y1.abs().max())\n",
    "print(((y1-y2).abs()).max())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc30fb8-08fd-48aa-8029-02e50f93c0c7",
   "metadata": {},
   "source": [
    "### export the model as ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cbd4c0f-9d4d-4378-8c23-eb261bd511d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------op.active_kernel_index: 4\n",
      "Parameter name: branch_kernel_0.weight, Shape: torch.Size([32])\n",
      "Parameter name: branch_kernel_0.bias, Shape: torch.Size([32])\n",
      "Parameter name: branch_kernel_1.conv.weight, Shape: torch.Size([32, 32, 1, 1])\n",
      "Parameter name: branch_kernel_1.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: branch_kernel_1.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: branch_kernel_3.conv.weight, Shape: torch.Size([32, 32, 3, 3])\n",
      "Parameter name: branch_kernel_3.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: branch_kernel_3.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: branch_kernel_5.conv.weight, Shape: torch.Size([32, 32, 5, 5])\n",
      "Parameter name: branch_kernel_5.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: branch_kernel_5.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: branch_kernel_7.conv.weight, Shape: torch.Size([32, 32, 7, 7])\n",
      "Parameter name: branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "---------op.active_kernel_index: 2\n",
      "Parameter name: branch_kernel_0.weight, Shape: torch.Size([32])\n",
      "Parameter name: branch_kernel_0.bias, Shape: torch.Size([32])\n",
      "Parameter name: branch_kernel_1.conv.weight, Shape: torch.Size([32, 32, 1, 1])\n",
      "Parameter name: branch_kernel_1.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: branch_kernel_1.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: branch_kernel_3.conv.weight, Shape: torch.Size([32, 32, 3, 3])\n",
      "Parameter name: branch_kernel_3.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: branch_kernel_3.bn.bias, Shape: torch.Size([32])\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "-----------\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "-----------\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "-----------\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "-----------\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "-----------\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "-----------\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "-----------\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "-----------\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "-----------\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "-----------\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n"
     ]
    }
   ],
   "source": [
    "# check the nas_rep_block\n",
    "in_channels     = 32\n",
    "out_channels    = 32  #  change here\n",
    "img_size        = 128\n",
    "max_kernel_size = 7\n",
    "stride          = 1   #  change here\n",
    "verbose         = True\n",
    "scaling_factor  = 0.5\n",
    "run_time_depth_index = 1\n",
    "\n",
    "\n",
    "op = NAS_REP_ConvBNBlock(\n",
    "\n",
    "    in_channels          = in_channels,\n",
    "    out_channels         = out_channels,\n",
    "    max_kernel_size      = max_kernel_size,\n",
    "    stride               = stride,\n",
    "    deploy               = False,\n",
    "    verbose              = verbose,\n",
    "    scaling_factor       = scaling_factor,\n",
    "    run_time_depth_index = run_time_depth_index,\n",
    "\n",
    ").to(device)\n",
    "\n",
    "\n",
    "print(\"---------op.active_kernel_index:\",op.active_kernel_index)\n",
    "for name, param in op.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Parameter name: {name}, Shape: {param.shape}\")\n",
    "\n",
    "# print(\"-----------------------------SPLIT-------------------------------------\")\n",
    "\n",
    "op.set_current_runtime_depth_and_kernel(\n",
    "\n",
    "    current_run_time_depth=2,          #  change here\n",
    "    kernel_index=2,                    #  change here\n",
    "\n",
    "    random=False,                      #  change here\n",
    "    all_layers=True,                  #  change here\n",
    "    \n",
    "    active_net=False,                  #  change here\n",
    "    active_all_sub_net=True,          #  change here\n",
    ")\n",
    "\n",
    "\n",
    "print(\"---------op.active_kernel_index:\",op.active_kernel_index)\n",
    "for name, param in op.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Parameter name: {name}, Shape: {param.shape}\")\n",
    "        \n",
    "\n",
    "for _ in range(10):\n",
    "    x = torch.randn([1, in_channels, img_size, img_size]).to(device)\n",
    "    y = op(x)\n",
    "    print(\"-----------\")\n",
    "\n",
    "op.eval()\n",
    "# check the inference with a random input\n",
    "x = torch.randn([1, in_channels, img_size, img_size]).to(device)\n",
    "torch.onnx.export(op,  # model being run\n",
    "                  x,  \n",
    "                  \"before.onnx\",\n",
    "                  export_params=True,  # store the trained parameter weights inside the model file\n",
    "                  # keep_initializers_as_inputs=True,\n",
    "                  # the ONNX version to export the model to\n",
    "                  opset_version=10,\n",
    "                  verbose=False,\n",
    "                  input_names=['input'],  # the model's input names\n",
    "                  output_names=['output'],  # the model's output names\n",
    "                  dynamic_axes={\"input\": {0: \"batch\", 1:\"channel\",2: \"width\",3:\"height\"}}\n",
    "                 )   \n",
    "\n",
    "\n",
    "op.switch_to_deploy()\n",
    "op.to(device)\n",
    "op.eval()\n",
    "\n",
    "torch.onnx.export(op,  # model being run\n",
    "                  x,  \n",
    "                  \"after.onnx\",\n",
    "                  export_params=True,  # store the trained parameter weights inside the model file\n",
    "                  # keep_initializers_as_inputs=True,\n",
    "                  # the ONNX version to export the model to\n",
    "                  opset_version=10,\n",
    "                  verbose=False,\n",
    "                  input_names=['input'],  # the model's input names\n",
    "                  output_names=['output'],  # the model's output names\n",
    "                  dynamic_axes={\"input\": {0: \"batch\", 1:\"channel\",2: \"width\",3:\"height\"}}\n",
    "                 )   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "834123ad-bcbb-461e-a4a8-3ad50ffd8a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op.active_kernel_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738ed727-22d2-4cf3-b3b1-05d94a65235c",
   "metadata": {},
   "source": [
    "### BottleRep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbad04b0-8d91-44e0-95d3-2681a2ebc3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- BackBone ----------------\n",
    "\n",
    "def autopad(k, p=None):  # kernel, padding\n",
    "    # Pad to 'same'\n",
    "    if p is None:\n",
    "        p = k // 2 if isinstance(k, int) else [x // 2 for x in k]  # auto-pad\n",
    "    return p\n",
    "\n",
    "\n",
    "\n",
    "# 2. Residual convolutional block ---> 2 convolutional + skip connection\n",
    "\n",
    "class BottleRep(nn.Module):\n",
    "\n",
    "    def __init__(self, c_in, c_out, max_kernel_size, stride= 1, number_blocks = 2, verbose = False, scaling_factor = 0.5, run_time_depth_index = 0, keep_same_run_time = True, skip_connection=True):\n",
    "        super().__init__()\n",
    "        self.c_in                 = c_in\n",
    "        self.c_out                = c_out\n",
    "        self.keep_same_run_time   = keep_same_run_time\n",
    "        self.skip_connection      = skip_connection\n",
    "        self.run_time_depth_index = run_time_depth_index\n",
    "        self.number_blocks        = number_blocks\n",
    "        if not keep_same_run_time:\n",
    "            self.run_time_depth_index_list = list(range(run_time_depth_index,run_time_depth_index+number_blocks)) \n",
    "        else:\n",
    "            self.run_time_depth_index_list = None\n",
    "\n",
    "\n",
    "        self.current_run_time_depth = None\n",
    "        # because of the residual connection\n",
    "        assert c_in   == c_out\n",
    "        assert stride == 1\n",
    "        \n",
    "        self.number_blocks =number_blocks\n",
    "        for b in range(number_blocks):\n",
    "            setattr(self, f\"conv_block_{b}\", NAS_REP_ConvBNBlock(\n",
    "                c_in,\n",
    "                c_out,\n",
    "                max_kernel_size,\n",
    "                stride, \n",
    "                verbose=verbose,\n",
    "                scaling_factor=scaling_factor, \n",
    "                run_time_depth_index = run_time_depth_index))\n",
    "            if not self.keep_same_run_time:\n",
    "                run_time_depth_index = run_time_depth_index + 1\n",
    "            if b == 0 :\n",
    "                c_in = c_out\n",
    "\n",
    "    def set_same_active_conv_all_blocks(self, conv_index):\n",
    "        for b in range(self.number_blocks):\n",
    "            getattr(self, f\"conv_block_{b}\").set_active_convs(conv_index)\n",
    "            \n",
    "    def activate_sampled_blocks(self):\n",
    "        for b in range(self.number_blocks):\n",
    "            getattr(self, f\"conv_block_{b}\").set_active_net_param()\n",
    "            \n",
    "    def set_random_active_conv(self):\n",
    "        for b in range(self.number_blocks):\n",
    "            getattr(self, f\"conv_block_{b}\").generate_active_convs()\n",
    "\n",
    "\n",
    "    def reset_active_depth_and_conv(self):\n",
    "        for b in range(self.number_blocks):\n",
    "            getattr(self, f\"conv_block_{b}\").reset_active_net_param()\n",
    "        self.current_run_time_depth = None\n",
    "\n",
    "\n",
    "\n",
    "    def set_current_runtime_depth_and_kernel(self, \n",
    "                                             current_run_time_depth  = None, \n",
    "                                             kernel_index            = None, \n",
    "                                             \n",
    "                                             random                  = False, \n",
    "                                             all_layers              = False,\n",
    "                                             \n",
    "                                             active_net              = False, \n",
    "                                             active_all_sub_net      = False,\n",
    "                                             \n",
    "                                            ):\n",
    "\n",
    "\n",
    "        self.current_run_time_depth = current_run_time_depth\n",
    "        \n",
    "        for b in range(self.number_blocks):\n",
    "            getattr(self, f\"conv_block_{b}\").set_current_runtime_depth_and_kernel(current_run_time_depth,    kernel_index,    random, all_layers, active_net, active_all_sub_net)\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        if self.current_run_time_depth is None or self.current_run_time_depth>=self.run_time_depth_index:\n",
    "\n",
    "            residual = x\n",
    "            \n",
    "            for b in range(self.number_blocks):\n",
    "    \n",
    "                x = getattr(self, f\"conv_block_{b}\")(x)\n",
    "\n",
    "            if self.skip_connection:\n",
    "    \n",
    "                return x + residual\n",
    "            else:\n",
    "                return x\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24335fad-64fb-416b-92f1-3f773b88edf2",
   "metadata": {},
   "source": [
    "### check the inference difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5db936f8-f434-40f9-9105-8aeddae8a52a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter name: conv_block_0.branch_kernel_0.weight, Shape: torch.Size([256])\n",
      "Parameter name: conv_block_0.branch_kernel_0.bias, Shape: torch.Size([256])\n",
      "Parameter name: conv_block_0.branch_kernel_1.conv.weight, Shape: torch.Size([256, 256, 1, 1])\n",
      "Parameter name: conv_block_0.branch_kernel_1.bn.weight, Shape: torch.Size([256])\n",
      "Parameter name: conv_block_0.branch_kernel_1.bn.bias, Shape: torch.Size([256])\n",
      "Parameter name: conv_block_0.branch_kernel_3.conv.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Parameter name: conv_block_0.branch_kernel_3.bn.weight, Shape: torch.Size([256])\n",
      "Parameter name: conv_block_0.branch_kernel_3.bn.bias, Shape: torch.Size([256])\n",
      "Parameter name: conv_block_0.branch_kernel_5.conv.weight, Shape: torch.Size([256, 256, 5, 5])\n",
      "Parameter name: conv_block_0.branch_kernel_5.bn.weight, Shape: torch.Size([256])\n",
      "Parameter name: conv_block_0.branch_kernel_5.bn.bias, Shape: torch.Size([256])\n",
      "Parameter name: conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([256, 256, 7, 7])\n",
      "Parameter name: conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([256])\n",
      "Parameter name: conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([256])\n",
      "Parameter name: conv_block_1.branch_kernel_0.weight, Shape: torch.Size([256])\n",
      "Parameter name: conv_block_1.branch_kernel_0.bias, Shape: torch.Size([256])\n",
      "Parameter name: conv_block_1.branch_kernel_1.conv.weight, Shape: torch.Size([256, 256, 1, 1])\n",
      "Parameter name: conv_block_1.branch_kernel_1.bn.weight, Shape: torch.Size([256])\n",
      "Parameter name: conv_block_1.branch_kernel_1.bn.bias, Shape: torch.Size([256])\n",
      "Parameter name: conv_block_1.branch_kernel_3.conv.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Parameter name: conv_block_1.branch_kernel_3.bn.weight, Shape: torch.Size([256])\n",
      "Parameter name: conv_block_1.branch_kernel_3.bn.bias, Shape: torch.Size([256])\n",
      "Parameter name: conv_block_1.branch_kernel_5.conv.weight, Shape: torch.Size([256, 256, 5, 5])\n",
      "Parameter name: conv_block_1.branch_kernel_5.bn.weight, Shape: torch.Size([256])\n",
      "Parameter name: conv_block_1.branch_kernel_5.bn.bias, Shape: torch.Size([256])\n",
      "Parameter name: conv_block_1.branch_kernel_7.conv.weight, Shape: torch.Size([256, 256, 7, 7])\n",
      "Parameter name: conv_block_1.branch_kernel_7.bn.weight, Shape: torch.Size([256])\n",
      "Parameter name: conv_block_1.branch_kernel_7.bn.bias, Shape: torch.Size([256])\n",
      "Parameter name: conv_block_2.branch_kernel_0.weight, Shape: torch.Size([256])\n",
      "Parameter name: conv_block_2.branch_kernel_0.bias, Shape: torch.Size([256])\n",
      "Parameter name: conv_block_2.branch_kernel_1.conv.weight, Shape: torch.Size([256, 256, 1, 1])\n",
      "Parameter name: conv_block_2.branch_kernel_1.bn.weight, Shape: torch.Size([256])\n",
      "Parameter name: conv_block_2.branch_kernel_1.bn.bias, Shape: torch.Size([256])\n",
      "Parameter name: conv_block_2.branch_kernel_3.conv.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Parameter name: conv_block_2.branch_kernel_3.bn.weight, Shape: torch.Size([256])\n",
      "Parameter name: conv_block_2.branch_kernel_3.bn.bias, Shape: torch.Size([256])\n",
      "Parameter name: conv_block_2.branch_kernel_5.conv.weight, Shape: torch.Size([256, 256, 5, 5])\n",
      "Parameter name: conv_block_2.branch_kernel_5.bn.weight, Shape: torch.Size([256])\n",
      "Parameter name: conv_block_2.branch_kernel_5.bn.bias, Shape: torch.Size([256])\n",
      "Parameter name: conv_block_2.branch_kernel_7.conv.weight, Shape: torch.Size([256, 256, 7, 7])\n",
      "Parameter name: conv_block_2.branch_kernel_7.bn.weight, Shape: torch.Size([256])\n",
      "Parameter name: conv_block_2.branch_kernel_7.bn.bias, Shape: torch.Size([256])\n",
      "-----------------------------SPLIT-------------------------------------\n",
      "Parameter name: conv_block_0.branch_kernel_0.weight, Shape: torch.Size([256])\n",
      "Parameter name: conv_block_0.branch_kernel_0.bias, Shape: torch.Size([256])\n",
      "Parameter name: conv_block_0.branch_kernel_1.conv.weight, Shape: torch.Size([256, 256, 1, 1])\n",
      "Parameter name: conv_block_0.branch_kernel_1.bn.weight, Shape: torch.Size([256])\n",
      "Parameter name: conv_block_0.branch_kernel_1.bn.bias, Shape: torch.Size([256])\n",
      "Parameter name: conv_block_0.branch_kernel_3.conv.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Parameter name: conv_block_0.branch_kernel_3.bn.weight, Shape: torch.Size([256])\n",
      "Parameter name: conv_block_0.branch_kernel_3.bn.bias, Shape: torch.Size([256])\n",
      "Parameter name: conv_block_0.branch_kernel_5.conv.weight, Shape: torch.Size([256, 256, 5, 5])\n",
      "Parameter name: conv_block_0.branch_kernel_5.bn.weight, Shape: torch.Size([256])\n",
      "Parameter name: conv_block_0.branch_kernel_5.bn.bias, Shape: torch.Size([256])\n",
      "Parameter name: conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([256, 256, 7, 7])\n",
      "Parameter name: conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([256])\n",
      "Parameter name: conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([256])\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "tensor(9.9104, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# check the nas_rep_block\n",
    "in_channels     = 32\n",
    "out_channels    = 32  #  change here\n",
    "img_size        = 128\n",
    "max_kernel_size = 7\n",
    "stride          = 1   #  change here\n",
    "verbose         = True\n",
    "scaling_factor  = 0.5\n",
    "run_time_depth_index = 1\n",
    "keep_same_run_time   = False\n",
    "skip_connection      = True\n",
    "number_blocks        = 3\n",
    "\n",
    "op = BottleRep(\n",
    "\n",
    "    c_in                      = in_channels,\n",
    "    c_out                     = out_channels,\n",
    "    max_kernel_size           = max_kernel_size,\n",
    "    stride                    = 1,\n",
    "    number_blocks             = number_blocks,\n",
    "    verbose                   = verbose,\n",
    "    scaling_factor            = scaling_factor,\n",
    "    run_time_depth_index      = run_time_depth_index,\n",
    "    keep_same_run_time        = keep_same_run_time,\n",
    "    skip_connection           = skip_connection,\n",
    "\n",
    ").to(device)\n",
    "\n",
    "\n",
    "\n",
    "for name, param in op.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Parameter name: {name}, Shape: {param.shape}\")\n",
    "\n",
    "print(\"-----------------------------SPLIT-------------------------------------\")\n",
    "\n",
    "op.set_current_runtime_depth_and_kernel(\n",
    "\n",
    "    current_run_time_depth=1,          #  change here\n",
    "    kernel_index=4,                    #  change here\n",
    "\n",
    "    random=False,                      #  change here\n",
    "    all_layers=False,                  #  change here\n",
    "    \n",
    "    active_net=False,                  #  change here\n",
    "    active_all_sub_net=True,          #  change here\n",
    ")\n",
    "\n",
    "\n",
    "for name, param in op.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Parameter name: {name}, Shape: {param.shape}\")\n",
    "        \n",
    "\n",
    "for _ in range(10):\n",
    "    x = torch.randn([1, in_channels, img_size, img_size]).to(device)\n",
    "    y = op(x)\n",
    "\n",
    "op.eval()\n",
    "# check the inference with a random input\n",
    "x = torch.randn([1, in_channels, img_size, img_size]).to(device)\n",
    "\n",
    "\n",
    "y1 = op(x)\n",
    "\n",
    "\n",
    "op_rep= rep_model_convert(op, do_copy=False)\n",
    "op_rep.to(device)\n",
    "op_rep.eval()\n",
    "\n",
    "\n",
    "y2 = op_rep(x)\n",
    "\n",
    "\n",
    "\n",
    "print(y1.abs().max())\n",
    "print(((y1-y2).abs()).max())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c20f71c-68d6-4e25-8cc6-0f51cfcd35d5",
   "metadata": {},
   "source": [
    "### Export the ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96a5554d-57bd-49ba-ac5f-e91a7ea422e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter name: conv_block_0.branch_kernel_0.weight, Shape: torch.Size([32])\n",
      "Parameter name: conv_block_0.branch_kernel_0.bias, Shape: torch.Size([32])\n",
      "Parameter name: conv_block_0.branch_kernel_1.conv.weight, Shape: torch.Size([32, 32, 1, 1])\n",
      "Parameter name: conv_block_0.branch_kernel_1.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: conv_block_0.branch_kernel_1.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: conv_block_0.branch_kernel_3.conv.weight, Shape: torch.Size([32, 32, 3, 3])\n",
      "Parameter name: conv_block_0.branch_kernel_3.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: conv_block_0.branch_kernel_3.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: conv_block_1.branch_kernel_0.weight, Shape: torch.Size([32])\n",
      "Parameter name: conv_block_1.branch_kernel_0.bias, Shape: torch.Size([32])\n",
      "Parameter name: conv_block_1.branch_kernel_1.conv.weight, Shape: torch.Size([32, 32, 1, 1])\n",
      "Parameter name: conv_block_1.branch_kernel_1.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: conv_block_1.branch_kernel_1.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: conv_block_1.branch_kernel_3.conv.weight, Shape: torch.Size([32, 32, 3, 3])\n",
      "Parameter name: conv_block_1.branch_kernel_3.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: conv_block_1.branch_kernel_3.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: conv_block_2.branch_kernel_0.weight, Shape: torch.Size([32])\n",
      "Parameter name: conv_block_2.branch_kernel_0.bias, Shape: torch.Size([32])\n",
      "Parameter name: conv_block_2.branch_kernel_1.conv.weight, Shape: torch.Size([32, 32, 1, 1])\n",
      "Parameter name: conv_block_2.branch_kernel_1.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: conv_block_2.branch_kernel_1.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: conv_block_2.branch_kernel_3.conv.weight, Shape: torch.Size([32, 32, 3, 3])\n",
      "Parameter name: conv_block_2.branch_kernel_3.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: conv_block_2.branch_kernel_3.bn.bias, Shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# check the nas_rep_block\n",
    "in_channels     = 32\n",
    "out_channels    = 32  #  change here\n",
    "img_size        = 128\n",
    "max_kernel_size = 5\n",
    "stride          = 1   #  change here\n",
    "verbose         = True\n",
    "scaling_factor  = 0.5\n",
    "run_time_depth_index = 1\n",
    "keep_same_run_time   = False\n",
    "skip_connection      = True\n",
    "number_blocks        = 3\n",
    "\n",
    "op = BottleRep(\n",
    "\n",
    "    c_in                      = in_channels,\n",
    "    c_out                     = out_channels,\n",
    "    max_kernel_size           = max_kernel_size,\n",
    "    stride                    = 1,\n",
    "    number_blocks             = number_blocks,\n",
    "    verbose                   = verbose,\n",
    "    scaling_factor            = scaling_factor,\n",
    "    run_time_depth_index      = run_time_depth_index,\n",
    "    keep_same_run_time        = keep_same_run_time,\n",
    "    skip_connection           = skip_connection,\n",
    "\n",
    ").to(device)\n",
    "\n",
    "\n",
    "\n",
    "# for name, param in op.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(f\"Parameter name: {name}, Shape: {param.shape}\")\n",
    "\n",
    "# print(\"-----------------------------SPLIT-------------------------------------\")\n",
    "\n",
    "op.set_current_runtime_depth_and_kernel(\n",
    "\n",
    "    current_run_time_depth=3,          #  change here\n",
    "    kernel_index=2,                    #  change here\n",
    "\n",
    "    random=False,                      #  change here\n",
    "    all_layers=True,                  #  change here\n",
    "    \n",
    "    active_net=False,                  #  change here\n",
    "    active_all_sub_net=True,          #  change here\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "for name, param in op.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Parameter name: {name}, Shape: {param.shape}\")\n",
    "        \n",
    "# print(\"-----------------------------SPLIT-------------------------------------\")\n",
    "\n",
    "# for _ in range(10):\n",
    "#     x = torch.randn([1, in_channels, img_size, img_size]).to(device)\n",
    "#     y = op(x)\n",
    "\n",
    "# op.eval()\n",
    "# # check the inference with a random input\n",
    "# x = torch.randn([1, in_channels, img_size, img_size]).to(device)\n",
    "# torch.onnx.export(op,  # model being run\n",
    "#                   x,  \n",
    "#                   \"before.onnx\",\n",
    "#                   export_params=True,  # store the trained parameter weights inside the model file\n",
    "#                   # keep_initializers_as_inputs=True,\n",
    "#                   # the ONNX version to export the model to\n",
    "#                   opset_version=10,\n",
    "#                   verbose=False,\n",
    "#                   input_names=['input'],  # the model's input names\n",
    "#                   output_names=['output'],  # the model's output names\n",
    "#                   dynamic_axes={\"input\": {0: \"batch\", 1:\"channel\",2: \"width\",3:\"height\"}}\n",
    "#                  )   \n",
    "\n",
    "\n",
    "# op_rep= rep_model_convert(op, do_copy=False)\n",
    "# op_rep.to(device)\n",
    "# op_rep.eval()\n",
    "\n",
    "# torch.onnx.export(op_rep,  # model being run\n",
    "#                   x,  \n",
    "#                   \"after.onnx\",\n",
    "#                   export_params=True,  # store the trained parameter weights inside the model file\n",
    "#                   # keep_initializers_as_inputs=True,\n",
    "#                   # the ONNX version to export the model to\n",
    "#                   opset_version=10,\n",
    "#                   verbose=False,\n",
    "#                   input_names=['input'],  # the model's input names\n",
    "#                   output_names=['output'],  # the model's output names\n",
    "#                   dynamic_axes={\"input\": {0: \"batch\", 1:\"channel\",2: \"width\",3:\"height\"}}\n",
    "#                  )   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1eff837-9931-4046-a27b-b97694344ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op.conv_block_0.run_time_depth_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ad1da53-5a81-4b81-8ae5-1e99439eec1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op.conv_block_1.run_time_depth_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "285bfbfa-326d-479d-84b0-7aea7faaebe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op.conv_block_2.run_time_depth_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefddaf1-b0d4-4464-9533-52d46f887e0d",
   "metadata": {},
   "source": [
    "### RepBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9715b0e8-da53-4e08-813c-dba251bdd203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. multiplt Residual convolutional block\n",
    "\n",
    "class RepBlock(nn.Module):\n",
    "    '''\n",
    "        RepBlock is a stage block with rep-style basic block\n",
    "    '''\n",
    "    def __init__(self,   c_in,   c_out,  max_kernel_size,  stride=1, number_BottleRep = 4, number_blocks_list = None, verbose=False, scaling_factor=0.5, run_time_depth_index=0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.c_in = c_in\n",
    "        self.c_out = c_out\n",
    "        self.verbose = verbose\n",
    "        assert c_in == c_out\n",
    "        assert stride == 1\n",
    "        self.max_kernel_size = max_kernel_size\n",
    "        self.number_BottleRep = number_BottleRep\n",
    "        \n",
    "        self.run_time_depth_index = run_time_depth_index\n",
    "\n",
    "        \n",
    "        self.run_time_depth_index_list = list(range(run_time_depth_index,run_time_depth_index+number_BottleRep)) \n",
    "\n",
    "\n",
    "        self.current_run_time_depth = None\n",
    "\n",
    "        if number_blocks_list is None:\n",
    "            self.number_blocks_list = [2] * number_BottleRep\n",
    "        else:\n",
    "            assert len(number_blocks_list) == number_BottleRep\n",
    "            self.number_blocks_list = number_blocks_list\n",
    "        \n",
    "        self.log(\"number_blocks_list\" + str(self.number_blocks_list))\n",
    "\n",
    "        run_time_depth_start_index = run_time_depth_index\n",
    "        for b in range(number_BottleRep):\n",
    "            setattr(self, f\"BottleRep_{b}\", BottleRep(c_in,\n",
    "                                                      c_out,\n",
    "                                                      max_kernel_size,\n",
    "                                                      stride, \n",
    "                                                      number_blocks = self.number_blocks_list[b],\n",
    "                                                      verbose = verbose,\n",
    "                                                      scaling_factor = scaling_factor,\n",
    "                                                      run_time_depth_index = run_time_depth_start_index))\n",
    "            run_time_depth_start_index = run_time_depth_start_index + 1\n",
    "\n",
    "        \n",
    "    def reset_active_depth_and_conv(self):\n",
    "\n",
    "\n",
    "        for b in list(range(self.number_BottleRep)):\n",
    "\n",
    "            getattr(self, f\"BottleRep_{b}\").reset_active_depth_and_conv()\n",
    "\n",
    "\n",
    "        self.current_run_time_depth = None\n",
    "\n",
    "\n",
    "\n",
    "    def set_current_runtime_depth_and_kernel(self, \n",
    "                                             current_run_time_depth  = None, \n",
    "                                             kernel_index            = None, \n",
    "                                             \n",
    "                                             random                  = False, \n",
    "                                             all_layers              = False,\n",
    "                                             \n",
    "                                             active_net              = False, \n",
    "                                             active_all_sub_net      = False,\n",
    "                                             \n",
    "                                            ):\n",
    "\n",
    "\n",
    "        self.current_run_time_depth = current_run_time_depth\n",
    "        for b in range(self.number_BottleRep):\n",
    "                getattr(self, f\"BottleRep_{b}\").set_current_runtime_depth_and_kernel(\n",
    "                    current_run_time_depth, \n",
    "                    kernel_index, \n",
    "                    \n",
    "                    random,\n",
    "                    all_layers,\n",
    "\n",
    "                    active_net,\n",
    "                    active_all_sub_net\n",
    "                )\n",
    "        \n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        if self.current_run_time_depth is None or self.current_run_time_depth >= max(self.run_time_depth_index_list): \n",
    "\n",
    "            for b in list(range(self.number_BottleRep)):\n",
    "    \n",
    "                x = getattr(self, f\"BottleRep_{b}\")(x)\n",
    "            return x\n",
    "\n",
    "        elif self.current_run_time_depth in self.run_time_depth_index_list:\n",
    "            for b in list(range(self.number_BottleRep))[:self.run_time_depth_index_list.index(self.current_run_time_depth)+1]:\n",
    "    \n",
    "                x = getattr(self, f\"BottleRep_{b}\")(x)\n",
    "\n",
    "            return x\n",
    "        else:\n",
    "            return x\n",
    "        \n",
    "\n",
    "    def log(self, message):\n",
    "        if self.verbose:\n",
    "            print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e8d55d-6c5c-4de4-848b-48b199e64992",
   "metadata": {},
   "source": [
    "### Check the inference difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b7a65f3-e8f7-468b-876b-75dffef8e939",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_blocks_list[2, 2, 2, 2]\n",
      "Parameter name: BottleRep_0.conv_block_0.branch_kernel_0.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_0.conv_block_0.branch_kernel_0.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_0.conv_block_0.branch_kernel_1.conv.weight, Shape: torch.Size([32, 32, 1, 1])\n",
      "Parameter name: BottleRep_0.conv_block_0.branch_kernel_1.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_0.conv_block_0.branch_kernel_1.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_0.conv_block_0.branch_kernel_3.conv.weight, Shape: torch.Size([32, 32, 3, 3])\n",
      "Parameter name: BottleRep_0.conv_block_0.branch_kernel_3.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_0.conv_block_0.branch_kernel_3.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_0.conv_block_0.branch_kernel_5.conv.weight, Shape: torch.Size([32, 32, 5, 5])\n",
      "Parameter name: BottleRep_0.conv_block_0.branch_kernel_5.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_0.conv_block_0.branch_kernel_5.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_0.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([32, 32, 7, 7])\n",
      "Parameter name: BottleRep_0.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_0.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_0.conv_block_1.branch_kernel_0.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_0.conv_block_1.branch_kernel_0.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_0.conv_block_1.branch_kernel_1.conv.weight, Shape: torch.Size([32, 32, 1, 1])\n",
      "Parameter name: BottleRep_0.conv_block_1.branch_kernel_1.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_0.conv_block_1.branch_kernel_1.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_0.conv_block_1.branch_kernel_3.conv.weight, Shape: torch.Size([32, 32, 3, 3])\n",
      "Parameter name: BottleRep_0.conv_block_1.branch_kernel_3.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_0.conv_block_1.branch_kernel_3.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_0.conv_block_1.branch_kernel_5.conv.weight, Shape: torch.Size([32, 32, 5, 5])\n",
      "Parameter name: BottleRep_0.conv_block_1.branch_kernel_5.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_0.conv_block_1.branch_kernel_5.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_0.conv_block_1.branch_kernel_7.conv.weight, Shape: torch.Size([32, 32, 7, 7])\n",
      "Parameter name: BottleRep_0.conv_block_1.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_0.conv_block_1.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_1.conv_block_0.branch_kernel_0.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_1.conv_block_0.branch_kernel_0.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_1.conv_block_0.branch_kernel_1.conv.weight, Shape: torch.Size([32, 32, 1, 1])\n",
      "Parameter name: BottleRep_1.conv_block_0.branch_kernel_1.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_1.conv_block_0.branch_kernel_1.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_1.conv_block_0.branch_kernel_3.conv.weight, Shape: torch.Size([32, 32, 3, 3])\n",
      "Parameter name: BottleRep_1.conv_block_0.branch_kernel_3.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_1.conv_block_0.branch_kernel_3.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_1.conv_block_0.branch_kernel_5.conv.weight, Shape: torch.Size([32, 32, 5, 5])\n",
      "Parameter name: BottleRep_1.conv_block_0.branch_kernel_5.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_1.conv_block_0.branch_kernel_5.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_1.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([32, 32, 7, 7])\n",
      "Parameter name: BottleRep_1.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_1.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_1.conv_block_1.branch_kernel_0.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_1.conv_block_1.branch_kernel_0.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_1.conv_block_1.branch_kernel_1.conv.weight, Shape: torch.Size([32, 32, 1, 1])\n",
      "Parameter name: BottleRep_1.conv_block_1.branch_kernel_1.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_1.conv_block_1.branch_kernel_1.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_1.conv_block_1.branch_kernel_3.conv.weight, Shape: torch.Size([32, 32, 3, 3])\n",
      "Parameter name: BottleRep_1.conv_block_1.branch_kernel_3.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_1.conv_block_1.branch_kernel_3.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_1.conv_block_1.branch_kernel_5.conv.weight, Shape: torch.Size([32, 32, 5, 5])\n",
      "Parameter name: BottleRep_1.conv_block_1.branch_kernel_5.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_1.conv_block_1.branch_kernel_5.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_1.conv_block_1.branch_kernel_7.conv.weight, Shape: torch.Size([32, 32, 7, 7])\n",
      "Parameter name: BottleRep_1.conv_block_1.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_1.conv_block_1.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_2.conv_block_0.branch_kernel_0.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_2.conv_block_0.branch_kernel_0.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_2.conv_block_0.branch_kernel_1.conv.weight, Shape: torch.Size([32, 32, 1, 1])\n",
      "Parameter name: BottleRep_2.conv_block_0.branch_kernel_1.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_2.conv_block_0.branch_kernel_1.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_2.conv_block_0.branch_kernel_3.conv.weight, Shape: torch.Size([32, 32, 3, 3])\n",
      "Parameter name: BottleRep_2.conv_block_0.branch_kernel_3.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_2.conv_block_0.branch_kernel_3.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_2.conv_block_0.branch_kernel_5.conv.weight, Shape: torch.Size([32, 32, 5, 5])\n",
      "Parameter name: BottleRep_2.conv_block_0.branch_kernel_5.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_2.conv_block_0.branch_kernel_5.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_2.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([32, 32, 7, 7])\n",
      "Parameter name: BottleRep_2.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_2.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_2.conv_block_1.branch_kernel_0.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_2.conv_block_1.branch_kernel_0.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_2.conv_block_1.branch_kernel_1.conv.weight, Shape: torch.Size([32, 32, 1, 1])\n",
      "Parameter name: BottleRep_2.conv_block_1.branch_kernel_1.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_2.conv_block_1.branch_kernel_1.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_2.conv_block_1.branch_kernel_3.conv.weight, Shape: torch.Size([32, 32, 3, 3])\n",
      "Parameter name: BottleRep_2.conv_block_1.branch_kernel_3.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_2.conv_block_1.branch_kernel_3.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_2.conv_block_1.branch_kernel_5.conv.weight, Shape: torch.Size([32, 32, 5, 5])\n",
      "Parameter name: BottleRep_2.conv_block_1.branch_kernel_5.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_2.conv_block_1.branch_kernel_5.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_2.conv_block_1.branch_kernel_7.conv.weight, Shape: torch.Size([32, 32, 7, 7])\n",
      "Parameter name: BottleRep_2.conv_block_1.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_2.conv_block_1.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_3.conv_block_0.branch_kernel_0.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_3.conv_block_0.branch_kernel_0.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_3.conv_block_0.branch_kernel_1.conv.weight, Shape: torch.Size([32, 32, 1, 1])\n",
      "Parameter name: BottleRep_3.conv_block_0.branch_kernel_1.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_3.conv_block_0.branch_kernel_1.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_3.conv_block_0.branch_kernel_3.conv.weight, Shape: torch.Size([32, 32, 3, 3])\n",
      "Parameter name: BottleRep_3.conv_block_0.branch_kernel_3.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_3.conv_block_0.branch_kernel_3.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_3.conv_block_0.branch_kernel_5.conv.weight, Shape: torch.Size([32, 32, 5, 5])\n",
      "Parameter name: BottleRep_3.conv_block_0.branch_kernel_5.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_3.conv_block_0.branch_kernel_5.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_3.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([32, 32, 7, 7])\n",
      "Parameter name: BottleRep_3.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_3.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_3.conv_block_1.branch_kernel_0.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_3.conv_block_1.branch_kernel_0.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_3.conv_block_1.branch_kernel_1.conv.weight, Shape: torch.Size([32, 32, 1, 1])\n",
      "Parameter name: BottleRep_3.conv_block_1.branch_kernel_1.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_3.conv_block_1.branch_kernel_1.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_3.conv_block_1.branch_kernel_3.conv.weight, Shape: torch.Size([32, 32, 3, 3])\n",
      "Parameter name: BottleRep_3.conv_block_1.branch_kernel_3.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_3.conv_block_1.branch_kernel_3.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_3.conv_block_1.branch_kernel_5.conv.weight, Shape: torch.Size([32, 32, 5, 5])\n",
      "Parameter name: BottleRep_3.conv_block_1.branch_kernel_5.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_3.conv_block_1.branch_kernel_5.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_3.conv_block_1.branch_kernel_7.conv.weight, Shape: torch.Size([32, 32, 7, 7])\n",
      "Parameter name: BottleRep_3.conv_block_1.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_3.conv_block_1.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "-----------------------------SPLIT-------------------------------------\n",
      "Parameter name: BottleRep_0.conv_block_0.branch_kernel_0.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_0.conv_block_0.branch_kernel_0.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_0.conv_block_0.branch_kernel_1.conv.weight, Shape: torch.Size([32, 32, 1, 1])\n",
      "Parameter name: BottleRep_0.conv_block_0.branch_kernel_1.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_0.conv_block_0.branch_kernel_1.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_0.conv_block_1.branch_kernel_0.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_0.conv_block_1.branch_kernel_0.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_0.conv_block_1.branch_kernel_1.conv.weight, Shape: torch.Size([32, 32, 1, 1])\n",
      "Parameter name: BottleRep_0.conv_block_1.branch_kernel_1.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_0.conv_block_1.branch_kernel_1.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_0.conv_block_1.branch_kernel_3.conv.weight, Shape: torch.Size([32, 32, 3, 3])\n",
      "Parameter name: BottleRep_0.conv_block_1.branch_kernel_3.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_0.conv_block_1.branch_kernel_3.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_0.conv_block_1.branch_kernel_5.conv.weight, Shape: torch.Size([32, 32, 5, 5])\n",
      "Parameter name: BottleRep_0.conv_block_1.branch_kernel_5.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_0.conv_block_1.branch_kernel_5.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_1.conv_block_0.branch_kernel_0.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_1.conv_block_0.branch_kernel_0.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_1.conv_block_0.branch_kernel_1.conv.weight, Shape: torch.Size([32, 32, 1, 1])\n",
      "Parameter name: BottleRep_1.conv_block_0.branch_kernel_1.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_1.conv_block_0.branch_kernel_1.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_1.conv_block_0.branch_kernel_3.conv.weight, Shape: torch.Size([32, 32, 3, 3])\n",
      "Parameter name: BottleRep_1.conv_block_0.branch_kernel_3.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_1.conv_block_0.branch_kernel_3.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_1.conv_block_0.branch_kernel_5.conv.weight, Shape: torch.Size([32, 32, 5, 5])\n",
      "Parameter name: BottleRep_1.conv_block_0.branch_kernel_5.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_1.conv_block_0.branch_kernel_5.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_1.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([32, 32, 7, 7])\n",
      "Parameter name: BottleRep_1.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_1.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_1.conv_block_1.branch_kernel_0.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_1.conv_block_1.branch_kernel_0.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_2.conv_block_0.branch_kernel_0.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_2.conv_block_0.branch_kernel_0.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_2.conv_block_1.branch_kernel_0.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_2.conv_block_1.branch_kernel_0.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_2.conv_block_1.branch_kernel_1.conv.weight, Shape: torch.Size([32, 32, 1, 1])\n",
      "Parameter name: BottleRep_2.conv_block_1.branch_kernel_1.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_2.conv_block_1.branch_kernel_1.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_2.conv_block_1.branch_kernel_3.conv.weight, Shape: torch.Size([32, 32, 3, 3])\n",
      "Parameter name: BottleRep_2.conv_block_1.branch_kernel_3.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_2.conv_block_1.branch_kernel_3.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_2.conv_block_1.branch_kernel_5.conv.weight, Shape: torch.Size([32, 32, 5, 5])\n",
      "Parameter name: BottleRep_2.conv_block_1.branch_kernel_5.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_2.conv_block_1.branch_kernel_5.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_3.conv_block_0.branch_kernel_0.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_3.conv_block_0.branch_kernel_0.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_3.conv_block_0.branch_kernel_1.conv.weight, Shape: torch.Size([32, 32, 1, 1])\n",
      "Parameter name: BottleRep_3.conv_block_0.branch_kernel_1.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_3.conv_block_0.branch_kernel_1.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_3.conv_block_0.branch_kernel_3.conv.weight, Shape: torch.Size([32, 32, 3, 3])\n",
      "Parameter name: BottleRep_3.conv_block_0.branch_kernel_3.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_3.conv_block_0.branch_kernel_3.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_3.conv_block_0.branch_kernel_5.conv.weight, Shape: torch.Size([32, 32, 5, 5])\n",
      "Parameter name: BottleRep_3.conv_block_0.branch_kernel_5.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_3.conv_block_0.branch_kernel_5.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_3.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([32, 32, 7, 7])\n",
      "Parameter name: BottleRep_3.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_3.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_3.conv_block_1.branch_kernel_0.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_3.conv_block_1.branch_kernel_0.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_3.conv_block_1.branch_kernel_1.conv.weight, Shape: torch.Size([32, 32, 1, 1])\n",
      "Parameter name: BottleRep_3.conv_block_1.branch_kernel_1.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_3.conv_block_1.branch_kernel_1.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_3.conv_block_1.branch_kernel_3.conv.weight, Shape: torch.Size([32, 32, 3, 3])\n",
      "Parameter name: BottleRep_3.conv_block_1.branch_kernel_3.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_3.conv_block_1.branch_kernel_3.bn.bias, Shape: torch.Size([32])\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_0\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_0\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_0\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_0\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_0\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_0\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_0\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_0\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_0\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_0\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_0\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "tensor(15.0766, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0043, device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# check the nas_rep_block\n",
    "in_channels     = 32\n",
    "out_channels    = 32  #  change here\n",
    "img_size        = 128\n",
    "max_kernel_size = 7\n",
    "stride          = 1   #  change here\n",
    "verbose         = True\n",
    "scaling_factor  = 0.5\n",
    "run_time_depth_index = 1\n",
    "number_BottleRep     = 4\n",
    "\n",
    "\n",
    "op = RepBlock(\n",
    "\n",
    "    \n",
    "    c_in                      = in_channels,\n",
    "    c_out                     = out_channels,\n",
    "    max_kernel_size           = max_kernel_size,\n",
    "    stride                    = 1,\n",
    "    number_BottleRep          = number_BottleRep,\n",
    "    number_blocks_list        = None,\n",
    "    verbose                   = verbose,\n",
    "    scaling_factor            = scaling_factor,\n",
    "    run_time_depth_index      = run_time_depth_index,\n",
    "\n",
    "\n",
    ").to(device)\n",
    "\n",
    "\n",
    "\n",
    "for name, param in op.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Parameter name: {name}, Shape: {param.shape}\")\n",
    "\n",
    "print(\"-----------------------------SPLIT-------------------------------------\")\n",
    "\n",
    "op.set_current_runtime_depth_and_kernel(\n",
    "\n",
    "    current_run_time_depth=10,          #  change here\n",
    "    kernel_index=None,                    #  change here\n",
    "\n",
    "    random=True,                      #  change here\n",
    "    all_layers=False,                  #  change here\n",
    "    \n",
    "    active_net=False,                  #  change here\n",
    "    active_all_sub_net=True,          #  change here\n",
    ")\n",
    "\n",
    "\n",
    "for name, param in op.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Parameter name: {name}, Shape: {param.shape}\")\n",
    "        \n",
    "\n",
    "for _ in range(10):\n",
    "    x = torch.randn([1, in_channels, img_size, img_size]).to(device)\n",
    "    y = op(x)\n",
    "\n",
    "op.eval()\n",
    "# check the inference with a random input\n",
    "x = torch.randn([1, in_channels, img_size, img_size]).to(device)\n",
    "\n",
    "\n",
    "y1 = op(x)\n",
    "\n",
    "\n",
    "op_rep= rep_model_convert(op, do_copy=False)\n",
    "op_rep.to(device)\n",
    "op_rep.eval()\n",
    "\n",
    "\n",
    "y2 = op_rep(x)\n",
    "\n",
    "\n",
    "\n",
    "print(y1.abs().max())\n",
    "print(((y1-y2).abs()).max())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b881394-f556-485a-8ad3-6bcbef7bf45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2f4979-ce10-4e32-9ade-cf9b659db86c",
   "metadata": {},
   "source": [
    "### Export ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d55797c0-0727-4e66-a02c-9c7bd4ef407d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_blocks_list[3, 5, 3]\n",
      "-----------------------------SPLIT-------------------------------------\n",
      "Parameter name: BottleRep_0.conv_block_0.branch_kernel_5.conv.weight, Shape: torch.Size([32, 32, 5, 5])\n",
      "Parameter name: BottleRep_0.conv_block_0.branch_kernel_5.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_0.conv_block_0.branch_kernel_5.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_0.conv_block_1.branch_kernel_5.conv.weight, Shape: torch.Size([32, 32, 5, 5])\n",
      "Parameter name: BottleRep_0.conv_block_1.branch_kernel_5.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_0.conv_block_1.branch_kernel_5.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_0.conv_block_2.branch_kernel_5.conv.weight, Shape: torch.Size([32, 32, 5, 5])\n",
      "Parameter name: BottleRep_0.conv_block_2.branch_kernel_5.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: BottleRep_0.conv_block_2.branch_kernel_5.bn.bias, Shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "# check the nas_rep_block\n",
    "in_channels     = 32\n",
    "out_channels    = 32  #  change here\n",
    "img_size        = 128\n",
    "max_kernel_size = 5\n",
    "stride          = 1   #  change here\n",
    "verbose         = True\n",
    "scaling_factor  = 0.5\n",
    "run_time_depth_index = 1\n",
    "number_BottleRep     = 3\n",
    "\n",
    "\n",
    "op = RepBlock(\n",
    "\n",
    "    \n",
    "    c_in                      = in_channels,\n",
    "    c_out                     = out_channels,\n",
    "    max_kernel_size           = max_kernel_size,\n",
    "    stride                    = 1,\n",
    "    number_BottleRep          = number_BottleRep,\n",
    "    number_blocks_list        = [3,5,3],\n",
    "    verbose                   = verbose,\n",
    "    scaling_factor            = scaling_factor,\n",
    "    run_time_depth_index      = run_time_depth_index,\n",
    "\n",
    "\n",
    ").to(device)\n",
    "\n",
    "\n",
    "# for name, param in op.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(f\"Parameter name: {name}, Shape: {param.shape}\")\n",
    "\n",
    "print(\"-----------------------------SPLIT-------------------------------------\")\n",
    "\n",
    "op.set_current_runtime_depth_and_kernel(\n",
    "\n",
    "    current_run_time_depth=1,          #  change here\n",
    "    kernel_index=3,                    #  change here\n",
    "\n",
    "    random=False,                      #  change here\n",
    "    all_layers=False,                  #  change here\n",
    "    \n",
    "    active_net=False,                  #  change here\n",
    "    active_all_sub_net=False,          #  change here\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "for name, param in op.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Parameter name: {name}, Shape: {param.shape}\")\n",
    "        \n",
    "# print(\"-----------------------------SPLIT-------------------------------------\")\n",
    "\n",
    "# for _ in range(10):\n",
    "#     x = torch.randn([1, in_channels, img_size, img_size]).to(device)\n",
    "#     y = op(x)\n",
    "\n",
    "# op.eval()\n",
    "# # check the inference with a random input\n",
    "# x = torch.randn([1, in_channels, img_size, img_size]).to(device)\n",
    "# torch.onnx.export(op,  # model being run\n",
    "#                   x,  \n",
    "#                   \"before.onnx\",\n",
    "#                   export_params=True,  # store the trained parameter weights inside the model file\n",
    "#                   # keep_initializers_as_inputs=True,\n",
    "#                   # the ONNX version to export the model to\n",
    "#                   opset_version=10,\n",
    "#                   verbose=False,\n",
    "#                   input_names=['input'],  # the model's input names\n",
    "#                   output_names=['output'],  # the model's output names\n",
    "#                   dynamic_axes={\"input\": {0: \"batch\", 1:\"channel\",2: \"width\",3:\"height\"}}\n",
    "#                  )   \n",
    "\n",
    "\n",
    "# op_rep= rep_model_convert(op, do_copy=False)\n",
    "# op_rep.to(device)\n",
    "# op_rep.eval()\n",
    "\n",
    "# torch.onnx.export(op_rep,  # model being run\n",
    "#                   x,  \n",
    "#                   \"after.onnx\",\n",
    "#                   export_params=True,  # store the trained parameter weights inside the model file\n",
    "#                   # keep_initializers_as_inputs=True,\n",
    "#                   # the ONNX version to export the model to\n",
    "#                   opset_version=10,\n",
    "#                   verbose=False,\n",
    "#                   input_names=['input'],  # the model's input names\n",
    "#                   output_names=['output'],  # the model's output names\n",
    "#                   dynamic_axes={\"input\": {0: \"batch\", 1:\"channel\",2: \"width\",3:\"height\"}}\n",
    "#                  )   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a7ffa5-91a8-4a2b-9a7c-e0a30ed1f81c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2ecb322-3f18-4781-92fa-6f969d3d0039",
   "metadata": {},
   "source": [
    "### BranchBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "573ba353-0dee-4e5e-ac8d-a6f4cc5c8e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class branch_block(nn.Module):\n",
    "    def __init__(self, \n",
    "                 c_in,   \n",
    "                 c_out,  \n",
    "                 max_kernel_size,   \n",
    "                 stride=1, \n",
    "                 number_BottleRep=2,  \n",
    "                 number_blocks_list = None, \n",
    "                 e=0.5, \n",
    "                 skip_connection=True,\n",
    "                 verbose = False,\n",
    "                 scaling_factor = 0.5,\n",
    "                 run_time_depth_index=0):  \n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        assert stride == 1\n",
    "        assert c_in == c_out\n",
    "        self.c_in =c_in\n",
    "        self.c_out = c_out\n",
    "        self.skip_connection = skip_connection\n",
    "        self.max_kernel_size = max_kernel_size\n",
    "        c_ = int(c_out * e)  # hidden channels\n",
    "        \n",
    "        self.c_ = c_\n",
    "\n",
    "\n",
    "\n",
    "        self.run_time_depth_index = run_time_depth_index\n",
    "\n",
    "        \n",
    "        self.run_time_depth_index_list = list(range(run_time_depth_index,run_time_depth_index+number_BottleRep+1)) \n",
    "\n",
    "\n",
    "        self.current_run_time_depth = None\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        if self.skip_connection : \n",
    "        \n",
    "            self.conv_block_reduction   = NAS_REP_ConvBNBlock(c_in, c_,   max_kernel_size,stride,verbose=verbose,scaling_factor=scaling_factor, run_time_depth_index = run_time_depth_index)\n",
    "            self.RepBlock               = RepBlock( c_in=c_, c_out=c_,  max_kernel_size = max_kernel_size,stride=stride, number_BottleRep=number_BottleRep ,number_blocks_list= number_blocks_list, verbose=verbose, scaling_factor = scaling_factor, run_time_depth_index=run_time_depth_index+1)\n",
    "            self.conv_block_skip        = NAS_REP_ConvBNBlock(c_in, c_,   max_kernel_size,stride,verbose=verbose,scaling_factor=scaling_factor, run_time_depth_index = run_time_depth_index)\n",
    "            self.conv_block_backmapping = NAS_REP_ConvBNBlock(2*c_, c_out,max_kernel_size,stride,verbose=verbose,scaling_factor=scaling_factor, run_time_depth_index = run_time_depth_index)\n",
    "        else:\n",
    "            \n",
    "            self.conv_block_reduction   = NAS_REP_ConvBNBlock(c_in, c_,   max_kernel_size,stride,verbose=verbose,scaling_factor=scaling_factor,  run_time_depth_index = run_time_depth_index)\n",
    "            self.RepBlock               = RepBlock(c_in=c_, c_out=c_,  max_kernel_size = max_kernel_size,stride=stride, number_BottleRep=number_BottleRep ,number_blocks_list= number_blocks_list, verbose=verbose, scaling_factor = scaling_factor, run_time_depth_index=run_time_depth_index+1)\n",
    "            self.conv_block_skip        = None\n",
    "            self.conv_block_backmapping = NAS_REP_ConvBNBlock(c_, c_out,max_kernel_size,stride,verbose=verbose,scaling_factor=scaling_factor,  run_time_depth_index = run_time_depth_index)\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.current_run_time_depth is None or self.current_run_time_depth>=min(self.run_time_depth_index_list):\n",
    "            if self.skip_connection :\n",
    "\n",
    "                return self.conv_block_backmapping(torch.cat((self.RepBlock(self.conv_block_reduction(x)), self.conv_block_skip(x)), dim=1))\n",
    "            else:\n",
    "                return self.conv_block_backmapping(self.RepBlock(self.conv_block_reduction(x)))\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "\n",
    "\n",
    "    def reset_active_depth_and_conv(self):\n",
    "        self.conv_block_reduction.reset_active_net_param()\n",
    "        self.conv_block_backmapping.reset_active_net_param()\n",
    "        \n",
    "        if self.skip_connection: \n",
    "            self.conv_block_skip.reset_active_net_param()\n",
    "\n",
    "        self.RepBlock.reset_active_depth_and_conv()\n",
    "            \n",
    "        self.current_run_time_depth = None\n",
    "        \n",
    "    \n",
    "\n",
    "    def set_current_runtime_depth_and_kernel(self, \n",
    "                                             current_run_time_depth  = None, \n",
    "                                             kernel_index            = None, \n",
    "                                             \n",
    "                                             random                  = False, \n",
    "                                             all_layers              = False,\n",
    "                                             \n",
    "                                             active_net              = False, \n",
    "                                             active_all_sub_net      = False,\n",
    "                                             \n",
    "                                            ):\n",
    "\n",
    "\n",
    "        self.current_run_time_depth = current_run_time_depth\n",
    "\n",
    "\n",
    "\n",
    "        self.conv_block_reduction.set_current_runtime_depth_and_kernel(current_run_time_depth, kernel_index,  random, all_layers, active_net, active_all_sub_net)\n",
    "        self.conv_block_backmapping.set_current_runtime_depth_and_kernel(current_run_time_depth, kernel_index,  random, all_layers, active_net, active_all_sub_net)\n",
    "        if self.skip_connection:\n",
    "            self.conv_block_skip.set_current_runtime_depth_and_kernel(current_run_time_depth, kernel_index,  random, all_layers, active_net, active_all_sub_net)\n",
    "        \n",
    "        self.RepBlock.set_current_runtime_depth_and_kernel(current_run_time_depth, kernel_index,  random, all_layers, active_net, active_all_sub_net)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879e2ab2-be15-4e00-b9f1-f52f3cb21e9c",
   "metadata": {},
   "source": [
    "### Check Inference difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e09fb5ff-93ae-4ae1-a62d-bafdaf483ec1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_blocks_list[2, 2, 2, 2]\n",
      "Parameter name: conv_block_reduction.branch_kernel_1.conv.weight, Shape: torch.Size([16, 32, 1, 1])\n",
      "Parameter name: conv_block_reduction.branch_kernel_1.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: conv_block_reduction.branch_kernel_1.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: conv_block_reduction.branch_kernel_3.conv.weight, Shape: torch.Size([16, 32, 3, 3])\n",
      "Parameter name: conv_block_reduction.branch_kernel_3.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: conv_block_reduction.branch_kernel_3.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: conv_block_reduction.branch_kernel_5.conv.weight, Shape: torch.Size([16, 32, 5, 5])\n",
      "Parameter name: conv_block_reduction.branch_kernel_5.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: conv_block_reduction.branch_kernel_5.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: conv_block_reduction.branch_kernel_7.conv.weight, Shape: torch.Size([16, 32, 7, 7])\n",
      "Parameter name: conv_block_reduction.branch_kernel_7.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: conv_block_reduction.branch_kernel_7.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_0.branch_kernel_0.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_0.branch_kernel_0.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_0.branch_kernel_1.conv.weight, Shape: torch.Size([16, 16, 1, 1])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_0.branch_kernel_1.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_0.branch_kernel_1.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_0.branch_kernel_3.conv.weight, Shape: torch.Size([16, 16, 3, 3])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_0.branch_kernel_3.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_0.branch_kernel_3.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_0.branch_kernel_5.conv.weight, Shape: torch.Size([16, 16, 5, 5])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_0.branch_kernel_5.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_0.branch_kernel_5.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([16, 16, 7, 7])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_1.branch_kernel_0.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_1.branch_kernel_0.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_1.branch_kernel_1.conv.weight, Shape: torch.Size([16, 16, 1, 1])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_1.branch_kernel_1.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_1.branch_kernel_1.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_1.branch_kernel_3.conv.weight, Shape: torch.Size([16, 16, 3, 3])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_1.branch_kernel_3.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_1.branch_kernel_3.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_1.branch_kernel_5.conv.weight, Shape: torch.Size([16, 16, 5, 5])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_1.branch_kernel_5.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_1.branch_kernel_5.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_1.branch_kernel_7.conv.weight, Shape: torch.Size([16, 16, 7, 7])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_1.branch_kernel_7.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_1.branch_kernel_7.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_0.branch_kernel_0.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_0.branch_kernel_0.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_0.branch_kernel_1.conv.weight, Shape: torch.Size([16, 16, 1, 1])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_0.branch_kernel_1.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_0.branch_kernel_1.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_0.branch_kernel_3.conv.weight, Shape: torch.Size([16, 16, 3, 3])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_0.branch_kernel_3.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_0.branch_kernel_3.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_0.branch_kernel_5.conv.weight, Shape: torch.Size([16, 16, 5, 5])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_0.branch_kernel_5.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_0.branch_kernel_5.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([16, 16, 7, 7])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_1.branch_kernel_0.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_1.branch_kernel_0.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_1.branch_kernel_1.conv.weight, Shape: torch.Size([16, 16, 1, 1])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_1.branch_kernel_1.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_1.branch_kernel_1.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_1.branch_kernel_3.conv.weight, Shape: torch.Size([16, 16, 3, 3])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_1.branch_kernel_3.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_1.branch_kernel_3.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_1.branch_kernel_5.conv.weight, Shape: torch.Size([16, 16, 5, 5])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_1.branch_kernel_5.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_1.branch_kernel_5.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_1.branch_kernel_7.conv.weight, Shape: torch.Size([16, 16, 7, 7])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_1.branch_kernel_7.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_1.branch_kernel_7.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_0.branch_kernel_0.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_0.branch_kernel_0.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_0.branch_kernel_1.conv.weight, Shape: torch.Size([16, 16, 1, 1])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_0.branch_kernel_1.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_0.branch_kernel_1.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_0.branch_kernel_3.conv.weight, Shape: torch.Size([16, 16, 3, 3])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_0.branch_kernel_3.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_0.branch_kernel_3.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_0.branch_kernel_5.conv.weight, Shape: torch.Size([16, 16, 5, 5])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_0.branch_kernel_5.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_0.branch_kernel_5.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([16, 16, 7, 7])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_1.branch_kernel_0.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_1.branch_kernel_0.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_1.branch_kernel_1.conv.weight, Shape: torch.Size([16, 16, 1, 1])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_1.branch_kernel_1.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_1.branch_kernel_1.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_1.branch_kernel_3.conv.weight, Shape: torch.Size([16, 16, 3, 3])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_1.branch_kernel_3.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_1.branch_kernel_3.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_1.branch_kernel_5.conv.weight, Shape: torch.Size([16, 16, 5, 5])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_1.branch_kernel_5.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_1.branch_kernel_5.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_1.branch_kernel_7.conv.weight, Shape: torch.Size([16, 16, 7, 7])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_1.branch_kernel_7.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_1.branch_kernel_7.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_3.conv_block_0.branch_kernel_0.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_3.conv_block_0.branch_kernel_0.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_3.conv_block_0.branch_kernel_1.conv.weight, Shape: torch.Size([16, 16, 1, 1])\n",
      "Parameter name: RepBlock.BottleRep_3.conv_block_0.branch_kernel_1.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_3.conv_block_0.branch_kernel_1.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_3.conv_block_0.branch_kernel_3.conv.weight, Shape: torch.Size([16, 16, 3, 3])\n",
      "Parameter name: RepBlock.BottleRep_3.conv_block_0.branch_kernel_3.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_3.conv_block_0.branch_kernel_3.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_3.conv_block_0.branch_kernel_5.conv.weight, Shape: torch.Size([16, 16, 5, 5])\n",
      "Parameter name: RepBlock.BottleRep_3.conv_block_0.branch_kernel_5.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_3.conv_block_0.branch_kernel_5.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_3.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([16, 16, 7, 7])\n",
      "Parameter name: RepBlock.BottleRep_3.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_3.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_3.conv_block_1.branch_kernel_0.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_3.conv_block_1.branch_kernel_0.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_3.conv_block_1.branch_kernel_1.conv.weight, Shape: torch.Size([16, 16, 1, 1])\n",
      "Parameter name: RepBlock.BottleRep_3.conv_block_1.branch_kernel_1.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_3.conv_block_1.branch_kernel_1.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_3.conv_block_1.branch_kernel_3.conv.weight, Shape: torch.Size([16, 16, 3, 3])\n",
      "Parameter name: RepBlock.BottleRep_3.conv_block_1.branch_kernel_3.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_3.conv_block_1.branch_kernel_3.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_3.conv_block_1.branch_kernel_5.conv.weight, Shape: torch.Size([16, 16, 5, 5])\n",
      "Parameter name: RepBlock.BottleRep_3.conv_block_1.branch_kernel_5.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_3.conv_block_1.branch_kernel_5.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_3.conv_block_1.branch_kernel_7.conv.weight, Shape: torch.Size([16, 16, 7, 7])\n",
      "Parameter name: RepBlock.BottleRep_3.conv_block_1.branch_kernel_7.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_3.conv_block_1.branch_kernel_7.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: conv_block_skip.branch_kernel_1.conv.weight, Shape: torch.Size([16, 32, 1, 1])\n",
      "Parameter name: conv_block_skip.branch_kernel_1.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: conv_block_skip.branch_kernel_1.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: conv_block_skip.branch_kernel_3.conv.weight, Shape: torch.Size([16, 32, 3, 3])\n",
      "Parameter name: conv_block_skip.branch_kernel_3.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: conv_block_skip.branch_kernel_3.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: conv_block_skip.branch_kernel_5.conv.weight, Shape: torch.Size([16, 32, 5, 5])\n",
      "Parameter name: conv_block_skip.branch_kernel_5.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: conv_block_skip.branch_kernel_5.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: conv_block_skip.branch_kernel_7.conv.weight, Shape: torch.Size([16, 32, 7, 7])\n",
      "Parameter name: conv_block_skip.branch_kernel_7.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: conv_block_skip.branch_kernel_7.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: conv_block_backmapping.branch_kernel_0.weight, Shape: torch.Size([32])\n",
      "Parameter name: conv_block_backmapping.branch_kernel_0.bias, Shape: torch.Size([32])\n",
      "Parameter name: conv_block_backmapping.branch_kernel_1.conv.weight, Shape: torch.Size([32, 32, 1, 1])\n",
      "Parameter name: conv_block_backmapping.branch_kernel_1.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: conv_block_backmapping.branch_kernel_1.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: conv_block_backmapping.branch_kernel_3.conv.weight, Shape: torch.Size([32, 32, 3, 3])\n",
      "Parameter name: conv_block_backmapping.branch_kernel_3.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: conv_block_backmapping.branch_kernel_3.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: conv_block_backmapping.branch_kernel_5.conv.weight, Shape: torch.Size([32, 32, 5, 5])\n",
      "Parameter name: conv_block_backmapping.branch_kernel_5.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: conv_block_backmapping.branch_kernel_5.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: conv_block_backmapping.branch_kernel_7.conv.weight, Shape: torch.Size([32, 32, 7, 7])\n",
      "Parameter name: conv_block_backmapping.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: conv_block_backmapping.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "-----------------------------SPLIT-------------------------------------\n",
      "Parameter name: conv_block_reduction.branch_kernel_1.conv.weight, Shape: torch.Size([16, 32, 1, 1])\n",
      "Parameter name: conv_block_reduction.branch_kernel_1.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: conv_block_reduction.branch_kernel_1.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: conv_block_reduction.branch_kernel_3.conv.weight, Shape: torch.Size([16, 32, 3, 3])\n",
      "Parameter name: conv_block_reduction.branch_kernel_3.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: conv_block_reduction.branch_kernel_3.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: conv_block_reduction.branch_kernel_5.conv.weight, Shape: torch.Size([16, 32, 5, 5])\n",
      "Parameter name: conv_block_reduction.branch_kernel_5.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: conv_block_reduction.branch_kernel_5.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_0.branch_kernel_0.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_0.branch_kernel_0.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_0.branch_kernel_1.conv.weight, Shape: torch.Size([16, 16, 1, 1])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_0.branch_kernel_1.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_0.branch_kernel_1.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_0.branch_kernel_3.conv.weight, Shape: torch.Size([16, 16, 3, 3])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_0.branch_kernel_3.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_0.branch_kernel_3.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_1.branch_kernel_0.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_1.branch_kernel_0.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_1.branch_kernel_1.conv.weight, Shape: torch.Size([16, 16, 1, 1])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_1.branch_kernel_1.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_1.branch_kernel_1.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_1.branch_kernel_3.conv.weight, Shape: torch.Size([16, 16, 3, 3])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_1.branch_kernel_3.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_1.branch_kernel_3.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_0.branch_kernel_0.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_0.branch_kernel_0.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_0.branch_kernel_1.conv.weight, Shape: torch.Size([16, 16, 1, 1])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_0.branch_kernel_1.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_0.branch_kernel_1.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_0.branch_kernel_3.conv.weight, Shape: torch.Size([16, 16, 3, 3])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_0.branch_kernel_3.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_0.branch_kernel_3.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_1.branch_kernel_0.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_1.branch_kernel_0.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_1.branch_kernel_1.conv.weight, Shape: torch.Size([16, 16, 1, 1])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_1.branch_kernel_1.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_1.conv_block_1.branch_kernel_1.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_0.branch_kernel_0.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_0.branch_kernel_0.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_0.branch_kernel_1.conv.weight, Shape: torch.Size([16, 16, 1, 1])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_0.branch_kernel_1.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_0.branch_kernel_1.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_0.branch_kernel_3.conv.weight, Shape: torch.Size([16, 16, 3, 3])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_0.branch_kernel_3.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_0.branch_kernel_3.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_0.branch_kernel_5.conv.weight, Shape: torch.Size([16, 16, 5, 5])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_0.branch_kernel_5.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_0.branch_kernel_5.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([16, 16, 7, 7])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_1.branch_kernel_0.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_1.branch_kernel_0.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_1.branch_kernel_1.conv.weight, Shape: torch.Size([16, 16, 1, 1])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_1.branch_kernel_1.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_1.branch_kernel_1.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_1.branch_kernel_3.conv.weight, Shape: torch.Size([16, 16, 3, 3])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_1.branch_kernel_3.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_2.conv_block_1.branch_kernel_3.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_3.conv_block_0.branch_kernel_0.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_3.conv_block_0.branch_kernel_0.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_3.conv_block_0.branch_kernel_1.conv.weight, Shape: torch.Size([16, 16, 1, 1])\n",
      "Parameter name: RepBlock.BottleRep_3.conv_block_0.branch_kernel_1.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_3.conv_block_0.branch_kernel_1.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_3.conv_block_1.branch_kernel_0.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_3.conv_block_1.branch_kernel_0.bias, Shape: torch.Size([16])\n",
      "Parameter name: conv_block_skip.branch_kernel_1.conv.weight, Shape: torch.Size([16, 32, 1, 1])\n",
      "Parameter name: conv_block_skip.branch_kernel_1.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: conv_block_skip.branch_kernel_1.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: conv_block_backmapping.branch_kernel_0.weight, Shape: torch.Size([32])\n",
      "Parameter name: conv_block_backmapping.branch_kernel_0.bias, Shape: torch.Size([32])\n",
      "Parameter name: conv_block_backmapping.branch_kernel_1.conv.weight, Shape: torch.Size([32, 32, 1, 1])\n",
      "Parameter name: conv_block_backmapping.branch_kernel_1.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: conv_block_backmapping.branch_kernel_1.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: conv_block_backmapping.branch_kernel_3.conv.weight, Shape: torch.Size([32, 32, 3, 3])\n",
      "Parameter name: conv_block_backmapping.branch_kernel_3.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: conv_block_backmapping.branch_kernel_3.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: conv_block_backmapping.branch_kernel_5.conv.weight, Shape: torch.Size([32, 32, 5, 5])\n",
      "Parameter name: conv_block_backmapping.branch_kernel_5.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: conv_block_backmapping.branch_kernel_5.bn.bias, Shape: torch.Size([32])\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "tensor(3.5138, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# check the nas_rep_block\n",
    "in_channels     = 32\n",
    "out_channels    = 32  #  change here\n",
    "img_size        = 128\n",
    "max_kernel_size = 7\n",
    "stride          = 1   #  change here\n",
    "verbose         = True\n",
    "scaling_factor  = 0.5\n",
    "run_time_depth_index = 1\n",
    "number_BottleRep     = 4\n",
    "\n",
    "\n",
    "op = branch_block(\n",
    " \n",
    "    c_in                      = in_channels,\n",
    "    c_out                     = out_channels,\n",
    "    max_kernel_size           = max_kernel_size,\n",
    "    stride                    = 1,\n",
    "    number_BottleRep          = number_BottleRep,\n",
    "    number_blocks_list        = None,\n",
    "    verbose                   = verbose,\n",
    "    scaling_factor            = scaling_factor,\n",
    "    run_time_depth_index      = run_time_depth_index,\n",
    "\n",
    "\n",
    ").to(device)\n",
    "\n",
    "\n",
    "\n",
    "for name, param in op.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Parameter name: {name}, Shape: {param.shape}\")\n",
    "\n",
    "print(\"-----------------------------SPLIT-------------------------------------\")\n",
    "\n",
    "op.set_current_runtime_depth_and_kernel(\n",
    "\n",
    "    current_run_time_depth=10,          #  change here\n",
    "    kernel_index=None,                    #  change here\n",
    "\n",
    "    random=True,                      #  change here\n",
    "    all_layers=False,                  #  change here\n",
    "    \n",
    "    active_net=False,                  #  change here\n",
    "    active_all_sub_net=True,          #  change here\n",
    ")\n",
    "\n",
    "\n",
    "for name, param in op.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Parameter name: {name}, Shape: {param.shape}\")\n",
    "        \n",
    "\n",
    "for _ in range(10):\n",
    "    x = torch.randn([1, in_channels, img_size, img_size]).to(device)\n",
    "    y = op(x)\n",
    "\n",
    "op.eval()\n",
    "# check the inference with a random input\n",
    "x = torch.randn([1, in_channels, img_size, img_size]).to(device)\n",
    "\n",
    "\n",
    "y1 = op(x)\n",
    "\n",
    "\n",
    "op_rep= rep_model_convert(op, do_copy=False)\n",
    "op_rep.to(device)\n",
    "op_rep.eval()\n",
    "\n",
    "\n",
    "y2 = op_rep(x)\n",
    "\n",
    "\n",
    "\n",
    "print(y1.abs().max())\n",
    "print(((y1-y2).abs()).max())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ee768d-59c8-4656-96e7-721229011de9",
   "metadata": {},
   "source": [
    "### Export ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "82435d90-830a-48f0-bd69-551d6b053c13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_blocks_list[2, 2, 2, 2]\n",
      "-----------------------------SPLIT-------------------------------------\n",
      "Parameter name: conv_block_reduction.branch_kernel_3.conv.weight, Shape: torch.Size([16, 32, 3, 3])\n",
      "Parameter name: conv_block_reduction.branch_kernel_3.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: conv_block_reduction.branch_kernel_3.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_0.branch_kernel_5.conv.weight, Shape: torch.Size([16, 16, 5, 5])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_0.branch_kernel_5.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_0.branch_kernel_5.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_1.branch_kernel_1.conv.weight, Shape: torch.Size([16, 16, 1, 1])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_1.branch_kernel_1.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: RepBlock.BottleRep_0.conv_block_1.branch_kernel_1.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: conv_block_skip.branch_kernel_1.conv.weight, Shape: torch.Size([16, 32, 1, 1])\n",
      "Parameter name: conv_block_skip.branch_kernel_1.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: conv_block_skip.branch_kernel_1.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: conv_block_backmapping.branch_kernel_7.conv.weight, Shape: torch.Size([32, 32, 7, 7])\n",
      "Parameter name: conv_block_backmapping.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: conv_block_backmapping.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_1\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_7\n"
     ]
    }
   ],
   "source": [
    "# check the nas_rep_block\n",
    "in_channels     = 32\n",
    "out_channels    = 32  #  change here\n",
    "img_size        = 128\n",
    "max_kernel_size = 7\n",
    "stride          = 1   #  change here\n",
    "verbose         = True\n",
    "scaling_factor  = 0.5\n",
    "run_time_depth_index = 1\n",
    "number_BottleRep     = 4\n",
    "\n",
    "\n",
    "op = branch_block(\n",
    " \n",
    "    c_in                      = in_channels,\n",
    "    c_out                     = out_channels,\n",
    "    max_kernel_size           = max_kernel_size,\n",
    "    stride                    = 1,\n",
    "    number_BottleRep          = number_BottleRep,\n",
    "    number_blocks_list        = None,\n",
    "    verbose                   = verbose,\n",
    "    scaling_factor            = scaling_factor,\n",
    "    run_time_depth_index      = run_time_depth_index,\n",
    "\n",
    "\n",
    ").to(device)\n",
    "\n",
    "\n",
    "# for name, param in op.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(f\"Parameter name: {name}, Shape: {param.shape}\")\n",
    "\n",
    "print(\"-----------------------------SPLIT-------------------------------------\")\n",
    "\n",
    "op.set_current_runtime_depth_and_kernel(\n",
    "\n",
    "    current_run_time_depth=2,          #  change here\n",
    "    kernel_index=None,                    #  change here\n",
    "\n",
    "    random=True,                      #  change here\n",
    "    all_layers=True,                  #  change here\n",
    "    \n",
    "    active_net=False,                  #  change here\n",
    "    active_all_sub_net=False,          #  change here\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "for name, param in op.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Parameter name: {name}, Shape: {param.shape}\")\n",
    "        \n",
    "# print(\"-----------------------------SPLIT-------------------------------------\")\n",
    "\n",
    "for _ in range(10):\n",
    "    x = torch.randn([1, in_channels, img_size, img_size]).to(device)\n",
    "    y = op(x)\n",
    "\n",
    "op.eval()\n",
    "# check the inference with a random input\n",
    "x = torch.randn([1, in_channels, img_size, img_size]).to(device)\n",
    "torch.onnx.export(op,  # model being run\n",
    "                  x,  \n",
    "                  \"before.onnx\",\n",
    "                  export_params=True,  # store the trained parameter weights inside the model file\n",
    "                  # keep_initializers_as_inputs=True,\n",
    "                  # the ONNX version to export the model to\n",
    "                  opset_version=10,\n",
    "                  verbose=False,\n",
    "                  input_names=['input'],  # the model's input names\n",
    "                  output_names=['output'],  # the model's output names\n",
    "                  dynamic_axes={\"input\": {0: \"batch\", 1:\"channel\",2: \"width\",3:\"height\"}}\n",
    "                 )   \n",
    "\n",
    "\n",
    "op_rep= rep_model_convert(op, do_copy=False)\n",
    "op_rep.to(device)\n",
    "op_rep.eval()\n",
    "\n",
    "torch.onnx.export(op_rep,  # model being run\n",
    "                  x,  \n",
    "                  \"after.onnx\",\n",
    "                  export_params=True,  # store the trained parameter weights inside the model file\n",
    "                  # keep_initializers_as_inputs=True,\n",
    "                  # the ONNX version to export the model to\n",
    "                  opset_version=10,\n",
    "                  verbose=False,\n",
    "                  input_names=['input'],  # the model's input names\n",
    "                  output_names=['output'],  # the model's output names\n",
    "                  dynamic_axes={\"input\": {0: \"batch\", 1:\"channel\",2: \"width\",3:\"height\"}}\n",
    "                 )   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ce4120-8dcd-4cf9-aa3d-9dc708cc19f7",
   "metadata": {},
   "source": [
    "### BackBone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb184252-813a-4da9-99fd-5d17c86f74f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    \"\"\"\n",
    "    This function is taken from the original tf repo.\n",
    "    It ensures that all layers have a channel number that is divisible by 8\n",
    "    It can be seen here:\n",
    "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
    "    :param v:\n",
    "    :param divisor:\n",
    "    :param min_value:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "class Backbone(nn.Module):\n",
    "    def __init__(self, \n",
    "                 config,\n",
    "                 max_kernel_size,\n",
    "                 width_mult=0.5,\n",
    "                 round_nearest=8,\n",
    "                 pre_img = False,\n",
    "                 combine_style = \"add\",\n",
    "                 verbose = False,\n",
    "                 scaling_factor = 0.5,\n",
    "                 skip_connection = True\n",
    "                 ):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        input_channel = 64\n",
    "        self.pre_img = pre_img\n",
    "        self.combine_style = combine_style\n",
    "        self.max_kernel_size = max_kernel_size\n",
    "\n",
    "        \n",
    "        assert self.combine_style in [\"add\",\"cat\",\"sub_cat\",\"add_cat\"]\n",
    "\n",
    "        input_channel = _make_divisible(input_channel * width_mult, round_nearest)\n",
    "\n",
    "        if pre_img:\n",
    "            print('adding pre_img layer...with input_channel',input_channel)\n",
    "            self.pre_img_layer = NAS_REP_ConvBNBlock(\n",
    "                3,\n",
    "                input_channel,\n",
    "                max_kernel_size, \n",
    "                stride=2,\n",
    "                verbose = verbose,\n",
    "                scaling_factor = scaling_factor,\n",
    "                run_time_depth_index = 0\n",
    "            )\n",
    "            \n",
    "\n",
    "        # this is also default\n",
    "        features = [NAS_REP_ConvBNBlock(\n",
    "            3, \n",
    "            input_channel, \n",
    "            max_kernel_size, \n",
    "            stride=2,\n",
    "            verbose = verbose,\n",
    "            scaling_factor = scaling_factor,\n",
    "            run_time_depth_index = 0\n",
    "        )]\n",
    "\n",
    "\n",
    "        if self.combine_style == \"add\":\n",
    "            input_channel = input_channel\n",
    "        elif  self.combine_style == \"cat\":\n",
    "            input_channel = input_channel * 2\n",
    "        elif self.combine_style == \"sub_cat\":\n",
    "            input_channel = input_channel * 3\n",
    "        elif self.combine_style == \"add_cat\":\n",
    "             input_channel = input_channel * 3\n",
    "        else :\n",
    "            raise Exception(\"non valid combine_style\")\n",
    "\n",
    "\n",
    "\n",
    "        self.key_block = [True]\n",
    "        all_channels = [input_channel]\n",
    "        self.channels = [input_channel]\n",
    "\n",
    "        for op_name, layer_cfg in config:\n",
    "\n",
    "            output_channel = layer_cfg[0]\n",
    "\n",
    "            output_channel = _make_divisible(output_channel * width_mult, round_nearest)\n",
    "            \n",
    "            op = eval(op_name)\n",
    "            \n",
    "            if op_name == \"NAS_REP_ConvBNBlock\":\n",
    "                stride = layer_cfg[1]\n",
    "                run_time_depth_index = layer_cfg[2]\n",
    "\n",
    "              \n",
    "                features.append(op(\n",
    "                    in_channels         = input_channel, \n",
    "                    out_channels        = output_channel, \n",
    "                    max_kernel_size     = max_kernel_size, \n",
    "                    stride              = stride,\n",
    "                    verbose             = verbose,\n",
    "                    scaling_factor      = scaling_factor,\n",
    "                    run_time_depth_index= run_time_depth_index\n",
    "                    )\n",
    "                )\n",
    "            elif op_name == \"branch_block\":\n",
    "                n = layer_cfg[1]\n",
    "                stride = 1\n",
    "                run_time_depth_index = layer_cfg[2]\n",
    "                features.append(op(\n",
    "                    c_in                = input_channel, \n",
    "                    c_out               = output_channel,\n",
    "                    max_kernel_size     = max_kernel_size,\n",
    "                    stride              = 1,\n",
    "                    number_BottleRep    = n,\n",
    "                    e                   = 0.5,\n",
    "                    skip_connection     = skip_connection,\n",
    "                    verbose             = verbose,\n",
    "                    scaling_factor      = scaling_factor,\n",
    "                    run_time_depth_index= run_time_depth_index   \n",
    "                ))\n",
    "\n",
    "\n",
    "            else:\n",
    "                assert 1==0\n",
    "            \n",
    "            input_channel = output_channel\n",
    "            if stride == 2:\n",
    "                self.key_block.append(True)\n",
    "            else:\n",
    "                self.key_block.append(False)\n",
    "                \n",
    "            all_channels.append(output_channel)\n",
    "\n",
    "        for i in range(len(self.key_block) - 1):\n",
    "            if self.key_block[i + 1]:\n",
    "                self.key_block[i] = True\n",
    "                self.key_block[i + 1] = False\n",
    "                self.channels.append(all_channels[i])\n",
    "\n",
    "        self.key_block[-1] = True\n",
    "        self.channels.append(all_channels[-1])\n",
    "\n",
    "        self.features = nn.ModuleList(features)\n",
    "        \n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.ones_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "\n",
    "    def set_current_runtime_depth_and_kernel(self, \n",
    "                                             current_run_time_depth  = None, \n",
    "                                             kernel_index            = None, \n",
    "                                             \n",
    "                                             random                  = False, \n",
    "                                             all_layers              = False,\n",
    "                                             \n",
    "                                             active_net              = False, \n",
    "                                             active_all_sub_net      = False,\n",
    "                                             \n",
    "                                            ):\n",
    "        if self.pre_img:\n",
    "            self.pre_img_layer.set_current_runtime_depth_and_kernel(current_run_time_depth,  kernel_index, random, all_layers, active_net, active_all_sub_net)\n",
    "\n",
    "        for layer in self.features:\n",
    "            layer.set_current_runtime_depth_and_kernel(current_run_time_depth,  kernel_index, random, all_layers, active_net, active_all_sub_net)\n",
    "\n",
    "                    \n",
    "    def random_set_current_runtime_depth_and_kernel(self, \n",
    "\n",
    "                                             all_layers              = False,\n",
    "                                             \n",
    "                                             active_net              = False, \n",
    "                                             active_all_sub_net      = False,\n",
    "                                             \n",
    "                                            ):\n",
    "        \n",
    "\n",
    "        if self.pre_img:\n",
    "            self.pre_img_layer.set_current_runtime_depth_and_kernel(0,  None, True, all_layers, active_net, active_all_sub_net)\n",
    "\n",
    "\n",
    "        for layer in self.features:\n",
    "\n",
    "            if type(layer).__name__  == \"NAS_REP_ConvBNBlock\":\n",
    "                assert layer.run_time_depth_index == 0\n",
    "                layer.set_current_runtime_depth_and_kernel(0,  None, True, all_layers, active_net, active_all_sub_net)\n",
    "            else:\n",
    "                assert type(layer).__name__  == \"branch_block\"\n",
    "                random_run_depth = random.choice(layer.run_time_depth_index_list) \n",
    "                layer.set_current_runtime_depth_and_kernel(random_run_depth,  None, True, all_layers, active_net, active_all_sub_net)\n",
    "\n",
    "    def reset_active_depth_and_conv(self):\n",
    "\n",
    "        if self.pre_img:\n",
    "            self.pre_img_layer.reset_active_net_param()\n",
    "\n",
    "        for layer in self.features:\n",
    "\n",
    "            if type(layer).__name__  == \"NAS_REP_ConvBNBlock\":\n",
    "                layer.reset_active_net_param()\n",
    "            else:\n",
    "                assert type(layer).__name__  == \"branch_block\"\n",
    "                layer.reset_active_depth_and_conv()\n",
    "    \n",
    "\n",
    "\n",
    "    def forward(self, inputs, pre_img=None, pre_hm=None):\n",
    "        # ------------!!!!!!!!!!!!!!!-------------\n",
    "        x = self.features[0](inputs)\n",
    "\n",
    "        if pre_img is not None:\n",
    "            if self.combine_style == \"add\":\n",
    "                x = x + self.pre_img_layer(pre_img)\n",
    "            elif  self.combine_style == \"cat\":\n",
    "                x = torch.cat(( x, self.pre_img_layer(pre_img)), dim=1)\n",
    "            elif self.combine_style == \"sub_cat\":\n",
    "                x_pre_img = self.pre_img_layer(pre_img)\n",
    "                sub_img = x - x_pre_img\n",
    "                x = torch.cat(( x, x_pre_img, sub_img), dim=1)\n",
    "            elif self.combine_style == \"add_cat\":\n",
    "                x_pre_img = self.pre_img_layer(pre_img)\n",
    "                add_img = x + x_pre_img\n",
    "                x = torch.cat(( x, x_pre_img, add_img), dim=1)\n",
    "            else :\n",
    "                raise Exception(\"non valid combine_style\")\n",
    "\n",
    "            \n",
    "            #x = x + self.pre_img_layer(pre_img)\n",
    "\n",
    "        y = [x]\n",
    "        for i in range(1, len(self.features)):\n",
    "            x = self.features[i](x)\n",
    "\n",
    "            if self.key_block[i]:\n",
    "\n",
    "                y.append(x)\n",
    "        return y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4ac240-08eb-481b-b4bc-f6efa02cd774",
   "metadata": {},
   "source": [
    "### Check the inference difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1cac8741-917f-470a-aaf3-75bf95739ea5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding pre_img layer...with input_channel 8\n",
      "-----------------------------SPLIT-------------------------------------\n",
      "Parameter name: features.3.RepBlock.BottleRep_2.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([4, 4, 7, 7])\n",
      "Parameter name: features.3.RepBlock.BottleRep_2.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([4])\n",
      "Parameter name: features.3.RepBlock.BottleRep_2.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([4])\n",
      "Parameter name: features.3.RepBlock.BottleRep_2.conv_block_1.branch_kernel_7.conv.weight, Shape: torch.Size([4, 4, 7, 7])\n",
      "Parameter name: features.3.RepBlock.BottleRep_2.conv_block_1.branch_kernel_7.bn.weight, Shape: torch.Size([4])\n",
      "Parameter name: features.3.RepBlock.BottleRep_2.conv_block_1.branch_kernel_7.bn.bias, Shape: torch.Size([4])\n",
      "Parameter name: features.5.RepBlock.BottleRep_2.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([8, 8, 7, 7])\n",
      "Parameter name: features.5.RepBlock.BottleRep_2.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([8])\n",
      "Parameter name: features.5.RepBlock.BottleRep_2.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([8])\n",
      "Parameter name: features.5.RepBlock.BottleRep_2.conv_block_1.branch_kernel_7.conv.weight, Shape: torch.Size([8, 8, 7, 7])\n",
      "Parameter name: features.5.RepBlock.BottleRep_2.conv_block_1.branch_kernel_7.bn.weight, Shape: torch.Size([8])\n",
      "Parameter name: features.5.RepBlock.BottleRep_2.conv_block_1.branch_kernel_7.bn.bias, Shape: torch.Size([8])\n",
      "Parameter name: features.7.RepBlock.BottleRep_2.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([16, 16, 7, 7])\n",
      "Parameter name: features.7.RepBlock.BottleRep_2.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: features.7.RepBlock.BottleRep_2.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: features.7.RepBlock.BottleRep_2.conv_block_1.branch_kernel_7.conv.weight, Shape: torch.Size([16, 16, 7, 7])\n",
      "Parameter name: features.7.RepBlock.BottleRep_2.conv_block_1.branch_kernel_7.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: features.7.RepBlock.BottleRep_2.conv_block_1.branch_kernel_7.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: features.9.RepBlock.BottleRep_2.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([32, 32, 7, 7])\n",
      "Parameter name: features.9.RepBlock.BottleRep_2.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: features.9.RepBlock.BottleRep_2.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: features.9.RepBlock.BottleRep_2.conv_block_1.branch_kernel_7.conv.weight, Shape: torch.Size([32, 32, 7, 7])\n",
      "Parameter name: features.9.RepBlock.BottleRep_2.conv_block_1.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: features.9.RepBlock.BottleRep_2.conv_block_1.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "tensor(18.6003, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0175, device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "config = [\n",
    "    # type of stage        [ channelsize, stride, run_time_depth (begin)]\n",
    "    ['NAS_REP_ConvBNBlock', [96, 1, 0]],\n",
    "    ['NAS_REP_ConvBNBlock', [128, 2, 0]],\n",
    "    ['branch_block',         [128, 5, 1]],\n",
    "    ['NAS_REP_ConvBNBlock', [256, 2, 0]],\n",
    "    ['branch_block', [256, 5, 1]],\n",
    "    ['NAS_REP_ConvBNBlock', [512, 2, 0]],\n",
    "    ['branch_block', [512, 5, 1]],\n",
    "    ['NAS_REP_ConvBNBlock', [1024, 2, 0]],\n",
    "    ['branch_block', [1024, 5, 1]],\n",
    "    ['NAS_REP_ConvBNBlock', [1024, 1, 0]]\n",
    "]\n",
    "\n",
    "\n",
    "max_kernel_size = 7\n",
    "\n",
    "op = Backbone(\n",
    "    \n",
    "    config,\n",
    "    max_kernel_size, \n",
    "    width_mult        = 0.0625,\n",
    "    combine_style     = \"sub_cat\",\n",
    "    pre_img           = True,\n",
    "    verbose           = False,\n",
    "    scaling_factor    = 0.5,\n",
    "    skip_connection   = True\n",
    "    \n",
    ").to(device) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for name, param in op.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(f\"Parameter name: {name}, Shape: {param.shape}\")\n",
    "\n",
    "print(\"-----------------------------SPLIT-------------------------------------\")\n",
    "\n",
    "op.set_current_runtime_depth_and_kernel(\n",
    "\n",
    "    current_run_time_depth=4,          #  change here\n",
    "    kernel_index=4,                    #  change here\n",
    "\n",
    "    random=False,                      #  change here\n",
    "    all_layers=False,                  #  change here\n",
    "    \n",
    "    active_net=False,                  #  change here\n",
    "    active_all_sub_net=False,          #  change here\n",
    ")\n",
    "\n",
    "\n",
    "for name, param in op.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Parameter name: {name}, Shape: {param.shape}\")\n",
    "        \n",
    "\n",
    "for _ in range(10):\n",
    "    x = torch.randn([1, 3, img_size, img_size]).to(device)\n",
    "    y = op(x, x)\n",
    "\n",
    "op.eval()\n",
    "# check the inference with a random input\n",
    "x = torch.randn([1, 3, img_size, img_size]).to(device)\n",
    "\n",
    "\n",
    "y1 = op(x, x)\n",
    "\n",
    "\n",
    "op_rep= rep_model_convert(op, do_copy=False)\n",
    "op_rep.to(device)\n",
    "op_rep.eval()\n",
    "\n",
    "\n",
    "y2 = op_rep(x,x)\n",
    "\n",
    "\n",
    "\n",
    "print(y1[-1].abs().max())\n",
    "print(((y1[-1]-y2[-1]).abs()).max())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eefdd106-dd02-4a7d-b283-7447e213d77c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding pre_img layer...with input_channel 8\n",
      "-----------------------------SPLIT-------------------------------------\n",
      "Parameter name: pre_img_layer.branch_kernel_7.conv.weight, Shape: torch.Size([8, 3, 7, 7])\n",
      "Parameter name: pre_img_layer.branch_kernel_7.bn.weight, Shape: torch.Size([8])\n",
      "Parameter name: pre_img_layer.branch_kernel_7.bn.bias, Shape: torch.Size([8])\n",
      "Parameter name: features.0.branch_kernel_7.conv.weight, Shape: torch.Size([8, 3, 7, 7])\n",
      "Parameter name: features.0.branch_kernel_7.bn.weight, Shape: torch.Size([8])\n",
      "Parameter name: features.0.branch_kernel_7.bn.bias, Shape: torch.Size([8])\n",
      "Parameter name: features.1.branch_kernel_7.conv.weight, Shape: torch.Size([8, 24, 7, 7])\n",
      "Parameter name: features.1.branch_kernel_7.bn.weight, Shape: torch.Size([8])\n",
      "Parameter name: features.1.branch_kernel_7.bn.bias, Shape: torch.Size([8])\n",
      "Parameter name: features.2.branch_kernel_7.conv.weight, Shape: torch.Size([8, 8, 7, 7])\n",
      "Parameter name: features.2.branch_kernel_7.bn.weight, Shape: torch.Size([8])\n",
      "Parameter name: features.2.branch_kernel_7.bn.bias, Shape: torch.Size([8])\n",
      "Parameter name: features.3.conv_block_reduction.branch_kernel_7.conv.weight, Shape: torch.Size([4, 8, 7, 7])\n",
      "Parameter name: features.3.conv_block_reduction.branch_kernel_7.bn.weight, Shape: torch.Size([4])\n",
      "Parameter name: features.3.conv_block_reduction.branch_kernel_7.bn.bias, Shape: torch.Size([4])\n",
      "Parameter name: features.3.RepBlock.BottleRep_0.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([4, 4, 7, 7])\n",
      "Parameter name: features.3.RepBlock.BottleRep_0.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([4])\n",
      "Parameter name: features.3.RepBlock.BottleRep_0.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([4])\n",
      "Parameter name: features.3.RepBlock.BottleRep_0.conv_block_1.branch_kernel_7.conv.weight, Shape: torch.Size([4, 4, 7, 7])\n",
      "Parameter name: features.3.RepBlock.BottleRep_0.conv_block_1.branch_kernel_7.bn.weight, Shape: torch.Size([4])\n",
      "Parameter name: features.3.RepBlock.BottleRep_0.conv_block_1.branch_kernel_7.bn.bias, Shape: torch.Size([4])\n",
      "Parameter name: features.3.RepBlock.BottleRep_1.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([4, 4, 7, 7])\n",
      "Parameter name: features.3.RepBlock.BottleRep_1.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([4])\n",
      "Parameter name: features.3.RepBlock.BottleRep_1.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([4])\n",
      "Parameter name: features.3.RepBlock.BottleRep_1.conv_block_1.branch_kernel_7.conv.weight, Shape: torch.Size([4, 4, 7, 7])\n",
      "Parameter name: features.3.RepBlock.BottleRep_1.conv_block_1.branch_kernel_7.bn.weight, Shape: torch.Size([4])\n",
      "Parameter name: features.3.RepBlock.BottleRep_1.conv_block_1.branch_kernel_7.bn.bias, Shape: torch.Size([4])\n",
      "Parameter name: features.3.RepBlock.BottleRep_2.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([4, 4, 7, 7])\n",
      "Parameter name: features.3.RepBlock.BottleRep_2.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([4])\n",
      "Parameter name: features.3.RepBlock.BottleRep_2.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([4])\n",
      "Parameter name: features.3.RepBlock.BottleRep_2.conv_block_1.branch_kernel_7.conv.weight, Shape: torch.Size([4, 4, 7, 7])\n",
      "Parameter name: features.3.RepBlock.BottleRep_2.conv_block_1.branch_kernel_7.bn.weight, Shape: torch.Size([4])\n",
      "Parameter name: features.3.RepBlock.BottleRep_2.conv_block_1.branch_kernel_7.bn.bias, Shape: torch.Size([4])\n",
      "Parameter name: features.3.RepBlock.BottleRep_3.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([4, 4, 7, 7])\n",
      "Parameter name: features.3.RepBlock.BottleRep_3.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([4])\n",
      "Parameter name: features.3.RepBlock.BottleRep_3.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([4])\n",
      "Parameter name: features.3.RepBlock.BottleRep_3.conv_block_1.branch_kernel_7.conv.weight, Shape: torch.Size([4, 4, 7, 7])\n",
      "Parameter name: features.3.RepBlock.BottleRep_3.conv_block_1.branch_kernel_7.bn.weight, Shape: torch.Size([4])\n",
      "Parameter name: features.3.RepBlock.BottleRep_3.conv_block_1.branch_kernel_7.bn.bias, Shape: torch.Size([4])\n",
      "Parameter name: features.3.RepBlock.BottleRep_4.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([4, 4, 7, 7])\n",
      "Parameter name: features.3.RepBlock.BottleRep_4.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([4])\n",
      "Parameter name: features.3.RepBlock.BottleRep_4.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([4])\n",
      "Parameter name: features.3.RepBlock.BottleRep_4.conv_block_1.branch_kernel_7.conv.weight, Shape: torch.Size([4, 4, 7, 7])\n",
      "Parameter name: features.3.RepBlock.BottleRep_4.conv_block_1.branch_kernel_7.bn.weight, Shape: torch.Size([4])\n",
      "Parameter name: features.3.RepBlock.BottleRep_4.conv_block_1.branch_kernel_7.bn.bias, Shape: torch.Size([4])\n",
      "Parameter name: features.3.conv_block_skip.branch_kernel_7.conv.weight, Shape: torch.Size([4, 8, 7, 7])\n",
      "Parameter name: features.3.conv_block_skip.branch_kernel_7.bn.weight, Shape: torch.Size([4])\n",
      "Parameter name: features.3.conv_block_skip.branch_kernel_7.bn.bias, Shape: torch.Size([4])\n",
      "Parameter name: features.3.conv_block_backmapping.branch_kernel_7.conv.weight, Shape: torch.Size([8, 8, 7, 7])\n",
      "Parameter name: features.3.conv_block_backmapping.branch_kernel_7.bn.weight, Shape: torch.Size([8])\n",
      "Parameter name: features.3.conv_block_backmapping.branch_kernel_7.bn.bias, Shape: torch.Size([8])\n",
      "Parameter name: features.4.branch_kernel_7.conv.weight, Shape: torch.Size([16, 8, 7, 7])\n",
      "Parameter name: features.4.branch_kernel_7.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: features.4.branch_kernel_7.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: features.5.conv_block_reduction.branch_kernel_7.conv.weight, Shape: torch.Size([8, 16, 7, 7])\n",
      "Parameter name: features.5.conv_block_reduction.branch_kernel_7.bn.weight, Shape: torch.Size([8])\n",
      "Parameter name: features.5.conv_block_reduction.branch_kernel_7.bn.bias, Shape: torch.Size([8])\n",
      "Parameter name: features.5.RepBlock.BottleRep_0.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([8, 8, 7, 7])\n",
      "Parameter name: features.5.RepBlock.BottleRep_0.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([8])\n",
      "Parameter name: features.5.RepBlock.BottleRep_0.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([8])\n",
      "Parameter name: features.5.RepBlock.BottleRep_0.conv_block_1.branch_kernel_7.conv.weight, Shape: torch.Size([8, 8, 7, 7])\n",
      "Parameter name: features.5.RepBlock.BottleRep_0.conv_block_1.branch_kernel_7.bn.weight, Shape: torch.Size([8])\n",
      "Parameter name: features.5.RepBlock.BottleRep_0.conv_block_1.branch_kernel_7.bn.bias, Shape: torch.Size([8])\n",
      "Parameter name: features.5.RepBlock.BottleRep_1.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([8, 8, 7, 7])\n",
      "Parameter name: features.5.RepBlock.BottleRep_1.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([8])\n",
      "Parameter name: features.5.RepBlock.BottleRep_1.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([8])\n",
      "Parameter name: features.5.RepBlock.BottleRep_1.conv_block_1.branch_kernel_7.conv.weight, Shape: torch.Size([8, 8, 7, 7])\n",
      "Parameter name: features.5.RepBlock.BottleRep_1.conv_block_1.branch_kernel_7.bn.weight, Shape: torch.Size([8])\n",
      "Parameter name: features.5.RepBlock.BottleRep_1.conv_block_1.branch_kernel_7.bn.bias, Shape: torch.Size([8])\n",
      "Parameter name: features.5.RepBlock.BottleRep_2.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([8, 8, 7, 7])\n",
      "Parameter name: features.5.RepBlock.BottleRep_2.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([8])\n",
      "Parameter name: features.5.RepBlock.BottleRep_2.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([8])\n",
      "Parameter name: features.5.RepBlock.BottleRep_2.conv_block_1.branch_kernel_7.conv.weight, Shape: torch.Size([8, 8, 7, 7])\n",
      "Parameter name: features.5.RepBlock.BottleRep_2.conv_block_1.branch_kernel_7.bn.weight, Shape: torch.Size([8])\n",
      "Parameter name: features.5.RepBlock.BottleRep_2.conv_block_1.branch_kernel_7.bn.bias, Shape: torch.Size([8])\n",
      "Parameter name: features.5.RepBlock.BottleRep_3.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([8, 8, 7, 7])\n",
      "Parameter name: features.5.RepBlock.BottleRep_3.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([8])\n",
      "Parameter name: features.5.RepBlock.BottleRep_3.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([8])\n",
      "Parameter name: features.5.RepBlock.BottleRep_3.conv_block_1.branch_kernel_7.conv.weight, Shape: torch.Size([8, 8, 7, 7])\n",
      "Parameter name: features.5.RepBlock.BottleRep_3.conv_block_1.branch_kernel_7.bn.weight, Shape: torch.Size([8])\n",
      "Parameter name: features.5.RepBlock.BottleRep_3.conv_block_1.branch_kernel_7.bn.bias, Shape: torch.Size([8])\n",
      "Parameter name: features.5.RepBlock.BottleRep_4.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([8, 8, 7, 7])\n",
      "Parameter name: features.5.RepBlock.BottleRep_4.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([8])\n",
      "Parameter name: features.5.RepBlock.BottleRep_4.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([8])\n",
      "Parameter name: features.5.RepBlock.BottleRep_4.conv_block_1.branch_kernel_7.conv.weight, Shape: torch.Size([8, 8, 7, 7])\n",
      "Parameter name: features.5.RepBlock.BottleRep_4.conv_block_1.branch_kernel_7.bn.weight, Shape: torch.Size([8])\n",
      "Parameter name: features.5.RepBlock.BottleRep_4.conv_block_1.branch_kernel_7.bn.bias, Shape: torch.Size([8])\n",
      "Parameter name: features.5.conv_block_skip.branch_kernel_7.conv.weight, Shape: torch.Size([8, 16, 7, 7])\n",
      "Parameter name: features.5.conv_block_skip.branch_kernel_7.bn.weight, Shape: torch.Size([8])\n",
      "Parameter name: features.5.conv_block_skip.branch_kernel_7.bn.bias, Shape: torch.Size([8])\n",
      "Parameter name: features.5.conv_block_backmapping.branch_kernel_7.conv.weight, Shape: torch.Size([16, 16, 7, 7])\n",
      "Parameter name: features.5.conv_block_backmapping.branch_kernel_7.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: features.5.conv_block_backmapping.branch_kernel_7.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: features.6.branch_kernel_7.conv.weight, Shape: torch.Size([32, 16, 7, 7])\n",
      "Parameter name: features.6.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: features.6.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: features.7.conv_block_reduction.branch_kernel_7.conv.weight, Shape: torch.Size([16, 32, 7, 7])\n",
      "Parameter name: features.7.conv_block_reduction.branch_kernel_7.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: features.7.conv_block_reduction.branch_kernel_7.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: features.7.RepBlock.BottleRep_0.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([16, 16, 7, 7])\n",
      "Parameter name: features.7.RepBlock.BottleRep_0.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: features.7.RepBlock.BottleRep_0.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: features.7.RepBlock.BottleRep_0.conv_block_1.branch_kernel_7.conv.weight, Shape: torch.Size([16, 16, 7, 7])\n",
      "Parameter name: features.7.RepBlock.BottleRep_0.conv_block_1.branch_kernel_7.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: features.7.RepBlock.BottleRep_0.conv_block_1.branch_kernel_7.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: features.7.RepBlock.BottleRep_1.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([16, 16, 7, 7])\n",
      "Parameter name: features.7.RepBlock.BottleRep_1.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: features.7.RepBlock.BottleRep_1.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: features.7.RepBlock.BottleRep_1.conv_block_1.branch_kernel_7.conv.weight, Shape: torch.Size([16, 16, 7, 7])\n",
      "Parameter name: features.7.RepBlock.BottleRep_1.conv_block_1.branch_kernel_7.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: features.7.RepBlock.BottleRep_1.conv_block_1.branch_kernel_7.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: features.7.RepBlock.BottleRep_2.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([16, 16, 7, 7])\n",
      "Parameter name: features.7.RepBlock.BottleRep_2.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: features.7.RepBlock.BottleRep_2.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: features.7.RepBlock.BottleRep_2.conv_block_1.branch_kernel_7.conv.weight, Shape: torch.Size([16, 16, 7, 7])\n",
      "Parameter name: features.7.RepBlock.BottleRep_2.conv_block_1.branch_kernel_7.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: features.7.RepBlock.BottleRep_2.conv_block_1.branch_kernel_7.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: features.7.RepBlock.BottleRep_3.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([16, 16, 7, 7])\n",
      "Parameter name: features.7.RepBlock.BottleRep_3.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: features.7.RepBlock.BottleRep_3.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: features.7.RepBlock.BottleRep_3.conv_block_1.branch_kernel_7.conv.weight, Shape: torch.Size([16, 16, 7, 7])\n",
      "Parameter name: features.7.RepBlock.BottleRep_3.conv_block_1.branch_kernel_7.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: features.7.RepBlock.BottleRep_3.conv_block_1.branch_kernel_7.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: features.7.RepBlock.BottleRep_4.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([16, 16, 7, 7])\n",
      "Parameter name: features.7.RepBlock.BottleRep_4.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: features.7.RepBlock.BottleRep_4.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: features.7.RepBlock.BottleRep_4.conv_block_1.branch_kernel_7.conv.weight, Shape: torch.Size([16, 16, 7, 7])\n",
      "Parameter name: features.7.RepBlock.BottleRep_4.conv_block_1.branch_kernel_7.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: features.7.RepBlock.BottleRep_4.conv_block_1.branch_kernel_7.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: features.7.conv_block_skip.branch_kernel_7.conv.weight, Shape: torch.Size([16, 32, 7, 7])\n",
      "Parameter name: features.7.conv_block_skip.branch_kernel_7.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: features.7.conv_block_skip.branch_kernel_7.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: features.7.conv_block_backmapping.branch_kernel_7.conv.weight, Shape: torch.Size([32, 32, 7, 7])\n",
      "Parameter name: features.7.conv_block_backmapping.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: features.7.conv_block_backmapping.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: features.8.branch_kernel_7.conv.weight, Shape: torch.Size([64, 32, 7, 7])\n",
      "Parameter name: features.8.branch_kernel_7.bn.weight, Shape: torch.Size([64])\n",
      "Parameter name: features.8.branch_kernel_7.bn.bias, Shape: torch.Size([64])\n",
      "Parameter name: features.9.conv_block_reduction.branch_kernel_7.conv.weight, Shape: torch.Size([32, 64, 7, 7])\n",
      "Parameter name: features.9.conv_block_reduction.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: features.9.conv_block_reduction.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: features.9.RepBlock.BottleRep_0.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([32, 32, 7, 7])\n",
      "Parameter name: features.9.RepBlock.BottleRep_0.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: features.9.RepBlock.BottleRep_0.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: features.9.RepBlock.BottleRep_0.conv_block_1.branch_kernel_7.conv.weight, Shape: torch.Size([32, 32, 7, 7])\n",
      "Parameter name: features.9.RepBlock.BottleRep_0.conv_block_1.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: features.9.RepBlock.BottleRep_0.conv_block_1.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: features.9.RepBlock.BottleRep_1.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([32, 32, 7, 7])\n",
      "Parameter name: features.9.RepBlock.BottleRep_1.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: features.9.RepBlock.BottleRep_1.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: features.9.RepBlock.BottleRep_1.conv_block_1.branch_kernel_7.conv.weight, Shape: torch.Size([32, 32, 7, 7])\n",
      "Parameter name: features.9.RepBlock.BottleRep_1.conv_block_1.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: features.9.RepBlock.BottleRep_1.conv_block_1.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: features.9.RepBlock.BottleRep_2.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([32, 32, 7, 7])\n",
      "Parameter name: features.9.RepBlock.BottleRep_2.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: features.9.RepBlock.BottleRep_2.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: features.9.RepBlock.BottleRep_2.conv_block_1.branch_kernel_7.conv.weight, Shape: torch.Size([32, 32, 7, 7])\n",
      "Parameter name: features.9.RepBlock.BottleRep_2.conv_block_1.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: features.9.RepBlock.BottleRep_2.conv_block_1.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: features.9.RepBlock.BottleRep_3.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([32, 32, 7, 7])\n",
      "Parameter name: features.9.RepBlock.BottleRep_3.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: features.9.RepBlock.BottleRep_3.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: features.9.RepBlock.BottleRep_3.conv_block_1.branch_kernel_7.conv.weight, Shape: torch.Size([32, 32, 7, 7])\n",
      "Parameter name: features.9.RepBlock.BottleRep_3.conv_block_1.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: features.9.RepBlock.BottleRep_3.conv_block_1.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: features.9.RepBlock.BottleRep_4.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([32, 32, 7, 7])\n",
      "Parameter name: features.9.RepBlock.BottleRep_4.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: features.9.RepBlock.BottleRep_4.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: features.9.RepBlock.BottleRep_4.conv_block_1.branch_kernel_7.conv.weight, Shape: torch.Size([32, 32, 7, 7])\n",
      "Parameter name: features.9.RepBlock.BottleRep_4.conv_block_1.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: features.9.RepBlock.BottleRep_4.conv_block_1.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: features.9.conv_block_skip.branch_kernel_7.conv.weight, Shape: torch.Size([32, 64, 7, 7])\n",
      "Parameter name: features.9.conv_block_skip.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: features.9.conv_block_skip.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: features.9.conv_block_backmapping.branch_kernel_7.conv.weight, Shape: torch.Size([64, 64, 7, 7])\n",
      "Parameter name: features.9.conv_block_backmapping.branch_kernel_7.bn.weight, Shape: torch.Size([64])\n",
      "Parameter name: features.9.conv_block_backmapping.branch_kernel_7.bn.bias, Shape: torch.Size([64])\n",
      "Parameter name: features.10.branch_kernel_7.conv.weight, Shape: torch.Size([64, 64, 7, 7])\n",
      "Parameter name: features.10.branch_kernel_7.bn.weight, Shape: torch.Size([64])\n",
      "Parameter name: features.10.branch_kernel_7.bn.bias, Shape: torch.Size([64])\n",
      "Parameter name: features.11.conv_block_reduction.branch_kernel_7.conv.weight, Shape: torch.Size([32, 64, 7, 7])\n",
      "Parameter name: features.11.conv_block_reduction.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: features.11.conv_block_reduction.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: features.11.RepBlock.BottleRep_0.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([32, 32, 7, 7])\n",
      "Parameter name: features.11.RepBlock.BottleRep_0.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: features.11.RepBlock.BottleRep_0.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: features.11.RepBlock.BottleRep_0.conv_block_1.branch_kernel_7.conv.weight, Shape: torch.Size([32, 32, 7, 7])\n",
      "Parameter name: features.11.RepBlock.BottleRep_0.conv_block_1.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: features.11.RepBlock.BottleRep_0.conv_block_1.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: features.11.RepBlock.BottleRep_1.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([32, 32, 7, 7])\n",
      "Parameter name: features.11.RepBlock.BottleRep_1.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: features.11.RepBlock.BottleRep_1.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: features.11.RepBlock.BottleRep_1.conv_block_1.branch_kernel_7.conv.weight, Shape: torch.Size([32, 32, 7, 7])\n",
      "Parameter name: features.11.RepBlock.BottleRep_1.conv_block_1.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: features.11.RepBlock.BottleRep_1.conv_block_1.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: features.11.RepBlock.BottleRep_2.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([32, 32, 7, 7])\n",
      "Parameter name: features.11.RepBlock.BottleRep_2.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: features.11.RepBlock.BottleRep_2.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: features.11.RepBlock.BottleRep_2.conv_block_1.branch_kernel_7.conv.weight, Shape: torch.Size([32, 32, 7, 7])\n",
      "Parameter name: features.11.RepBlock.BottleRep_2.conv_block_1.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: features.11.RepBlock.BottleRep_2.conv_block_1.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: features.11.RepBlock.BottleRep_3.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([32, 32, 7, 7])\n",
      "Parameter name: features.11.RepBlock.BottleRep_3.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: features.11.RepBlock.BottleRep_3.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: features.11.RepBlock.BottleRep_3.conv_block_1.branch_kernel_7.conv.weight, Shape: torch.Size([32, 32, 7, 7])\n",
      "Parameter name: features.11.RepBlock.BottleRep_3.conv_block_1.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: features.11.RepBlock.BottleRep_3.conv_block_1.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: features.11.RepBlock.BottleRep_4.conv_block_0.branch_kernel_7.conv.weight, Shape: torch.Size([32, 32, 7, 7])\n",
      "Parameter name: features.11.RepBlock.BottleRep_4.conv_block_0.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: features.11.RepBlock.BottleRep_4.conv_block_0.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: features.11.RepBlock.BottleRep_4.conv_block_1.branch_kernel_7.conv.weight, Shape: torch.Size([32, 32, 7, 7])\n",
      "Parameter name: features.11.RepBlock.BottleRep_4.conv_block_1.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: features.11.RepBlock.BottleRep_4.conv_block_1.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: features.11.conv_block_skip.branch_kernel_7.conv.weight, Shape: torch.Size([32, 64, 7, 7])\n",
      "Parameter name: features.11.conv_block_skip.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: features.11.conv_block_skip.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: features.11.conv_block_backmapping.branch_kernel_7.conv.weight, Shape: torch.Size([64, 64, 7, 7])\n",
      "Parameter name: features.11.conv_block_backmapping.branch_kernel_7.bn.weight, Shape: torch.Size([64])\n",
      "Parameter name: features.11.conv_block_backmapping.branch_kernel_7.bn.bias, Shape: torch.Size([64])\n",
      "Parameter name: features.12.branch_kernel_7.conv.weight, Shape: torch.Size([64, 64, 7, 7])\n",
      "Parameter name: features.12.branch_kernel_7.bn.weight, Shape: torch.Size([64])\n",
      "Parameter name: features.12.branch_kernel_7.bn.bias, Shape: torch.Size([64])\n",
      "-----------------------------SPLIT-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "config = [\n",
    "    ['NAS_REP_ConvBNBlock', [96, 1, 0]],\n",
    "    \n",
    "    ['NAS_REP_ConvBNBlock', [128, 2, 0]],\n",
    "    ['branch_block',         [128, 5, 1]],\n",
    "    \n",
    "    ['NAS_REP_ConvBNBlock', [256, 2, 0]],\n",
    "    ['branch_block', [256, 5, 1]],\n",
    "    \n",
    "    ['NAS_REP_ConvBNBlock', [512, 2, 0]],\n",
    "    ['branch_block', [512, 5, 1]],\n",
    "    \n",
    "    ['NAS_REP_ConvBNBlock', [1024, 2, 0]],\n",
    "    ['branch_block', [1024, 5, 1]],\n",
    "    \n",
    "    # #---\n",
    "    # ['NAS_REP_ConvBNBlock', [1024, 2, 0]],\n",
    "    # ['branch_block', [1024, 5, 1]],\n",
    "    # # ---\n",
    "    \n",
    "    ['NAS_REP_ConvBNBlock', [1024, 1, 0]]\n",
    "]\n",
    "\n",
    "\n",
    "max_kernel_size = 7\n",
    "\n",
    "op = Backbone(\n",
    "    \n",
    "    config,\n",
    "    max_kernel_size, \n",
    "    width_mult        = 0.0625,\n",
    "    combine_style     = \"sub_cat\",\n",
    "    pre_img           = True,\n",
    "    verbose           = False,\n",
    "    scaling_factor    = 0.5,\n",
    "    skip_connection   = True\n",
    "    \n",
    ").to(device) \n",
    "\n",
    "\n",
    "# for name, param in op.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(f\"Parameter name: {name}, Shape: {param.shape}\")\n",
    "\n",
    "print(\"-----------------------------SPLIT-------------------------------------\")\n",
    "\n",
    "op.set_current_runtime_depth_and_kernel(\n",
    "\n",
    "    current_run_time_depth=10,          #  change here\n",
    "    kernel_index=4,                    #  change here\n",
    "\n",
    "    random=False,                      #  change here\n",
    "    all_layers=True,                  #  change here\n",
    "    \n",
    "    active_net=False,                  #  change here\n",
    "    active_all_sub_net=False,          #  change here\n",
    ")\n",
    "\n",
    "\n",
    "# op.ra(\n",
    "\n",
    "#     current_run_time_depth=3,          #  change here\n",
    "#     kernel_index=2,                    #  change here\n",
    "\n",
    "#     random=False,                      #  change here\n",
    "#     all_layers=False,                  #  change here\n",
    "    \n",
    "#     active_net=False,                  #  change here\n",
    "#     active_all_sub_net=False,          #  change here\n",
    "# )\n",
    "\n",
    "\n",
    "for name, param in op.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Parameter name: {name}, Shape: {param.shape}\")\n",
    "        \n",
    "print(\"-----------------------------SPLIT-------------------------------------\")\n",
    "img_size = 1280\n",
    "for _ in range(10):\n",
    "    x = torch.randn([1, 3, img_size, img_size]).to(device)\n",
    "    y = op(x,x)\n",
    "\n",
    "op.eval()\n",
    "# check the inference with a random input\n",
    "x = torch.randn([1, 3, img_size, img_size]).to(device)\n",
    "\n",
    "torch.onnx.export(op,  # model being run\n",
    "                  (x,x) ,\n",
    "                  \"before.onnx\",\n",
    "                  export_params=True,  # store the trained parameter weights inside the model file\n",
    "                  # keep_initializers_as_inputs=True,\n",
    "                  # the ONNX version to export the model to\n",
    "                  opset_version=10,\n",
    "                  verbose=False,\n",
    "                  input_names=['input1','input2'],  # the model's input names\n",
    "                  output_names=['output'],  # the model's output names\n",
    "                  #dynamic_axes={\"input\": {0: \"batch\", 1:\"channel\",2: \"width\",3:\"height\"}}\n",
    "                 )   \n",
    "\n",
    "\n",
    "op_rep= rep_model_convert(op, do_copy=False)\n",
    "op_rep.to(device)\n",
    "op_rep.eval()\n",
    "\n",
    "torch.onnx.export(op_rep,  # model being run\n",
    "                  (x,x) ,\n",
    "                  \"after.onnx\",\n",
    "                  export_params=True,  # store the trained parameter weights inside the model file\n",
    "                  # keep_initializers_as_inputs=True,\n",
    "                  # the ONNX version to export the model to\n",
    "                  opset_version=10,\n",
    "                  verbose=False,\n",
    "                  input_names=['input1','input2'],  # the model's input names\n",
    "                  output_names=['output'],  # the model's output names\n",
    "                  #dynamic_axes={\"input\": {0: \"batch\", 1:\"channel\",2: \"width\",3:\"height\"}}\n",
    "                 )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "471048cf-32ea-48f5-b887-6c0077741bfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding pre_img layer...with input_channel 8\n",
      "-----------------------------SPLIT-------------------------------------\n",
      "Parameter name: pre_img_layer.branch_kernel_7.conv.weight, Shape: torch.Size([8, 3, 7, 7])\n",
      "Parameter name: pre_img_layer.branch_kernel_7.bn.weight, Shape: torch.Size([8])\n",
      "Parameter name: pre_img_layer.branch_kernel_7.bn.bias, Shape: torch.Size([8])\n",
      "Parameter name: features.0.branch_kernel_3.conv.weight, Shape: torch.Size([8, 3, 3, 3])\n",
      "Parameter name: features.0.branch_kernel_3.bn.weight, Shape: torch.Size([8])\n",
      "Parameter name: features.0.branch_kernel_3.bn.bias, Shape: torch.Size([8])\n",
      "Parameter name: features.1.branch_kernel_3.conv.weight, Shape: torch.Size([8, 24, 3, 3])\n",
      "Parameter name: features.1.branch_kernel_3.bn.weight, Shape: torch.Size([8])\n",
      "Parameter name: features.1.branch_kernel_3.bn.bias, Shape: torch.Size([8])\n",
      "Parameter name: features.2.branch_kernel_3.conv.weight, Shape: torch.Size([8, 8, 3, 3])\n",
      "Parameter name: features.2.branch_kernel_3.bn.weight, Shape: torch.Size([8])\n",
      "Parameter name: features.2.branch_kernel_3.bn.bias, Shape: torch.Size([8])\n",
      "Parameter name: features.3.conv_block_reduction.branch_kernel_3.conv.weight, Shape: torch.Size([4, 8, 3, 3])\n",
      "Parameter name: features.3.conv_block_reduction.branch_kernel_3.bn.weight, Shape: torch.Size([4])\n",
      "Parameter name: features.3.conv_block_reduction.branch_kernel_3.bn.bias, Shape: torch.Size([4])\n",
      "Parameter name: features.3.RepBlock.BottleRep_0.conv_block_0.branch_kernel_5.conv.weight, Shape: torch.Size([4, 4, 5, 5])\n",
      "Parameter name: features.3.RepBlock.BottleRep_0.conv_block_0.branch_kernel_5.bn.weight, Shape: torch.Size([4])\n",
      "Parameter name: features.3.RepBlock.BottleRep_0.conv_block_0.branch_kernel_5.bn.bias, Shape: torch.Size([4])\n",
      "Parameter name: features.3.RepBlock.BottleRep_0.conv_block_1.branch_kernel_1.conv.weight, Shape: torch.Size([4, 4, 1, 1])\n",
      "Parameter name: features.3.RepBlock.BottleRep_0.conv_block_1.branch_kernel_1.bn.weight, Shape: torch.Size([4])\n",
      "Parameter name: features.3.RepBlock.BottleRep_0.conv_block_1.branch_kernel_1.bn.bias, Shape: torch.Size([4])\n",
      "Parameter name: features.3.conv_block_skip.branch_kernel_7.conv.weight, Shape: torch.Size([4, 8, 7, 7])\n",
      "Parameter name: features.3.conv_block_skip.branch_kernel_7.bn.weight, Shape: torch.Size([4])\n",
      "Parameter name: features.3.conv_block_skip.branch_kernel_7.bn.bias, Shape: torch.Size([4])\n",
      "Parameter name: features.3.conv_block_backmapping.branch_kernel_5.conv.weight, Shape: torch.Size([8, 8, 5, 5])\n",
      "Parameter name: features.3.conv_block_backmapping.branch_kernel_5.bn.weight, Shape: torch.Size([8])\n",
      "Parameter name: features.3.conv_block_backmapping.branch_kernel_5.bn.bias, Shape: torch.Size([8])\n",
      "Parameter name: features.4.branch_kernel_5.conv.weight, Shape: torch.Size([16, 8, 5, 5])\n",
      "Parameter name: features.4.branch_kernel_5.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: features.4.branch_kernel_5.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: features.5.conv_block_reduction.branch_kernel_1.conv.weight, Shape: torch.Size([8, 16, 1, 1])\n",
      "Parameter name: features.5.conv_block_reduction.branch_kernel_1.bn.weight, Shape: torch.Size([8])\n",
      "Parameter name: features.5.conv_block_reduction.branch_kernel_1.bn.bias, Shape: torch.Size([8])\n",
      "Parameter name: features.5.conv_block_skip.branch_kernel_7.conv.weight, Shape: torch.Size([8, 16, 7, 7])\n",
      "Parameter name: features.5.conv_block_skip.branch_kernel_7.bn.weight, Shape: torch.Size([8])\n",
      "Parameter name: features.5.conv_block_skip.branch_kernel_7.bn.bias, Shape: torch.Size([8])\n",
      "Parameter name: features.5.conv_block_backmapping.branch_kernel_5.conv.weight, Shape: torch.Size([16, 16, 5, 5])\n",
      "Parameter name: features.5.conv_block_backmapping.branch_kernel_5.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: features.5.conv_block_backmapping.branch_kernel_5.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: features.6.branch_kernel_5.conv.weight, Shape: torch.Size([32, 16, 5, 5])\n",
      "Parameter name: features.6.branch_kernel_5.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: features.6.branch_kernel_5.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: features.7.conv_block_reduction.branch_kernel_5.conv.weight, Shape: torch.Size([16, 32, 5, 5])\n",
      "Parameter name: features.7.conv_block_reduction.branch_kernel_5.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: features.7.conv_block_reduction.branch_kernel_5.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: features.7.RepBlock.BottleRep_0.conv_block_0.branch_kernel_0.weight, Shape: torch.Size([16])\n",
      "Parameter name: features.7.RepBlock.BottleRep_0.conv_block_0.branch_kernel_0.bias, Shape: torch.Size([16])\n",
      "Parameter name: features.7.RepBlock.BottleRep_0.conv_block_1.branch_kernel_3.conv.weight, Shape: torch.Size([16, 16, 3, 3])\n",
      "Parameter name: features.7.RepBlock.BottleRep_0.conv_block_1.branch_kernel_3.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: features.7.RepBlock.BottleRep_0.conv_block_1.branch_kernel_3.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: features.7.conv_block_skip.branch_kernel_5.conv.weight, Shape: torch.Size([16, 32, 5, 5])\n",
      "Parameter name: features.7.conv_block_skip.branch_kernel_5.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: features.7.conv_block_skip.branch_kernel_5.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: features.7.conv_block_backmapping.branch_kernel_1.conv.weight, Shape: torch.Size([32, 32, 1, 1])\n",
      "Parameter name: features.7.conv_block_backmapping.branch_kernel_1.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: features.7.conv_block_backmapping.branch_kernel_1.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: features.8.branch_kernel_5.conv.weight, Shape: torch.Size([64, 32, 5, 5])\n",
      "Parameter name: features.8.branch_kernel_5.bn.weight, Shape: torch.Size([64])\n",
      "Parameter name: features.8.branch_kernel_5.bn.bias, Shape: torch.Size([64])\n",
      "Parameter name: features.9.conv_block_reduction.branch_kernel_7.conv.weight, Shape: torch.Size([32, 64, 7, 7])\n",
      "Parameter name: features.9.conv_block_reduction.branch_kernel_7.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: features.9.conv_block_reduction.branch_kernel_7.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: features.9.RepBlock.BottleRep_0.conv_block_0.branch_kernel_3.conv.weight, Shape: torch.Size([32, 32, 3, 3])\n",
      "Parameter name: features.9.RepBlock.BottleRep_0.conv_block_0.branch_kernel_3.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: features.9.RepBlock.BottleRep_0.conv_block_0.branch_kernel_3.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: features.9.RepBlock.BottleRep_0.conv_block_1.branch_kernel_5.conv.weight, Shape: torch.Size([32, 32, 5, 5])\n",
      "Parameter name: features.9.RepBlock.BottleRep_0.conv_block_1.branch_kernel_5.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: features.9.RepBlock.BottleRep_0.conv_block_1.branch_kernel_5.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: features.9.RepBlock.BottleRep_1.conv_block_0.branch_kernel_5.conv.weight, Shape: torch.Size([32, 32, 5, 5])\n",
      "Parameter name: features.9.RepBlock.BottleRep_1.conv_block_0.branch_kernel_5.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: features.9.RepBlock.BottleRep_1.conv_block_0.branch_kernel_5.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: features.9.RepBlock.BottleRep_1.conv_block_1.branch_kernel_3.conv.weight, Shape: torch.Size([32, 32, 3, 3])\n",
      "Parameter name: features.9.RepBlock.BottleRep_1.conv_block_1.branch_kernel_3.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: features.9.RepBlock.BottleRep_1.conv_block_1.branch_kernel_3.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: features.9.RepBlock.BottleRep_2.conv_block_0.branch_kernel_5.conv.weight, Shape: torch.Size([32, 32, 5, 5])\n",
      "Parameter name: features.9.RepBlock.BottleRep_2.conv_block_0.branch_kernel_5.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: features.9.RepBlock.BottleRep_2.conv_block_0.branch_kernel_5.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: features.9.RepBlock.BottleRep_2.conv_block_1.branch_kernel_0.weight, Shape: torch.Size([32])\n",
      "Parameter name: features.9.RepBlock.BottleRep_2.conv_block_1.branch_kernel_0.bias, Shape: torch.Size([32])\n",
      "Parameter name: features.9.conv_block_skip.branch_kernel_1.conv.weight, Shape: torch.Size([32, 64, 1, 1])\n",
      "Parameter name: features.9.conv_block_skip.branch_kernel_1.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: features.9.conv_block_skip.branch_kernel_1.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: features.9.conv_block_backmapping.branch_kernel_1.conv.weight, Shape: torch.Size([64, 64, 1, 1])\n",
      "Parameter name: features.9.conv_block_backmapping.branch_kernel_1.bn.weight, Shape: torch.Size([64])\n",
      "Parameter name: features.9.conv_block_backmapping.branch_kernel_1.bn.bias, Shape: torch.Size([64])\n",
      "Parameter name: features.10.branch_kernel_1.conv.weight, Shape: torch.Size([64, 64, 1, 1])\n",
      "Parameter name: features.10.branch_kernel_1.bn.weight, Shape: torch.Size([64])\n",
      "Parameter name: features.10.branch_kernel_1.bn.bias, Shape: torch.Size([64])\n",
      "tensor(0.4461, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "config = [\n",
    "    ['NAS_REP_ConvBNBlock', [96, 1, 0]],\n",
    "    ['NAS_REP_ConvBNBlock', [128, 2, 0]],\n",
    "    ['branch_block',         [128, 5, 1]],\n",
    "    ['NAS_REP_ConvBNBlock', [256, 2, 0]],\n",
    "    ['branch_block', [256, 5, 1]],\n",
    "    ['NAS_REP_ConvBNBlock', [512, 2, 0]],\n",
    "    ['branch_block', [512, 5, 1]],\n",
    "    ['NAS_REP_ConvBNBlock', [1024, 2, 0]],\n",
    "    ['branch_block', [1024, 5, 1]],\n",
    "    ['NAS_REP_ConvBNBlock', [1024, 1, 0]]\n",
    "]\n",
    "\n",
    "\n",
    "max_kernel_size = 7\n",
    "\n",
    "op = Backbone(\n",
    "    \n",
    "    config,\n",
    "    max_kernel_size, \n",
    "    width_mult        = 0.0625,\n",
    "    combine_style     = \"sub_cat\",\n",
    "    pre_img           = True,\n",
    "    verbose           = False,\n",
    "    scaling_factor    = 0.5,\n",
    "    skip_connection   = True\n",
    "    \n",
    ").to(device) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"-----------------------------SPLIT-------------------------------------\")\n",
    "\n",
    "op.random_set_current_runtime_depth_and_kernel(    all_layers=False, active_net=False, active_all_sub_net=False)\n",
    "\n",
    "for name, param in op.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Parameter name: {name}, Shape: {param.shape}\")\n",
    "        \n",
    "\n",
    "for _ in range(10):\n",
    "    x = torch.randn([1, 3, img_size, img_size]).to(device)\n",
    "    y = op(x, x)\n",
    "\n",
    "op.eval()\n",
    "# check the inference with a random input\n",
    "x = torch.randn([1, 3, img_size, img_size]).to(device)\n",
    "\n",
    "\n",
    "y1 = op(x, x)\n",
    "\n",
    "torch.onnx.export(op,  # model being run\n",
    "                  (x,x) ,\n",
    "                  \"before.onnx\",\n",
    "                  export_params=True,  # store the trained parameter weights inside the model file\n",
    "                  # keep_initializers_as_inputs=True,\n",
    "                  # the ONNX version to export the model to\n",
    "                  opset_version=10,\n",
    "                  verbose=False,\n",
    "                  input_names=['input1','input2'],  # the model's input names\n",
    "                  output_names=['output'],  # the model's output names\n",
    "                  #dynamic_axes={\"input\": {0: \"batch\", 1:\"channel\",2: \"width\",3:\"height\"}}\n",
    "                 )   \n",
    "op_rep= rep_model_convert(op, do_copy=False)\n",
    "op_rep.to(device)\n",
    "op_rep.eval()\n",
    "\n",
    "\n",
    "y2 = op_rep(x,x)\n",
    "\n",
    "\n",
    "\n",
    "print(y1[-1].abs().max())\n",
    "print(((y1[-1]-y2[-1]).abs()).max())\n",
    "\n",
    "torch.onnx.export(op_rep,  # model being run\n",
    "                  (x,x) ,\n",
    "                  \"after.onnx\",\n",
    "                  export_params=True,  # store the trained parameter weights inside the model file\n",
    "                  # keep_initializers_as_inputs=True,\n",
    "                  # the ONNX version to export the model to\n",
    "                  opset_version=10,\n",
    "                  verbose=False,\n",
    "                  input_names=['input1','input2'],  # the model's input names\n",
    "                  output_names=['output'],  # the model's output names\n",
    "                  #dynamic_axes={\"input\": {0: \"batch\", 1:\"channel\",2: \"width\",3:\"height\"}}\n",
    "                 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b566e642-9965-4893-9345-bd9a2b599dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding pre_img layer...with input_channel 8\n",
      "Total trainable parameters: 2661664\n",
      "-----------------------------SPLIT-------------------------------------\n",
      "Total trainable parameters: 401424\n",
      "Total trainable parameters: 2661664\n"
     ]
    }
   ],
   "source": [
    "config = [\n",
    "    ['NAS_REP_ConvBNBlock', [96, 1, 0]],\n",
    "    ['NAS_REP_ConvBNBlock', [128, 2, 0]],\n",
    "    ['branch_block',         [128, 5, 1]],\n",
    "    ['NAS_REP_ConvBNBlock', [256, 2, 0]],\n",
    "    ['branch_block', [256, 5, 1]],\n",
    "    ['NAS_REP_ConvBNBlock', [512, 2, 0]],\n",
    "    ['branch_block', [512, 5, 1]],\n",
    "    ['NAS_REP_ConvBNBlock', [1024, 2, 0]],\n",
    "    ['branch_block', [1024, 5, 1]],\n",
    "    ['NAS_REP_ConvBNBlock', [1024, 1, 0]]\n",
    "]\n",
    "\n",
    "\n",
    "max_kernel_size = 7\n",
    "\n",
    "op = Backbone(\n",
    "    \n",
    "    config,\n",
    "    max_kernel_size, \n",
    "    width_mult        = 0.0625,\n",
    "    combine_style     = \"sub_cat\",\n",
    "    pre_img           = True,\n",
    "    verbose           = False,\n",
    "    scaling_factor    = 0.5,\n",
    "    skip_connection   = True\n",
    "    \n",
    ").to(device) \n",
    "\n",
    "\n",
    "\n",
    "total_params = sum(p.numel() for p in op.parameters() if p.requires_grad)\n",
    "print(f'Total trainable parameters: {total_params}')\n",
    "\n",
    "print(\"-----------------------------SPLIT-------------------------------------\")\n",
    "\n",
    "op.random_set_current_runtime_depth_and_kernel(    all_layers=False, active_net=False, active_all_sub_net=False)\n",
    "\n",
    "total_params = sum(p.numel() for p in op.parameters() if p.requires_grad)\n",
    "print(f'Total trainable parameters: {total_params}')\n",
    "\n",
    "op.reset_active_depth_and_conv()\n",
    "total_params = sum(p.numel() for p in op.parameters() if p.requires_grad)\n",
    "print(f'Total trainable parameters: {total_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57271b4-c1bd-4ef2-9276-aa2bc6564c0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeac71ac-0754-4215-a2c4-eea3b0ac6970",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02f5ca65-d211-4ed1-b15a-e15a3d7f319d",
   "metadata": {},
   "source": [
    "# NECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b04efc49-8255-40e6-aa34-c678215e71ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_up_weights(up):\n",
    "    w = up.weight.data\n",
    "    f = math.ceil(w.size(2) / 2)\n",
    "    c = (2 * f - 1 - f % 2) / (2. * f)\n",
    "    for i in range(w.size(2)):\n",
    "        for j in range(w.size(3)):\n",
    "            w[0, 0, i, j] = \\\n",
    "                (1 - math.fabs(i / f - c)) * (1 - math.fabs(j / f - c))\n",
    "    for c in range(1, w.size(0)):\n",
    "        w[c, 0, :, :] = w[0, 0, :, :]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class BottleRep_neck_IDAUp(nn.Module):\n",
    "    def __init__(self, c_in, c_out, max_kernel_size,configs,verbose=False, scaling_factor = 0.5, run_time_depth_index=0):\n",
    "        # configs  [1,[3,3,3],2,[3,3,3]]\n",
    "        # [3, [5], 2, [3]]\n",
    "        super(BottleRep_neck_IDAUp, self).__init__()\n",
    "\n",
    "        self.c_in                 = c_in\n",
    "        self.c_out                = c_out\n",
    "        self.max_kernel_size      = max_kernel_size\n",
    "        self.scaling_factor       = scaling_factor\n",
    "        self.run_time_depth_index = run_time_depth_index\n",
    "\n",
    "\n",
    "        self.project =  NAS_REP_ConvBNBlock(\n",
    "            c_in,\n",
    "            c_out,\n",
    "            max_kernel_size, \n",
    "            1, \n",
    "            verbose=verbose, \n",
    "            scaling_factor=scaling_factor,\n",
    "            run_time_depth_index = 0\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        n1 = configs[0]\n",
    "        self.BottleRep_neck_0 = BottleRep(\n",
    "            c_out, \n",
    "            c_out, \n",
    "            max_kernel_size, \n",
    "            1, \n",
    "            number_blocks = n1, \n",
    "            verbose = verbose,\n",
    "            scaling_factor = scaling_factor,\n",
    "            run_time_depth_index = 1,\n",
    "            keep_same_run_time = False,\n",
    "            skip_connection    = False\n",
    "        )\n",
    "            \n",
    "        up_ratio      = configs[1]\n",
    "        self.up = nn.ConvTranspose2d(c_out, c_out, \n",
    "                                     up_ratio * 2, stride=up_ratio, \n",
    "                                     padding=up_ratio // 2, output_padding=0,\n",
    "                                     groups=c_out, bias=False) # 变大wh\n",
    "        fill_up_weights(self.up)\n",
    "        \n",
    "        \n",
    "        \n",
    "        n2    = configs[2]\n",
    "\n",
    "        self.BottleRep_neck_1 = BottleRep(\n",
    "            c_out, \n",
    "            c_out, \n",
    "            max_kernel_size, \n",
    "            1, \n",
    "            number_blocks        = n2, \n",
    "            verbose              = verbose,\n",
    "            scaling_factor       = scaling_factor,\n",
    "            run_time_depth_index = 0,\n",
    "            keep_same_run_time   = False,\n",
    "            skip_connection      = False\n",
    "        )\n",
    "    \n",
    "    def forward(self, x1,x2):\n",
    "        # x1 has more downration 2 times than x2\n",
    "\n",
    "        x2 = self.project(x2)\n",
    "\n",
    "        x2 = self.BottleRep_neck_0(x2)\n",
    "\n",
    "        x2 = self.up(x2)\n",
    "        \n",
    "        return self.BottleRep_neck_1(x1+x2)\n",
    "\n",
    "    \n",
    "    def reset_active_depth_and_conv(self):\n",
    "        \n",
    "        self.project.reset_active_net_param()\n",
    "        self.BottleRep_neck_0.reset_active_depth_and_conv()\n",
    "        self.BottleRep_neck_1.reset_active_depth_and_conv()\n",
    "        for param in self.up.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "    def set_current_runtime_depth_and_kernel(self, \n",
    "                                             current_run_time_depth  = None, \n",
    "                                             kernel_index            = None, \n",
    "                                             \n",
    "                                             random                  = False, \n",
    "                                             all_layers              = False,\n",
    "                                             \n",
    "                                             active_net              = False, \n",
    "                                             active_all_sub_net      = False,\n",
    "                                             \n",
    "                                            ):\n",
    "\n",
    "        assert current_run_time_depth>= self.run_time_depth_index\n",
    "        self.current_run_time_depth = current_run_time_depth\n",
    "        \n",
    "\n",
    "        self.project.set_current_runtime_depth_and_kernel(current_run_time_depth,    kernel_index,    random, all_layers, active_net, active_all_sub_net)\n",
    "        self.BottleRep_neck_0.set_current_runtime_depth_and_kernel(current_run_time_depth,    kernel_index,    random, all_layers, active_net, active_all_sub_net)\n",
    "        self.BottleRep_neck_1.set_current_runtime_depth_and_kernel(current_run_time_depth,    kernel_index,    random, all_layers, active_net, active_all_sub_net)\n",
    "\n",
    "        for param in self.up.parameters():\n",
    "            param.requires_grad = False\n",
    "        if current_run_time_depth == self.run_time_depth_index:\n",
    "            for param in self.up.parameters():\n",
    "                param.requires_grad = True\n",
    "        elif current_run_time_depth>self.run_time_depth_index:\n",
    "            if random or all_layers:\n",
    "                for param in self.up.parameters():\n",
    "                    param.requires_grad = True\n",
    "\n",
    "    def random_set_current_runtime_depth_and_kernel( self,     all_layers=False,    active_net=False,     active_all_sub_net=False):\n",
    "        \n",
    "        self.project.set_current_runtime_depth_and_kernel(0,    None,    True, all_layers, active_net, active_all_sub_net)\n",
    "        \n",
    "        assert self.BottleRep_neck_0.run_time_depth_index_list is not None\n",
    "        if self.BottleRep_neck_0.run_time_depth_index > 0:\n",
    "            random_run_depth = random.choice([0]+self.BottleRep_neck_0.run_time_depth_index_list) \n",
    "        else:\n",
    "            random_run_depth = random.choice(self.BottleRep_neck_0.run_time_depth_index_list) \n",
    "            \n",
    "        self.BottleRep_neck_0.set_current_runtime_depth_and_kernel(random_run_depth,    None,    True, all_layers, active_net, active_all_sub_net)\n",
    "\n",
    "        assert self.BottleRep_neck_1.run_time_depth_index_list is not None\n",
    "        if self.BottleRep_neck_1.run_time_depth_index > 0:\n",
    "            random_run_depth = random.choice([0]+self.BottleRep_neck_1.run_time_depth_index_list) \n",
    "        else:\n",
    "            random_run_depth = random.choice(self.BottleRep_neck_1.run_time_depth_index_list) \n",
    "            \n",
    "        self.BottleRep_neck_1.set_current_runtime_depth_and_kernel(random_run_depth,    None,    True, all_layers, active_net, active_all_sub_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced44bb0-995e-42a2-8215-f894242bd050",
   "metadata": {},
   "source": [
    "### check the inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d1286050-30a4-46ef-b361-2a0059f0179d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------  split line ---------------------\n",
      "Parameter name: project.branch_kernel_3.conv.weight, Shape: torch.Size([256, 128, 3, 3])\n",
      "Parameter name: project.branch_kernel_3.bn.weight, Shape: torch.Size([256])\n",
      "Parameter name: project.branch_kernel_3.bn.bias, Shape: torch.Size([256])\n",
      "Parameter name: up.weight, Shape: torch.Size([256, 1, 4, 4])\n",
      "Parameter name: BottleRep_neck_1.conv_block_0.branch_kernel_5.conv.weight, Shape: torch.Size([256, 256, 5, 5])\n",
      "Parameter name: BottleRep_neck_1.conv_block_0.branch_kernel_5.bn.weight, Shape: torch.Size([256])\n",
      "Parameter name: BottleRep_neck_1.conv_block_0.branch_kernel_5.bn.bias, Shape: torch.Size([256])\n",
      "Parameter name: BottleRep_neck_1.conv_block_1.branch_kernel_0.weight, Shape: torch.Size([256])\n",
      "Parameter name: BottleRep_neck_1.conv_block_1.branch_kernel_0.bias, Shape: torch.Size([256])\n",
      "Parameter name: BottleRep_neck_1.conv_block_2.branch_kernel_3.conv.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Parameter name: BottleRep_neck_1.conv_block_2.branch_kernel_3.bn.weight, Shape: torch.Size([256])\n",
      "Parameter name: BottleRep_neck_1.conv_block_2.branch_kernel_3.bn.bias, Shape: torch.Size([256])\n",
      "Parameter name: BottleRep_neck_1.conv_block_3.branch_kernel_3.conv.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Parameter name: BottleRep_neck_1.conv_block_3.branch_kernel_3.bn.weight, Shape: torch.Size([256])\n",
      "Parameter name: BottleRep_neck_1.conv_block_3.branch_kernel_3.bn.bias, Shape: torch.Size([256])\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_5\n",
      "using branch_kernel_0\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "using branch_kernel_0\n",
      "using branch_kernel_1\n",
      "using branch_kernel_3\n",
      "tensor(1.4971, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# check the nas_rep_block\n",
    "in_channels        = 128\n",
    "out_channels       = 256\n",
    "img_size           = 128\n",
    "max_kernel_size    = 7\n",
    "configs            = [4,2,5]\n",
    "run_time_depth_index = 0\n",
    "# init the block with verbose as True, to check the forward pass\n",
    "op = BottleRep_neck_IDAUp(\n",
    "\n",
    "    in_channels,\n",
    "    out_channels,\n",
    "    max_kernel_size,\n",
    "    configs, \n",
    "    verbose=True,\n",
    "    scaling_factor=0.5,\n",
    "    run_time_depth_index = run_time_depth_index).to(device) \n",
    "\n",
    "# check the name and the parameter shape\n",
    "# for name, param in op.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(f\"Parameter name: {name}, Shape: {param.shape}\")\n",
    "print(\"-----------------------  split line ---------------------\")\n",
    "        \n",
    "# # check the inference with a random input\n",
    "# op.set_current_runtime_depth_and_kernel(\n",
    "#     current_run_time_depth=10,\n",
    "#     kernel_index=3,\n",
    "#     random=False,\n",
    "#     all_layers=True,\n",
    "#     active_net=False,\n",
    "#     active_all_sub_net=False,\n",
    "# )\n",
    "\n",
    "op.random_set_current_runtime_depth_and_kernel()\n",
    "\n",
    "for name, param in op.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Parameter name: {name}, Shape: {param.shape}\")\n",
    "for _ in range(10):\n",
    "    x2 = torch.randn([1, in_channels, img_size, img_size]).to(device)  \n",
    "    x1 = torch.randn([1, out_channels, int(img_size*2), int(2*img_size)]).to(device)  \n",
    "    \n",
    "    y = op(x1,x2)\n",
    "\n",
    "\n",
    "op.eval()\n",
    "# check the inference with a random input\n",
    "x2 = torch.randn([1, in_channels, img_size, img_size]).to(device)  \n",
    "x1 = torch.randn([1, out_channels, int(img_size*2), int(2*img_size)]).to(device)  \n",
    "\n",
    "\n",
    "y1 = op(x1,x2)\n",
    "\n",
    "\n",
    "torch.onnx.export(op,  # model being run\n",
    "                  (x1,x2) ,\n",
    "                  \"before.onnx\",\n",
    "                  export_params=True,  # store the trained parameter weights inside the model file\n",
    "                  # keep_initializers_as_inputs=True,\n",
    "                  # the ONNX version to export the model to\n",
    "                  opset_version=10,\n",
    "                  verbose=False,\n",
    "                  input_names=['input1','input2'],  # the model's input names\n",
    "                  output_names=['output'],  # the model's output names\n",
    "                  #dynamic_axes={\"input\": {0: \"batch\", 1:\"channel\",2: \"width\",3:\"height\"}}\n",
    "                 )   \n",
    "\n",
    "\n",
    "op_rep= rep_model_convert(op, do_copy=False)\n",
    "op_rep.to(device)\n",
    "op_rep.eval()\n",
    "\n",
    "\n",
    "y2 = op_rep(x1,x2)\n",
    "\n",
    "\n",
    "\n",
    "print(y1.abs().max())\n",
    "print(((y1-y2).abs()).max())\n",
    "\n",
    "torch.onnx.export(op_rep,  # model being run\n",
    "                  (x1,x2) ,\n",
    "                  \"after.onnx\",\n",
    "                  export_params=True,  # store the trained parameter weights inside the model file\n",
    "                  # keep_initializers_as_inputs=True,\n",
    "                  # the ONNX version to export the model to\n",
    "                  opset_version=10,\n",
    "                  verbose=False,\n",
    "                  input_names=['input1','input2'],  # the model's input names\n",
    "                  output_names=['output'],  # the model's output names\n",
    "                  #dynamic_axes={\"input\": {0: \"batch\", 1:\"channel\",2: \"width\",3:\"height\"}}\n",
    "                 )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e20e32d-fd35-4ddb-af75-d97439c83458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6811b6ff-277c-41c3-9606-e3e95cf948bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e43e060-8791-4499-b39d-3b8d90353f12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296e3fff-7161-4aa5-826b-0ba33d5dbb00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e650b4-acb6-401e-b9cd-e629db104938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2d6116e-452a-4264-b34e-00683ed66dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neck(nn.Module):\n",
    "    def __init__(self,  channels, max_kernel_size,     configs, verbose=False, scaling_factor = 0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.channels = channels # [32, 48, 64, 128, 256, 512]\n",
    "        assert len(self.channels) == 4\n",
    "        assert len(configs) == len(self.channels)-1+2\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        config_list = configs[0]\n",
    "        self.up_level_1 = []\n",
    "        for i, cfg in enumerate(config_list):\n",
    "\n",
    "            self.up_level_1.append(BottleRep_neck_IDAUp(\n",
    "                c_in             =  self.channels[i+1], \n",
    "                c_out            =  self.channels[i],\n",
    "                max_kernel_size  =  max_kernel_size,\n",
    "                configs          =  cfg,\n",
    "                verbose          =  verbose,\n",
    "                scaling_factor   =  0.5,\n",
    "                run_time_depth_index= 0\n",
    "            ))\n",
    "            \n",
    "        self.up_level_1 = nn.ModuleList(self.up_level_1)\n",
    "          \n",
    "        config_list = configs[1]\n",
    "        self.up_level_2 = []\n",
    "        for i, cfg in enumerate(config_list):\n",
    "            self.up_level_2.append(BottleRep_neck_IDAUp(\n",
    "                c_in             = self.channels[i+1], \n",
    "                c_out            = self.channels[i],\n",
    "                max_kernel_size  = max_kernel_size,\n",
    "                configs          = cfg,\n",
    "                verbose          =  verbose,\n",
    "                scaling_factor   =  0.5,\n",
    "                run_time_depth_index= 0\n",
    "            ))\n",
    "            \n",
    "        self.up_level_2 = nn.ModuleList(self.up_level_2)\n",
    "        \n",
    "        config_list = configs[2]    \n",
    "        self.up_level_3 = []\n",
    "        for i, cfg in enumerate(config_list):\n",
    "            self.up_level_3.append(BottleRep_neck_IDAUp(\n",
    "                c_in             = self.channels[i+1], \n",
    "                c_out            = self.channels[i],\n",
    "                max_kernel_size  = max_kernel_size,\n",
    "                configs          = cfg,\n",
    "                verbose          =  verbose,\n",
    "                scaling_factor   =  0.5,\n",
    "                run_time_depth_index= 0\n",
    "            ))\n",
    "            \n",
    "        self.up_level_3 = nn.ModuleList(self.up_level_3)\n",
    "        \n",
    "        cfg = configs[3]\n",
    "        self.up_level_4 = BottleRep_neck_IDAUp(\n",
    "            c_in             = self.channels[1], \n",
    "            c_out            = self.channels[0],\n",
    "            max_kernel_size  = max_kernel_size,\n",
    "            configs          = cfg,\n",
    "            verbose          =  verbose,\n",
    "            scaling_factor   =  0.5,\n",
    "            run_time_depth_index= 0\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        cfg = configs[4]\n",
    "        self.up_level_5 = BottleRep_neck_IDAUp(\n",
    "            c_in             =self.channels[2], \n",
    "            c_out            =self.channels[0],\n",
    "            max_kernel_size  =max_kernel_size,\n",
    "            configs          = cfg,\n",
    "            verbose          =  verbose,\n",
    "            scaling_factor   =  0.5,\n",
    "            run_time_depth_index= 0\n",
    "        )\n",
    "        \n",
    "    def forward(self, x1, x2, x3, x4):\n",
    "        x_list = [x1, x2, x3, x4]\n",
    "        out_level_1 = []\n",
    "        for i,op in enumerate(self.up_level_1):\n",
    "            out_level_1.append(op(x_list[i],x_list[i+1]))\n",
    "\n",
    "            \n",
    "        out_level_2 = []\n",
    "        for i,op in enumerate(self.up_level_2):\n",
    "            out_level_2.append(op(out_level_1[i],out_level_1[i+1]))\n",
    "  \n",
    "            \n",
    "        out_level_3 = []\n",
    "        for i,op in enumerate(self.up_level_3):\n",
    "            out_level_3.append(op(out_level_2[i],out_level_2[i+1]))\n",
    "\n",
    "\n",
    "        out = self.up_level_4(out_level_3[-1],out_level_2[-1])\n",
    "\n",
    "\n",
    "        out = self.up_level_5(out, out_level_1[-1])\n",
    "\n",
    "        return out\n",
    "\n",
    "    def reset_active_depth_and_conv(self):\n",
    "        \n",
    "        for layer in self.up_level_1:\n",
    "            layer.reset_active_depth_and_conv()\n",
    "        \n",
    "        for layer in self.up_level_2:\n",
    "            layer.reset_active_depth_and_conv()\n",
    "\n",
    "        for layer in self.up_level_3:\n",
    "            layer.reset_active_depth_and_conv()\n",
    "        self.up_level_4.reset_active_depth_and_conv()\n",
    "        self.up_level_5.reset_active_depth_and_conv()\n",
    "\n",
    "    def set_current_runtime_depth_and_kernel(self, \n",
    "                                             current_run_time_depth  = None, \n",
    "                                             kernel_index            = None, \n",
    "                                             \n",
    "                                             random                  = False, \n",
    "                                             all_layers              = False,\n",
    "                                             \n",
    "                                             active_net              = False, \n",
    "                                             active_all_sub_net      = False,\n",
    "                                             \n",
    "                                            ):\n",
    "\n",
    "        for layer in self.up_level_1:\n",
    "            layer.set_current_runtime_depth_and_kernel(current_run_time_depth,    kernel_index,    random, all_layers, active_net, active_all_sub_net)\n",
    "        \n",
    "        for layer in self.up_level_2:\n",
    "            layer.set_current_runtime_depth_and_kernel(current_run_time_depth,    kernel_index,    random, all_layers, active_net, active_all_sub_net)\n",
    "\n",
    "        for layer in self.up_level_3:\n",
    "            layer.set_current_runtime_depth_and_kernel(current_run_time_depth,    kernel_index,    random, all_layers, active_net, active_all_sub_net)\n",
    "        self.up_level_4.set_current_runtime_depth_and_kernel(current_run_time_depth,    kernel_index,    random, all_layers, active_net, active_all_sub_net)\n",
    "        self.up_level_5.set_current_runtime_depth_and_kernel(current_run_time_depth,    kernel_index,    random, all_layers, active_net, active_all_sub_net)\n",
    "\n",
    "    def random_set_current_runtime_depth_and_kernel( self,     all_layers=False,    active_net=False,     active_all_sub_net=False):\n",
    "        \n",
    "        for layer in self.up_level_1:\n",
    "            layer.random_set_current_runtime_depth_and_kernel(all_layers, active_net, active_all_sub_net)\n",
    "        \n",
    "        for layer in self.up_level_2:\n",
    "            layer.random_set_current_runtime_depth_and_kernel(all_layers, active_net, active_all_sub_net)\n",
    "\n",
    "        for layer in self.up_level_3:\n",
    "            layer.random_set_current_runtime_depth_and_kernel(all_layers, active_net, active_all_sub_net)\n",
    "            \n",
    "        self.up_level_4.random_set_current_runtime_depth_and_kernel(all_layers, active_net, active_all_sub_net)\n",
    "        self.up_level_5.random_set_current_runtime_depth_and_kernel(all_layers, active_net, active_all_sub_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530f117d-87b4-49ad-ab0e-1a739e61411b",
   "metadata": {},
   "source": [
    "# SuperNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0efd5ba9-ed06-4422-979e-1845c6780fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_fc_weights(layers):\n",
    "    for m in layers.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "class SuperNetNetwork(nn.Module):\n",
    "    def __init__(self,  network_config,  network_seed = 1, opt = None):\n",
    "        super(SuperNetNetwork, self).__init__()\n",
    "        \n",
    "        self.opt = opt\n",
    "\n",
    "        assert network_config[\"backbone\"] is not None\n",
    "        assert network_config[\"neck\"] is not None\n",
    "        assert network_config[\"head\"] is not None\n",
    "        \n",
    "        backbone_config = network_config[\"backbone\"]\n",
    "        self.backbone = Backbone(\n",
    "            config             = backbone_config,\n",
    "            max_kernel_size    = opt.max_kernel_size,\n",
    "            width_mult         = opt.width_mult,\n",
    "            round_nearest      = 8,\n",
    "            pre_img            = opt.pre_img,\n",
    "            combine_style      = opt.combine_style,\n",
    "            verbose            = opt.verbose,\n",
    "            scaling_factor     = opt.scaling_factor,\n",
    "            skip_connection    = opt.skip_connection,\n",
    "        )\n",
    "\n",
    "        \n",
    "        channels = self.backbone.channels[2:]\n",
    "        neck_config = network_config[\"neck\"]\n",
    "        self.neck = Neck(\n",
    "            \n",
    "            channels         = channels,\n",
    "            max_kernel_size  = opt.max_kernel_size, \n",
    "            configs          = neck_config, \n",
    "            verbose          = opt.verbose,\n",
    "            scaling_factor   = opt.scaling_factor\n",
    "        )\n",
    "\n",
    "        \n",
    "        last_channel         = channels[0]\n",
    "        self.heads           = opt.heads\n",
    "        head_kernel          = 3\n",
    "        prior_bias           = -4.6\n",
    "        head_configs         = network_config[\"head\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        for head in self.heads: # {'hm': num_cls, 'reg': 2, 'wh': 2}\n",
    "            classes = self.heads[head]\n",
    "            number_blocks =  head_configs[head]\n",
    "            if number_blocks>0:\n",
    "                convs = BottleRep(\n",
    "                    c_in                = last_channel,\n",
    "                    c_out               = last_channel,\n",
    "                    max_kernel_size     = opt.max_kernel_size,\n",
    "                    stride              =  1,\n",
    "                    number_blocks       = number_blocks,\n",
    "                    verbose             = opt.verbose,\n",
    "                    scaling_factor      = opt.scaling_factor,\n",
    "                    run_time_depth_index= 0,\n",
    "                    keep_same_run_time  =False,\n",
    "                    skip_connection     =False,\n",
    "                )\n",
    "            else:\n",
    "                convs = None\n",
    "\n",
    "            \n",
    "            out = nn.Conv2d(last_channel, classes, kernel_size=1, stride=1, padding=0, bias=True)\n",
    "            \n",
    "            if convs is not None:\n",
    "                fc = nn.Sequential(convs,out)\n",
    "            else:\n",
    "                fc = nn.Sequential(out)\n",
    "                \n",
    "            if 'hm' in head:\n",
    "                fc[-1].bias.data.fill_(prior_bias)\n",
    "            else:\n",
    "                fill_fc_weights(fc)\n",
    "            self.__setattr__(head, fc)\n",
    "            \n",
    "            \n",
    "    def forward(self, x, pre_img=None, pre_hm=None):\n",
    "\n",
    "        y = self.backbone(x, pre_img, pre_hm)\n",
    "\n",
    "        feats = self.neck(*y[2:])\n",
    "        out = []\n",
    "        \n",
    "        if self.opt.model_output_list:\n",
    "            z = []\n",
    "\n",
    "            for head in sorted(self.heads):\n",
    "\n",
    "                z_temp = self.__getattr__(head)(feats)\n",
    "\n",
    "                z.append(z_temp)\n",
    "            out.append(z)\n",
    "        else:\n",
    "            z = {}\n",
    "            for head in sorted(self.heads):\n",
    "                z_temp = self.__getattr__(head)(feats)\n",
    "\n",
    "                z[head] = z_temp\n",
    "\n",
    "            out.append(z)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def set_current_runtime_depth_and_kernel(self, \n",
    "                                             current_run_time_depth  = None, \n",
    "                                             kernel_index            = None, \n",
    "                                             \n",
    "                                             random                  = False, \n",
    "                                             all_layers              = False,\n",
    "                                             \n",
    "                                             active_net              = False, \n",
    "                                             active_all_sub_net      = False,\n",
    "                                             \n",
    "                                            ):\n",
    "\n",
    "        self.backbone.set_current_runtime_depth_and_kernel(current_run_time_depth,    kernel_index,    random, all_layers, active_net, active_all_sub_net)\n",
    "        self.neck.set_current_runtime_depth_and_kernel(current_run_time_depth,    kernel_index,    random, all_layers, active_net, active_all_sub_net)\n",
    "        for head in sorted(self.heads):\n",
    "            self.__getattr__(head)[0].set_current_runtime_depth_and_kernel(current_run_time_depth,    kernel_index,    random, all_layers, active_net, active_all_sub_net)\n",
    "\n",
    "    def random_set_current_runtime_depth_and_kernel( self,     all_layers=False,    active_net=False,     active_all_sub_net=False):\n",
    "        self.backbone.random_set_current_runtime_depth_and_kernel(all_layers,    active_net,     active_all_sub_net)\n",
    "        self.neck.random_set_current_runtime_depth_and_kernel(all_layers,    active_net,     active_all_sub_net)\n",
    "        for head in sorted(self.heads):\n",
    "            assert self.__getattr__(head)[0].run_time_depth_index_list is not None\n",
    "            random_run_depth = random.choice(self.__getattr__(head)[0].run_time_depth_index_list) \n",
    "            self.__getattr__(head)[0].set_current_runtime_depth_and_kernel(random_run_depth,    None,    True, all_layers, active_net, active_all_sub_net)\n",
    "            \n",
    "    def reset_active_depth_and_conv(self):\n",
    "        \n",
    "        self.backbone.reset_active_depth_and_conv()\n",
    "        self.neck.reset_active_depth_and_conv()\n",
    "        for head in sorted(self.heads):\n",
    "            self.__getattr__(head)[0].reset_active_depth_and_conv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05f848f3-92be-4a84-8b10-836551a9e395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding pre_img layer...with input_channel 8\n",
      "Total trainable parameters: 3837404\n",
      "-----------------------------SPLIT-------------------------------------\n",
      "Total trainable parameters: 784284\n",
      "Total trainable parameters: 3837404\n"
     ]
    }
   ],
   "source": [
    "network_config = {\n",
    "    \"backbone\" : [\n",
    "        ['NAS_REP_ConvBNBlock', [96, 1, 0]],\n",
    "        ['NAS_REP_ConvBNBlock', [128, 2, 0]],\n",
    "        ['branch_block',         [128, 5, 1]],\n",
    "        ['NAS_REP_ConvBNBlock', [256, 2, 0]],\n",
    "        ['branch_block', [256, 5, 1]],\n",
    "        ['NAS_REP_ConvBNBlock', [512, 2, 0]],\n",
    "        ['branch_block', [512, 5, 1]],\n",
    "        ['NAS_REP_ConvBNBlock', [1024, 2, 0]],\n",
    "        ['branch_block', [1024, 5, 1]],\n",
    "        ['NAS_REP_ConvBNBlock', [1024, 1, 0]]\n",
    "    ],\n",
    "    \"neck\" : [\n",
    "        [[2,2,3], [2,2,3], [2,2,3]],\n",
    "        [[2,2,3], [2,2,3]],\n",
    "        [[2,2,3]],\n",
    "        [2,2,3],\n",
    "        [2,4,3]\n",
    "    ],\n",
    "    \"head\" : {\n",
    "        'hm':  3,\n",
    "        'reg': 3,\n",
    "        'wh':  3,\n",
    "        'tracking': 3\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "\n",
    "opt = dotdict()\n",
    "\n",
    "opt.max_kernel_size     = 7\n",
    "opt.width_mult          = 0.0625\n",
    "opt.pre_img             = True\n",
    "opt.combine_style       = \"sub_cat\"\n",
    "opt.verbose             = False\n",
    "opt.scaling_factor      = 0.5\n",
    "opt.skip_connection     = True\n",
    "num_cls                 = 6\n",
    "opt.heads               = {'hm': num_cls, 'reg': 2, 'wh': 2, 'tracking':2}\n",
    "\n",
    "op = SuperNetNetwork(network_config = network_config, opt=opt).to(device)  \n",
    "\n",
    "\n",
    "total_params = sum(p.numel() for p in op.parameters() if p.requires_grad)\n",
    "print(f'Total trainable parameters: {total_params}')\n",
    "\n",
    "print(\"-----------------------------SPLIT-------------------------------------\")\n",
    "\n",
    "op.random_set_current_runtime_depth_and_kernel(    all_layers=False, active_net=False, active_all_sub_net=False)\n",
    "\n",
    "total_params = sum(p.numel() for p in op.parameters() if p.requires_grad)\n",
    "print(f'Total trainable parameters: {total_params}')\n",
    "\n",
    "op.reset_active_depth_and_conv()\n",
    "total_params = sum(p.numel() for p in op.parameters() if p.requires_grad)\n",
    "print(f'Total trainable parameters: {total_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b91deea-0356-4b1b-bb88-ef9e6fc61e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "749e51d5-dd6b-4ac5-abc6-d37c25147e68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding pre_img layer...with input_channel 8\n",
      "-----------------------  split line ---------------------\n",
      "Parameter name: backbone.features.3.RepBlock.BottleRep_1.conv_block_0.branch_kernel_1.conv.weight, Shape: torch.Size([4, 4, 1, 1])\n",
      "Parameter name: backbone.features.3.RepBlock.BottleRep_1.conv_block_0.branch_kernel_1.bn.weight, Shape: torch.Size([4])\n",
      "Parameter name: backbone.features.3.RepBlock.BottleRep_1.conv_block_0.branch_kernel_1.bn.bias, Shape: torch.Size([4])\n",
      "Parameter name: backbone.features.3.RepBlock.BottleRep_1.conv_block_1.branch_kernel_1.conv.weight, Shape: torch.Size([4, 4, 1, 1])\n",
      "Parameter name: backbone.features.3.RepBlock.BottleRep_1.conv_block_1.branch_kernel_1.bn.weight, Shape: torch.Size([4])\n",
      "Parameter name: backbone.features.3.RepBlock.BottleRep_1.conv_block_1.branch_kernel_1.bn.bias, Shape: torch.Size([4])\n",
      "Parameter name: backbone.features.5.RepBlock.BottleRep_1.conv_block_0.branch_kernel_1.conv.weight, Shape: torch.Size([8, 8, 1, 1])\n",
      "Parameter name: backbone.features.5.RepBlock.BottleRep_1.conv_block_0.branch_kernel_1.bn.weight, Shape: torch.Size([8])\n",
      "Parameter name: backbone.features.5.RepBlock.BottleRep_1.conv_block_0.branch_kernel_1.bn.bias, Shape: torch.Size([8])\n",
      "Parameter name: backbone.features.5.RepBlock.BottleRep_1.conv_block_1.branch_kernel_1.conv.weight, Shape: torch.Size([8, 8, 1, 1])\n",
      "Parameter name: backbone.features.5.RepBlock.BottleRep_1.conv_block_1.branch_kernel_1.bn.weight, Shape: torch.Size([8])\n",
      "Parameter name: backbone.features.5.RepBlock.BottleRep_1.conv_block_1.branch_kernel_1.bn.bias, Shape: torch.Size([8])\n",
      "Parameter name: backbone.features.7.RepBlock.BottleRep_1.conv_block_0.branch_kernel_1.conv.weight, Shape: torch.Size([16, 16, 1, 1])\n",
      "Parameter name: backbone.features.7.RepBlock.BottleRep_1.conv_block_0.branch_kernel_1.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: backbone.features.7.RepBlock.BottleRep_1.conv_block_0.branch_kernel_1.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: backbone.features.7.RepBlock.BottleRep_1.conv_block_1.branch_kernel_1.conv.weight, Shape: torch.Size([16, 16, 1, 1])\n",
      "Parameter name: backbone.features.7.RepBlock.BottleRep_1.conv_block_1.branch_kernel_1.bn.weight, Shape: torch.Size([16])\n",
      "Parameter name: backbone.features.7.RepBlock.BottleRep_1.conv_block_1.branch_kernel_1.bn.bias, Shape: torch.Size([16])\n",
      "Parameter name: backbone.features.9.RepBlock.BottleRep_1.conv_block_0.branch_kernel_1.conv.weight, Shape: torch.Size([32, 32, 1, 1])\n",
      "Parameter name: backbone.features.9.RepBlock.BottleRep_1.conv_block_0.branch_kernel_1.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: backbone.features.9.RepBlock.BottleRep_1.conv_block_0.branch_kernel_1.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: backbone.features.9.RepBlock.BottleRep_1.conv_block_1.branch_kernel_1.conv.weight, Shape: torch.Size([32, 32, 1, 1])\n",
      "Parameter name: backbone.features.9.RepBlock.BottleRep_1.conv_block_1.branch_kernel_1.bn.weight, Shape: torch.Size([32])\n",
      "Parameter name: backbone.features.9.RepBlock.BottleRep_1.conv_block_1.branch_kernel_1.bn.bias, Shape: torch.Size([32])\n",
      "Parameter name: hm.1.weight, Shape: torch.Size([6, 8, 1, 1])\n",
      "Parameter name: hm.1.bias, Shape: torch.Size([6])\n",
      "Parameter name: reg.1.weight, Shape: torch.Size([2, 8, 1, 1])\n",
      "Parameter name: reg.1.bias, Shape: torch.Size([2])\n",
      "Parameter name: wh.1.weight, Shape: torch.Size([2, 8, 1, 1])\n",
      "Parameter name: wh.1.bias, Shape: torch.Size([2])\n",
      "Parameter name: tracking.1.weight, Shape: torch.Size([2, 8, 1, 1])\n",
      "Parameter name: tracking.1.bias, Shape: torch.Size([2])\n",
      "tensor(4.7261, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7.2002e-05, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "-------------\n",
      "tensor(0.0317, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3.4565e-05, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "-------------\n",
      "tensor(0.1100, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "-------------\n",
      "tensor(0.0789, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(7.0244e-05, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "network_config = {\n",
    "    \"backbone\" : [\n",
    "        ['NAS_REP_ConvBNBlock', [96, 1, 0]],\n",
    "        ['NAS_REP_ConvBNBlock', [128, 2, 0]],\n",
    "        ['branch_block',         [128, 5, 1]],\n",
    "        ['NAS_REP_ConvBNBlock', [256, 2, 0]],\n",
    "        ['branch_block', [256, 5, 1]],\n",
    "        ['NAS_REP_ConvBNBlock', [512, 2, 0]],\n",
    "        ['branch_block', [512, 5, 1]],\n",
    "        ['NAS_REP_ConvBNBlock', [1024, 2, 0]],\n",
    "        ['branch_block', [1024, 5, 1]],\n",
    "        ['NAS_REP_ConvBNBlock', [1024, 1, 0]]\n",
    "    ],\n",
    "    \"neck\" : [\n",
    "        [[2,2,3], [2,2,3], [2,2,3]],\n",
    "        [[2,2,3], [2,2,3]],\n",
    "        [[2,2,3]],\n",
    "        [2,2,3],\n",
    "        [2,4,3]\n",
    "    ],\n",
    "    \"head\" : {\n",
    "        'hm':  3,\n",
    "        'reg': 3,\n",
    "        'wh':  3,\n",
    "        'tracking': 3\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "\n",
    "opt = dotdict()\n",
    "\n",
    "opt.max_kernel_size     = 7\n",
    "opt.width_mult          = 0.0625\n",
    "opt.pre_img             = True\n",
    "opt.combine_style       = \"sub_cat\"\n",
    "opt.verbose             = False\n",
    "opt.scaling_factor      = 0.5\n",
    "opt.skip_connection     = True\n",
    "num_cls                 = 6\n",
    "opt.heads               = {'hm': num_cls, 'reg': 2, 'wh': 2, 'tracking':2}\n",
    "\n",
    "op = SuperNetNetwork(network_config = network_config, opt=opt).to(device)  \n",
    "\n",
    "print(\"-----------------------  split line ---------------------\")\n",
    "        \n",
    "# # check the inference with a random input\n",
    "op.set_current_runtime_depth_and_kernel(\n",
    "    current_run_time_depth=3,\n",
    "    kernel_index=1,\n",
    "    random=False,\n",
    "    all_layers=False,\n",
    "    active_net=False,\n",
    "    active_all_sub_net=False,\n",
    ")\n",
    "\n",
    "# op.random_set_current_runtime_depth_and_kernel()\n",
    "\n",
    "for name, param in op.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Parameter name: {name}, Shape: {param.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for _ in range(10):\n",
    "    x2 = torch.randn([1, 3, img_size, img_size]).to(device)  \n",
    "    x1 = torch.randn([1, 3, img_size, img_size]).to(device)  \n",
    "    \n",
    "    y = op(x1,x2)\n",
    "\n",
    "\n",
    "op.eval()\n",
    "# check the inference with a random input\n",
    "x2 = torch.randn([1, 3, img_size, img_size]).to(device)  \n",
    "x1 = torch.randn([1, 3, img_size, img_size]).to(device)  \n",
    "\n",
    "\n",
    "y1 = op(x1,x2)\n",
    "\n",
    "\n",
    "torch.onnx.export(op,  # model being run\n",
    "                  (x1,x2) ,\n",
    "                  \"before.onnx\",\n",
    "                  export_params=True,  # store the trained parameter weights inside the model file\n",
    "                  # keep_initializers_as_inputs=True,\n",
    "                  # the ONNX version to export the model to\n",
    "                  opset_version=10,\n",
    "                  verbose=False,\n",
    "                  input_names=['input1','input2'],  # the model's input names\n",
    "                  output_names=['output'],  # the model's output names\n",
    "                  #dynamic_axes={\"input\": {0: \"batch\", 1:\"channel\",2: \"width\",3:\"height\"}}\n",
    "                 )   \n",
    "\n",
    "\n",
    "op_rep= rep_model_convert(op, do_copy=False)\n",
    "op_rep.to(device)\n",
    "op_rep.eval()\n",
    "\n",
    "\n",
    "y2 = op_rep(x1,x2)\n",
    "\n",
    "\n",
    "\n",
    "for head in opt.heads.keys():\n",
    "    \n",
    "\n",
    "    print(y1[0][head].abs().max())\n",
    "    print(((y1[0][head]-y2[0][head]).abs()).max())\n",
    "    print(\"-------------\")\n",
    "\n",
    "\n",
    "torch.onnx.export(op_rep,  # model being run\n",
    "                  (x1,x2) ,\n",
    "                  \"after.onnx\",\n",
    "                  export_params=True,  # store the trained parameter weights inside the model file\n",
    "                  # keep_initializers_as_inputs=True,\n",
    "                  # the ONNX version to export the model to\n",
    "                  opset_version=10,\n",
    "                  verbose=False,\n",
    "                  input_names=['input1','input2'],  # the model's input names\n",
    "                  output_names=['output'],  # the model's output names\n",
    "                  #dynamic_axes={\"input\": {0: \"batch\", 1:\"channel\",2: \"width\",3:\"height\"}}\n",
    "                 )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "43029685-3137-41b6-9df0-a40a7847929e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding pre_img layer...with input_channel 8\n",
      "tensor(25.5773, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0284, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "-------------\n",
      "tensor(12.8019, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0178, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "-------------\n",
      "tensor(4.9662, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0327, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "-------------\n",
      "tensor(23.3574, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0220, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "-------------\n",
      "--========================================\n"
     ]
    }
   ],
   "source": [
    "network_config = {\n",
    "    \"backbone\" : [\n",
    "        ['NAS_REP_ConvBNBlock', [96, 1, 0]],\n",
    "        ['NAS_REP_ConvBNBlock', [128, 2, 0]],\n",
    "        ['branch_block',         [128, 5, 1]],\n",
    "        ['NAS_REP_ConvBNBlock', [256, 2, 0]],\n",
    "        ['branch_block', [256, 5, 1]],\n",
    "        ['NAS_REP_ConvBNBlock', [512, 2, 0]],\n",
    "        ['branch_block', [512, 5, 1]],\n",
    "        ['NAS_REP_ConvBNBlock', [1024, 2, 0]],\n",
    "        ['branch_block', [1024, 5, 1]],\n",
    "        ['NAS_REP_ConvBNBlock', [1024, 1, 0]]\n",
    "    ],\n",
    "    \"neck\" : [\n",
    "        [[2,2,3], [2,2,3], [2,2,3]],\n",
    "        [[2,2,3], [2,2,3]],\n",
    "        [[2,2,3]],\n",
    "        [2,2,3],\n",
    "        [2,4,3]\n",
    "    ],\n",
    "    \"head\" : {\n",
    "        'hm':  3,\n",
    "        'reg': 3,\n",
    "        'wh':  3,\n",
    "        'tracking': 3\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "\n",
    "opt = dotdict()\n",
    "\n",
    "opt.max_kernel_size     = 7\n",
    "opt.width_mult          = 0.125\n",
    "opt.pre_img             = True\n",
    "opt.combine_style       = \"sub_cat\"\n",
    "opt.verbose             = False\n",
    "opt.scaling_factor      = 0.5\n",
    "opt.skip_connection     = True\n",
    "num_cls                 = 6\n",
    "opt.heads               = {'hm': num_cls, 'reg': 2, 'wh': 2, 'tracking':2}\n",
    "\n",
    "\n",
    "for _ in range(1):\n",
    "    op = SuperNetNetwork(network_config = network_config, opt=opt).to(device)  \n",
    "    \n",
    "\n",
    "    img_size        = 128\n",
    "    for i in range(10):\n",
    "        x2 = torch.randn([1, 3, img_size, img_size]).to(device)  \n",
    "        x1 = torch.randn([1, 3, img_size, img_size]).to(device)  \n",
    "        y = op(x1, x2)\n",
    "\n",
    "    \n",
    "    op.eval()\n",
    "\n",
    "    torch.onnx.export(op,  # model being run\n",
    "                      (x1,x2) ,\n",
    "                      \"before.onnx\",\n",
    "                      export_params=True,  # store the trained parameter weights inside the model file\n",
    "                      # keep_initializers_as_inputs=True,\n",
    "                      # the ONNX version to export the model to\n",
    "                      opset_version=10,\n",
    "                      verbose=False,\n",
    "                      input_names=['input1','input2'],  # the model's input names\n",
    "                      output_names=['output'],  # the model's output names\n",
    "                      #dynamic_axes={\"input\": {0: \"batch\", 1:\"channel\",2: \"width\",3:\"height\"}}\n",
    "                     )   \n",
    "    \n",
    "    x2 = torch.randn([1, 3, img_size, img_size]).to(device)  \n",
    "    x1 = torch.randn([1, 3, img_size, img_size]).to(device)  \n",
    "    y1 = op(x1, x2)\n",
    "\n",
    "    op_rep= rep_model_convert(op, do_copy=False)\n",
    "    y2 = op_rep(x1, x2)\n",
    "\n",
    "    torch.onnx.export(op_rep,  # model being run\n",
    "                      (x1,x2) ,\n",
    "                      \"after.onnx\",\n",
    "                      export_params=True,  # store the trained parameter weights inside the model file\n",
    "                      # keep_initializers_as_inputs=True,\n",
    "                      # the ONNX version to export the model to\n",
    "                      opset_version=10,\n",
    "                      verbose=False,\n",
    "                      input_names=['input1','input2'],  # the model's input names\n",
    "                      output_names=['output'],  # the model's output names\n",
    "                      #dynamic_axes={\"input\": {0: \"batch\", 1:\"channel\",2: \"width\",3:\"height\"}}\n",
    "                     )   \n",
    "    for head in opt.heads.keys():\n",
    "        \n",
    "\n",
    "        print(y1[0][head].max())\n",
    "        print(((y1[0][head]-y2[0][head]).abs()).max())\n",
    "        print(\"-------------\")\n",
    "\n",
    "\n",
    "    print(\"--========================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a94b80b-471e-4954-94f5-f5424f185430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda2e105-bc9d-422b-9fb5-131fd60ba783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f25d18-fe87-4028-942e-801ea7ec6aac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b8b8ff94-c4e9-4b0e-b32a-c627c9f38c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding pre_img layer...with input_channel 8\n",
      "tensor(-4.5436, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(4.1485e-05, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "-------------\n",
      "tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "-------------\n",
      "tensor(0.0247, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "-------------\n",
      "tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "-------------\n",
      "--========================================\n"
     ]
    }
   ],
   "source": [
    "network_config = {\n",
    "    \"backbone\" : [\n",
    "        ['NAS_REP_ConvBNBlock', [96, 1, 0]],\n",
    "        ['NAS_REP_ConvBNBlock', [128, 2, 0]],\n",
    "        ['branch_block',         [128, 5, 1]],\n",
    "        ['NAS_REP_ConvBNBlock', [256, 2, 0]],\n",
    "        ['branch_block', [256, 5, 1]],\n",
    "        ['NAS_REP_ConvBNBlock', [512, 2, 0]],\n",
    "        ['branch_block', [512, 5, 1]],\n",
    "        ['NAS_REP_ConvBNBlock', [1024, 2, 0]],\n",
    "        ['branch_block', [1024, 5, 1]],\n",
    "        ['NAS_REP_ConvBNBlock', [1024, 1, 0]]\n",
    "    ],\n",
    "    \"neck\" : [\n",
    "        [[2,2,3], [2,2,3], [2,2,3]],\n",
    "        [[2,2,3], [2,2,3]],\n",
    "        [[2,2,3]],\n",
    "        [2,2,3],\n",
    "        [2,4,3]\n",
    "    ],\n",
    "    \"head\" : {\n",
    "        'hm':  3,\n",
    "        'reg': 3,\n",
    "        'wh':  3,\n",
    "        'tracking': 3\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "\n",
    "opt = dotdict()\n",
    "\n",
    "opt.max_kernel_size     = 7\n",
    "opt.width_mult          = 0.125\n",
    "opt.pre_img             = True\n",
    "opt.combine_style       = \"sub_cat\"\n",
    "opt.verbose             = False\n",
    "opt.scaling_factor      = 0.5\n",
    "opt.skip_connection     = True\n",
    "num_cls                 = 6\n",
    "opt.heads               = {'hm': num_cls, 'reg': 2, 'wh': 2, 'tracking':2}\n",
    "\n",
    "\n",
    "for _ in range(1):\n",
    "    op = SuperNetNetwork(network_config = network_config, opt=opt).to(device)  \n",
    "    \n",
    "    op.set_current_runtime_depth_and_kernel(\n",
    "        current_run_time_depth=2,\n",
    "        kernel_index=None,\n",
    "        random=True,\n",
    "        all_layers=False,\n",
    "        active_net=False,\n",
    "        active_all_sub_net=False,\n",
    "    )\n",
    "\n",
    "    img_size        = 128\n",
    "    for i in range(10):\n",
    "        x2 = torch.randn([1, 3, img_size, img_size]).to(device)  \n",
    "        x1 = torch.randn([1, 3, img_size, img_size]).to(device)  \n",
    "        y = op(x1, x2)\n",
    "\n",
    "    \n",
    "    op.eval()\n",
    "\n",
    "    torch.onnx.export(op,  # model being run\n",
    "                      (x1,x2) ,\n",
    "                      \"before.onnx\",\n",
    "                      export_params=True,  # store the trained parameter weights inside the model file\n",
    "                      # keep_initializers_as_inputs=True,\n",
    "                      # the ONNX version to export the model to\n",
    "                      opset_version=10,\n",
    "                      verbose=False,\n",
    "                      input_names=['input1','input2'],  # the model's input names\n",
    "                      output_names=['output'],  # the model's output names\n",
    "                      #dynamic_axes={\"input\": {0: \"batch\", 1:\"channel\",2: \"width\",3:\"height\"}}\n",
    "                     )   \n",
    "    \n",
    "    x2 = torch.randn([1, 3, img_size, img_size]).to(device)  \n",
    "    x1 = torch.randn([1, 3, img_size, img_size]).to(device)  \n",
    "    y1 = op(x1, x2)\n",
    "\n",
    "    op_rep= rep_model_convert(op, do_copy=False)\n",
    "    y2 = op_rep(x1, x2)\n",
    "\n",
    "    torch.onnx.export(op_rep,  # model being run\n",
    "                      (x1,x2) ,\n",
    "                      \"after.onnx\",\n",
    "                      export_params=True,  # store the trained parameter weights inside the model file\n",
    "                      # keep_initializers_as_inputs=True,\n",
    "                      # the ONNX version to export the model to\n",
    "                      opset_version=10,\n",
    "                      verbose=False,\n",
    "                      input_names=['input1','input2'],  # the model's input names\n",
    "                      output_names=['output'],  # the model's output names\n",
    "                      #dynamic_axes={\"input\": {0: \"batch\", 1:\"channel\",2: \"width\",3:\"height\"}}\n",
    "                     )   \n",
    "    for head in opt.heads.keys():\n",
    "        \n",
    "\n",
    "        print(y1[0][head].max())\n",
    "        print(((y1[0][head]-y2[0][head]).abs()).max())\n",
    "        print(\"-------------\")\n",
    "\n",
    "\n",
    "    print(\"--========================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "36e49e67-cc16-4425-bb63-e306dd6d7d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding pre_img layer...with input_channel 8\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 88\u001b[0m\n\u001b[1;32m     85\u001b[0m x1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, img_size, img_size])\u001b[38;5;241m.\u001b[39mto(device)  \n\u001b[1;32m     86\u001b[0m y1 \u001b[38;5;241m=\u001b[39m op(x1, x2)\n\u001b[0;32m---> 88\u001b[0m op_rep\u001b[38;5;241m=\u001b[39m \u001b[43mrep_model_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_copy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m y2 \u001b[38;5;241m=\u001b[39m op_rep(x1, x2)\n\u001b[1;32m     91\u001b[0m torch\u001b[38;5;241m.\u001b[39monnx\u001b[38;5;241m.\u001b[39mexport(op_rep,  \u001b[38;5;66;03m# model being run\u001b[39;00m\n\u001b[1;32m     92\u001b[0m                   (x1,x2) ,\n\u001b[1;32m     93\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mafter.onnx\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m                   \u001b[38;5;66;03m#dynamic_axes={\"input\": {0: \"batch\", 1:\"channel\",2: \"width\",3:\"height\"}}\u001b[39;00m\n\u001b[1;32m    102\u001b[0m                  )   \n",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m, in \u001b[0;36mrep_model_convert\u001b[0;34m(model, save_path, do_copy)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mmodules():\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(module, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mswitch_to_deploy\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m----> 6\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mswitch_to_deploy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      8\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), save_path)\n",
      "Cell \u001b[0;32mIn[11], line 306\u001b[0m, in \u001b[0;36mNAS_REP_ConvBNBlock.switch_to_deploy\u001b[0;34m(self, only_for_weight)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m only_for_weight:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m kernel, bias\n\u001b[0;32m--> 306\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_reparam \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactive_kernel_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactive_kernel_index\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_reparam\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m kernel\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_reparam\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m bias\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py:430\u001b[0m, in \u001b[0;36mConv2d.__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[1;32m    428\u001b[0m padding_ \u001b[38;5;241m=\u001b[39m padding \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(padding, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m _pair(padding)\n\u001b[1;32m    429\u001b[0m dilation_ \u001b[38;5;241m=\u001b[39m _pair(dilation)\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mConv2d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pair\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py:138\u001b[0m, in \u001b[0;36m_ConvNd.__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_parameter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 138\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py:144\u001b[0m, in \u001b[0;36m_ConvNd.reset_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     fan_in, _ \u001b[38;5;241m=\u001b[39m init\u001b[38;5;241m.\u001b[39m_calculate_fan_in_and_fan_out(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight)\n\u001b[0;32m--> 144\u001b[0m     bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfan_in\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     init\u001b[38;5;241m.\u001b[39muniform_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;241m-\u001b[39mbound, bound)\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "network_config = {\n",
    "    \"backbone\" : [\n",
    "        ['NAS_REP_ConvBNBlock', [96, 1, 0]],\n",
    "        ['NAS_REP_ConvBNBlock', [128, 2, 0]],\n",
    "        ['branch_block',         [128, 5, 1]],\n",
    "        ['NAS_REP_ConvBNBlock', [256, 2, 0]],\n",
    "        ['branch_block', [256, 5, 1]],\n",
    "        ['NAS_REP_ConvBNBlock', [512, 2, 0]],\n",
    "        ['branch_block', [512, 5, 1]],\n",
    "        ['NAS_REP_ConvBNBlock', [1024, 2, 0]],\n",
    "        ['branch_block', [1024, 5, 1]],\n",
    "        ['NAS_REP_ConvBNBlock', [1024, 1, 0]]\n",
    "    ],\n",
    "    \"neck\" : [\n",
    "        [[2,2,3], [2,2,3], [2,2,3]],\n",
    "        [[2,2,3], [2,2,3]],\n",
    "        [[2,2,3]],\n",
    "        [2,2,3],\n",
    "        [2,4,3]\n",
    "    ],\n",
    "    \"head\" : {\n",
    "        'hm':  3,\n",
    "        'reg': 3,\n",
    "        'wh':  3,\n",
    "        'tracking': 3\n",
    "        'specific':3\n",
    "        }\n",
    "\n",
    "}\n",
    "\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "\n",
    "opt = dotdict()\n",
    "\n",
    "opt.max_kernel_size     = 7\n",
    "opt.width_mult          = 0.125\n",
    "opt.pre_img             = True\n",
    "opt.combine_style       = \"sub_cat\"\n",
    "opt.verbose             = False\n",
    "opt.scaling_factor      = 0.5\n",
    "opt.skip_connection     = True\n",
    "num_cls                 = 6\n",
    "opt.heads               = {'hm': num_cls, 'reg': 2, 'wh': 2, 'tracking':2}\n",
    "\n",
    "\n",
    "for _ in range(1):\n",
    "    op = SuperNetNetwork(network_config = network_config, opt=opt).to(device)  \n",
    "    \n",
    "    op.set_current_runtime_depth_and_kernel(\n",
    "        current_run_time_depth=2,\n",
    "        kernel_index=None,\n",
    "        random=True,\n",
    "        all_layers=False,\n",
    "        active_net=False,\n",
    "        active_all_sub_net=False,\n",
    "    )\n",
    "\n",
    "    img_size        = 128\n",
    "    for i in range(10):\n",
    "        x2 = torch.randn([1, 3, img_size, img_size]).to(device)  \n",
    "        x1 = torch.randn([1, 3, img_size, img_size]).to(device)  \n",
    "        y = op(x1, x2)\n",
    "\n",
    "    \n",
    "    op.eval()\n",
    "\n",
    "    torch.onnx.export(op,  # model being run\n",
    "                      (x1,x2) ,\n",
    "                      \"before.onnx\",\n",
    "                      export_params=True,  # store the trained parameter weights inside the model file\n",
    "                      # keep_initializers_as_inputs=True,\n",
    "                      # the ONNX version to export the model to\n",
    "                      opset_version=10,\n",
    "                      verbose=False,\n",
    "                      input_names=['input1','input2'],  # the model's input names\n",
    "                      output_names=['output'],  # the model's output names\n",
    "                      #dynamic_axes={\"input\": {0: \"batch\", 1:\"channel\",2: \"width\",3:\"height\"}}\n",
    "                     )   \n",
    "    \n",
    "    x2 = torch.randn([1, 3, img_size, img_size]).to(device)  \n",
    "    x1 = torch.randn([1, 3, img_size, img_size]).to(device)  \n",
    "    y1 = op(x1, x2)\n",
    "\n",
    "    op_rep= rep_model_convert(op, do_copy=False)\n",
    "    y2 = op_rep(x1, x2)\n",
    "\n",
    "    torch.onnx.export(op_rep,  # model being run\n",
    "                      (x1,x2) ,\n",
    "                      \"after.onnx\",\n",
    "                      export_params=True,  # store the trained parameter weights inside the model file\n",
    "                      # keep_initializers_as_inputs=True,\n",
    "                      # the ONNX version to export the model to\n",
    "                      opset_version=10,\n",
    "                      verbose=False,\n",
    "                      input_names=['input1','input2'],  # the model's input names\n",
    "                      output_names=['output'],  # the model's output names\n",
    "                      #dynamic_axes={\"input\": {0: \"batch\", 1:\"channel\",2: \"width\",3:\"height\"}}\n",
    "                     )   \n",
    "    for head in opt.heads.keys():\n",
    "        \n",
    "\n",
    "        print(y1[0][head].max())\n",
    "        print(((y1[0][head]-y2[0][head]).abs()).max())\n",
    "        print(\"-------------\")\n",
    "\n",
    "\n",
    "    print(\"--========================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7931e7d-d44d-41bc-83b1-5ddd04eca992",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iswc23",
   "language": "python",
   "name": "iswc23"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
